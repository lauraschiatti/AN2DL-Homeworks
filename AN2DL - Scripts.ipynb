{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "AN2DL - Scripts.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "vgFGiPLeMKtB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e8da3146-3bf3-4b2a-89c2-90e04a48dd99"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eFAHb7jCTBkb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c1185908-b27f-4417-a77f-7febbbebd561"
      },
      "source": [
        "open(\"/content/drive/My Drive/Colab Notebooks/file.out\", \"a\")"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_io.TextIOWrapper name='/content/drive/My Drive/Colab Notebooks/file.out' mode='a' encoding='UTF-8'>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "bD9Tuu6YLmIf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "c477f1c7-81ee-4241-f112-37b67c2b901b"
      },
      "source": [
        "!pip install split-folders"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting split-folders\n",
            "  Downloading https://files.pythonhosted.org/packages/20/67/29dda743e6d23ac1ea3d16704d8bbb48d65faf3f1b1eaf53153b3da56c56/split_folders-0.3.1-py3-none-any.whl\n",
            "Installing collected packages: split-folders\n",
            "Successfully installed split-folders-0.3.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "oXmHFHb3LmIm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "0469045b-e845-4e7d-8b71-fe3f996bf916"
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "# Installa TensorFlow\n",
        "try:\n",
        "  # %tensorflow_version solo existe in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "\n",
        "import os\n",
        "import tensorflow as tf\n",
        "import split_folders\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from datetime import datetime\n",
        "\n",
        "## ------------------------------------------------------------------------------------ ##\n",
        "                                 # Data loader #\n",
        "## ------------------------------------------------------------------------------------ ##\n",
        "\n",
        "# fix the seed for random operations to make experiments reproducible\n",
        "seed = 123\n",
        "tf.random.set_seed(seed)\n",
        "\n",
        "cwd = os.getcwd()\n",
        "# path to dataset\n",
        "dataset_dir = os.path.join('/content/drive/My Drive/Colab Notebooks', 'Classification_Dataset')\n",
        "\n",
        "train_dir = os.path.join(dataset_dir, 'training')\n",
        "test_dir = os.path.join(dataset_dir, 'test')\n",
        "\n",
        "# input image dimensions\n",
        "img_w = 256\n",
        "img_h = 256\n",
        "\n",
        "# number of input channels (color space)\n",
        "channels = 3  # rgb\n",
        "\n",
        "# input shape\n",
        "input_shape = (img_h, img_w, channels)\n",
        "\n",
        "class_list = [\n",
        "    'owl',  # 0\n",
        "    'galaxy',  # 1\n",
        "    'lightning',  # 2\n",
        "    'wine-bottle',  # 3\n",
        "    't-shirt',  # 4\n",
        "    'waterfall',  # 5\n",
        "    'sword',  # 6\n",
        "    'school-bus',  # 7\n",
        "    'calculator',  # 8\n",
        "    'sheet-music',  # 9\n",
        "    'airplanes',  # 10\n",
        "    'lightbulb',  # 11\n",
        "    'skyscraper',  # 12\n",
        "    'mountain-bike',  # 13\n",
        "    'fireworks',  # 14\n",
        "    'computer-monitor',  # 15\n",
        "    'bear',  # 16\n",
        "    'grand-piano',  # 17\n",
        "    'kangaroo',  # 18\n",
        "    'laptop'  # 19\n",
        "]\n",
        "\n",
        "num_classes = len(class_list) # 20\n",
        "\n",
        "# number of training samples to feed the NN at each training step\n",
        "batch_size = 16 # 8, 32, 64             # training size: 1247 samples\n",
        "                                        # batch size: 16 samples/iteration\n",
        "                                        # more or less 78 iterations/epochh\n",
        "\n",
        "\n",
        "\n",
        "# Create image generators from directory\n",
        "# --------------------------------------\n",
        "def setup_data_generator(with_data_augmentation=True, create_test_generator=False):\n",
        "    # the data, split between train and test sets\n",
        "\n",
        "    # NOTE: splitting is done with 'flow_from_directory(â€¦, subset=training/validation)\n",
        "    # The fixed random seed is enough to reproduce the splitting.\n",
        "\n",
        "    # fraction of images reserved for validation\n",
        "    valid_split = 0.2\n",
        "\n",
        "    # define data augmentation configuration\n",
        "    apply_data_augmentation = with_data_augmentation\n",
        "    if apply_data_augmentation:\n",
        "\n",
        "        train_data_gen = ImageDataGenerator(rescale=1. / 255,  # every pixel value from range [0,255] -> [0,1]\n",
        "                                            shear_range=0.2,\n",
        "                                            zoom_range=0.2,\n",
        "                                            rotation_range=45,\n",
        "                                            horizontal_flip=True,\n",
        "                                            vertical_flip=True,\n",
        "                                            validation_split=valid_split)\n",
        "\n",
        "    else:\n",
        "        train_data_gen = ImageDataGenerator(rescale=1. / 255,\n",
        "                                            validation_split=valid_split)\n",
        "\n",
        "    print('\\ntrain_gen ... ')\n",
        "    train_generator = train_data_gen.flow_from_directory(train_dir,\n",
        "                                                  subset='training',  # subset of data\n",
        "                                                  batch_size=batch_size,\n",
        "                                                  target_size=(img_w, img_h),  # images are automatically resized\n",
        "                                                  color_mode='rgb',\n",
        "                                                  classes=class_list,\n",
        "                                                  class_mode='categorical',\n",
        "                                                  shuffle=True,\n",
        "                                                  seed=seed)\n",
        "\n",
        "    print('\\nvalid_gen ... ')\n",
        "    valid_generator = train_data_gen.flow_from_directory(train_dir,\n",
        "                                                  subset='validation',\n",
        "                                                  batch_size=batch_size,\n",
        "                                                  target_size=(img_w, img_h),\n",
        "                                                  color_mode='rgb',\n",
        "                                                  classes=class_list,\n",
        "                                                  class_mode='categorical',\n",
        "                                                  shuffle=False,\n",
        "                                                  seed=seed)\n",
        "\n",
        "    return train_generator, valid_generator\n",
        "\n",
        "    \n",
        "# Visualize accuracy and loss over time\n",
        "# -------------------------------------\n",
        "def visualize_performance(trained_model):\n",
        "    # plt.plot(trained_model.history)\n",
        "\n",
        "    accuracy = trained_model.history['accuracy']\n",
        "    validation_accuracy = trained_model.history['val_accuracy']\n",
        "    loss = trained_model.history['loss']\n",
        "    validation_loss = trained_model.history['val_loss']\n",
        "\n",
        "    epochs = range(len(accuracy))\n",
        "\n",
        "    # Visualize History for Loss.\n",
        "    plt.title('Model loss')\n",
        "    plt.plot(epochs, loss, 'b', label='Training loss')\n",
        "    plt.plot(epochs, validation_loss, 'r', label='Validation loss')\n",
        "    plt.title('Training and validation loss')\n",
        "    plt.legend(['training', 'validation'], loc='upper right')\n",
        "    plt.show()\n",
        "\n",
        "    # # Visualize History for Accuracy.\n",
        "    plt.title('Model accuracy')\n",
        "    plt.plot(epochs, accuracy, 'b', label='Training acc')\n",
        "    plt.plot(epochs, validation_accuracy, 'r', label='Validation acc')\n",
        "    plt.title('Training and validation accuracy')\n",
        "    plt.legend(['training', 'validation'], loc='lower right')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# Compute predictions (probabilities -- the output of the last layer)\n",
        "# -------------------------------------------------------------------\n",
        "def generate_predictions(model, model_name):\n",
        "    results = {}\n",
        "    results_str = {}\n",
        "\n",
        "    image_filenames = next(os.walk(test_dir))[2]  # s[:10] predict until 10th image\n",
        "\n",
        "    for filename in image_filenames:\n",
        "        img = Image.open(os.path.join(test_dir, filename)).convert('RGB')  # open as RGB\n",
        "        img = img.resize((img_h, img_w))  # target size\n",
        "\n",
        "        # data_normalization\n",
        "        img_array = np.array(img)  #\n",
        "        img_array = img_array * 1. / 255  # normalization\n",
        "        img_array = np.expand_dims(img_array, axis=0)  # to fix dims of input in the model\n",
        "\n",
        "        print(\"prediction for {}...\".format(filename))\n",
        "        predictions = model.predict(img_array)\n",
        "\n",
        "        # Get predicted class as the index corresponding to the maximum value in the vector probability\n",
        "        predicted_class = np.argmax(predictions, axis=-1)  # multiple categories\n",
        "        predicted_class = predicted_class[0]\n",
        "\n",
        "        results[filename] = predicted_class\n",
        "        results_str[filename] = class_list[predicted_class]\n",
        "\n",
        "    create_csv(results, model_name)\n",
        "\n",
        "    # Prints the nicely formatted dictionary\n",
        "    from pprint import pprint\n",
        "    pprint(results_str)\n",
        "\n",
        "    print('Num. of labeled images', results.__len__())\n",
        "\n",
        "\n",
        "# Create submission csv file\n",
        "# --------------------------\n",
        "def create_csv(results, model_name):\n",
        "    print(\"\\nGenerating submission csv ... \")\n",
        "\n",
        "    # save on a different dir according to the classifier used\n",
        "    results_dir = 'image_classification/submissions/' + model_name\n",
        "\n",
        "    # If directory for the classifier does not exist, create\n",
        "    if not os.path.exists(results_dir):\n",
        "        os.makedirs(results_dir)\n",
        "\n",
        "    csv_fname = 'results_'\n",
        "    csv_fname += datetime.now().strftime('%b%d_%H-%M-%S') + '.csv'\n",
        "\n",
        "    with open(os.path.join(results_dir, csv_fname), 'w') as f:\n",
        "\n",
        "        fieldnames = 'Id,Category'\n",
        "        f.write(fieldnames + '\\n')\n",
        "\n",
        "        for key, value in results.items():\n",
        "            f.write(key + ',' + str(value) + '\\n')\n",
        "\n",
        "# Save model\n",
        "# -------------------------------\n",
        "def save_model(path, model, model_type):\n",
        "    model_filename = os.path.join(path, \"model_\"+model_type+\"-\"+datetime.now().strftime('%b%d_%H-%M-%S') + \".json\")\n",
        "    model_json = model.to_json()\n",
        "    json_file = open(model_filename, \"a\")\n",
        "    json_file.write(model_json)\n",
        "        \n",
        "    # serialize weights to HDF5\n",
        "    model.save_weights(model_filename+\".h5\")\n",
        "\n",
        "############################################################################################"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "FoirLHttLmIp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "17f7aa33-0275-42cb-8e37-66c571f871b7"
      },
      "source": [
        "import tensorflow as tf\n",
        "from keras import activations\n",
        "\n",
        "# Data loader\n",
        "# -----------\n",
        "train_generator, valid_generator = setup_data_generator()\n",
        "\n",
        "epochs = 150\n",
        "\n",
        "transfer_learning = True\n",
        "cnn = True\n",
        "cnn_eval_output = \"\"\n",
        "tl_eval_output = \"\"\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "train_gen ... \n",
            "Found 1247 images belonging to 20 classes.\n",
            "\n",
            "valid_gen ... \n",
            "Found 307 images belonging to 20 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "_NuZaweYLmIt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c641f8e1-3447-49d3-9c28-58c4411cc2ef"
      },
      "source": [
        "###############################################\n",
        "##   Transfer learning\n",
        "if transfer_learning:\n",
        "\n",
        "    # build the VGG16 network\n",
        "    # ------------------------\n",
        "    vgg = tf.keras.applications.VGG16(weights='imagenet',\n",
        "                                      include_top=False,\n",
        "                                      input_shape=input_shape)\n",
        "\n",
        "    vgg.summary()\n",
        "#     print(\"vgg.layers\", vgg.layers)\n",
        "\n",
        "    model_name = 'CNN+TF'\n",
        "\n",
        "    # build a classifier model to put on top of the convolutional model\n",
        "\n",
        "    # Two types of transfer learning: feature extraction and fine-tuning\n",
        "    fine_tuning = True\n",
        "\n",
        "    if fine_tuning:\n",
        "        freeze_until = 8  # layer from which we want to fine-tune\n",
        "\n",
        "        # set the first freeze_until layers (up to the last conv block => depth = 5)\n",
        "        # to non-trainable (weights will not be updated)\n",
        "        for layer in vgg.layers[:freeze_until]:\n",
        "            layer.trainable = False\n",
        "\n",
        "    else:\n",
        "        vgg.trainable = False\n",
        "\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(vgg)\n",
        "    model.add(tf.keras.layers.Flatten())\n",
        "\n",
        "    # dense layers\n",
        "    model.add(tf.keras.layers.Dense(units=512, activation='relu'))\n",
        "    model.add(tf.keras.layers.Dense(units=512, activation='relu'))\n",
        "    model.add(tf.keras.layers.Dense(units=512, activation='relu'))\n",
        "    model.add(tf.keras.layers.Dense(units=512, activation='relu'))\n",
        "    model.add(tf.keras.layers.Dense(units=512, activation='relu'))\n",
        "    model.add(tf.keras.layers.Dense(units=512, activation='relu'))\n",
        "\n",
        "    # final layer with softmax activation\n",
        "    model.add(tf.keras.layers.Dense(units=num_classes, activation='softmax'))\n",
        "\n",
        "    # Visualize created model as a table\n",
        "    # model.summary()\n",
        "\n",
        "    # Visualize initialized weights\n",
        "    # print(\"model.weights\", model.weights)\n",
        "\n",
        "    # Prepare the model for training\n",
        "    # ------------------------------\n",
        "    loss = tf.keras.losses.CategoricalCrossentropy()\n",
        "\n",
        "    # learning rate\n",
        "    lr = 1e-4\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n",
        "\n",
        "    metrics = ['accuracy']  # validation metrics to monitor\n",
        "\n",
        "    model.compile(optimizer=optimizer,\n",
        "                  loss=loss,\n",
        "                  metrics=metrics)\n",
        "\n",
        "    step_size_train = train_generator.n // train_generator.batch_size\n",
        "    trained_model = model.fit_generator(generator=train_generator,\n",
        "                                        steps_per_epoch=step_size_train,\n",
        "                                        epochs=epochs)\n",
        "\n",
        "#     print('\\nhistory dict:', trained_model.history)\n",
        "\n",
        "\n",
        "    # Model evaluation\n",
        "    # ----------------\n",
        "\n",
        "    eval_out = model.evaluate_generator(valid_generator,\n",
        "                                        steps=len(valid_generator),\n",
        "                                        verbose=0)\n",
        "\n",
        "    print('eval_out', eval_out)\n",
        "    \n",
        "    # /content/drive/My Drive/Colab Notebooks\n",
        "    save_model('/content/drive/My Drive/Colab Notebooks', model, model_name)\n",
        "   \n",
        "    # Check Performance\n",
        "    # visualize_performance(trained_model)\n",
        "\n",
        "    # Generate predictions\n",
        "    # -------------------\n",
        "    generate_predictions(model, model_name)\n",
        "    "
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_8 (InputLayer)         [(None, 256, 256, 3)]     0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 256, 256, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 256, 256, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 128, 128, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 128, 128, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 128, 128, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 64, 64, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 64, 64, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 64, 64, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 64, 64, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 32, 32, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 32, 32, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 32, 32, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 32, 32, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 16, 16, 512)       0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 8, 8, 512)         0         \n",
            "=================================================================\n",
            "Total params: 14,714,688\n",
            "Trainable params: 14,714,688\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/150\n",
            "77/77 [==============================] - 62s 811ms/step - loss: 2.6504 - accuracy: 0.1795\n",
            "Epoch 2/150\n",
            "77/77 [==============================] - 62s 802ms/step - loss: 1.8909 - accuracy: 0.3867\n",
            "Epoch 3/150\n",
            "77/77 [==============================] - 62s 801ms/step - loss: 1.4347 - accuracy: 0.5402\n",
            "Epoch 4/150\n",
            "77/77 [==============================] - 62s 802ms/step - loss: 1.1848 - accuracy: 0.6255\n",
            "Epoch 5/150\n",
            "77/77 [==============================] - 62s 801ms/step - loss: 0.9522 - accuracy: 0.6954\n",
            "Epoch 6/150\n",
            "77/77 [==============================] - 62s 802ms/step - loss: 0.8551 - accuracy: 0.7256\n",
            "Epoch 7/150\n",
            "77/77 [==============================] - 62s 801ms/step - loss: 0.7584 - accuracy: 0.7715\n",
            "Epoch 8/150\n",
            "77/77 [==============================] - 62s 800ms/step - loss: 0.6766 - accuracy: 0.7929\n",
            "Epoch 9/150\n",
            "77/77 [==============================] - 62s 799ms/step - loss: 0.6251 - accuracy: 0.8042\n",
            "Epoch 10/150\n",
            "77/77 [==============================] - 62s 801ms/step - loss: 0.5650 - accuracy: 0.8205\n",
            "Epoch 11/150\n",
            "77/77 [==============================] - 62s 799ms/step - loss: 0.4725 - accuracy: 0.8554\n",
            "Epoch 12/150\n",
            "77/77 [==============================] - 62s 799ms/step - loss: 0.5143 - accuracy: 0.8424\n",
            "Epoch 13/150\n",
            "77/77 [==============================] - 62s 800ms/step - loss: 0.4995 - accuracy: 0.8351\n",
            "Epoch 14/150\n",
            "77/77 [==============================] - 62s 800ms/step - loss: 0.4533 - accuracy: 0.8603\n",
            "Epoch 15/150\n",
            "77/77 [==============================] - 62s 799ms/step - loss: 0.5577 - accuracy: 0.8343\n",
            "Epoch 16/150\n",
            "77/77 [==============================] - 62s 800ms/step - loss: 0.4214 - accuracy: 0.8749\n",
            "Epoch 17/150\n",
            "77/77 [==============================] - 62s 799ms/step - loss: 0.3787 - accuracy: 0.8830\n",
            "Epoch 18/150\n",
            "77/77 [==============================] - 62s 799ms/step - loss: 0.3182 - accuracy: 0.8928\n",
            "Epoch 19/150\n",
            "77/77 [==============================] - 62s 801ms/step - loss: 0.3845 - accuracy: 0.8799\n",
            "Epoch 20/150\n",
            "77/77 [==============================] - 62s 800ms/step - loss: 0.3547 - accuracy: 0.8863\n",
            "Epoch 21/150\n",
            "77/77 [==============================] - 62s 800ms/step - loss: 0.2481 - accuracy: 0.9268\n",
            "Epoch 22/150\n",
            "77/77 [==============================] - 62s 799ms/step - loss: 0.2157 - accuracy: 0.9358\n",
            "Epoch 23/150\n",
            "77/77 [==============================] - 62s 799ms/step - loss: 0.2358 - accuracy: 0.9261\n",
            "Epoch 24/150\n",
            "77/77 [==============================] - 62s 799ms/step - loss: 0.3428 - accuracy: 0.9017\n",
            "Epoch 25/150\n",
            "77/77 [==============================] - 62s 799ms/step - loss: 0.2588 - accuracy: 0.9106\n",
            "Epoch 26/150\n",
            "77/77 [==============================] - 61s 797ms/step - loss: 0.1742 - accuracy: 0.9440\n",
            "Epoch 27/150\n",
            "77/77 [==============================] - 61s 798ms/step - loss: 0.3329 - accuracy: 0.9041\n",
            "Epoch 28/150\n",
            "77/77 [==============================] - 62s 800ms/step - loss: 0.1987 - accuracy: 0.9448\n",
            "Epoch 29/150\n",
            "77/77 [==============================] - 62s 799ms/step - loss: 0.2518 - accuracy: 0.9228\n",
            "Epoch 30/150\n",
            "77/77 [==============================] - 61s 798ms/step - loss: 0.1496 - accuracy: 0.9513\n",
            "Epoch 31/150\n",
            "77/77 [==============================] - 61s 797ms/step - loss: 0.1936 - accuracy: 0.9366\n",
            "Epoch 32/150\n",
            "77/77 [==============================] - 61s 796ms/step - loss: 0.1793 - accuracy: 0.9480\n",
            "Epoch 33/150\n",
            "77/77 [==============================] - 61s 797ms/step - loss: 0.1717 - accuracy: 0.9529\n",
            "Epoch 34/150\n",
            "77/77 [==============================] - 61s 799ms/step - loss: 0.2311 - accuracy: 0.9367\n",
            "Epoch 35/150\n",
            "77/77 [==============================] - 61s 797ms/step - loss: 0.2290 - accuracy: 0.9374\n",
            "Epoch 36/150\n",
            "77/77 [==============================] - 61s 797ms/step - loss: 0.1611 - accuracy: 0.9496\n",
            "Epoch 37/150\n",
            "77/77 [==============================] - 61s 796ms/step - loss: 0.2420 - accuracy: 0.9342\n",
            "Epoch 38/150\n",
            "77/77 [==============================] - 61s 796ms/step - loss: 0.1560 - accuracy: 0.9545\n",
            "Epoch 39/150\n",
            "77/77 [==============================] - 61s 796ms/step - loss: 0.1797 - accuracy: 0.9481\n",
            "Epoch 40/150\n",
            "77/77 [==============================] - 61s 796ms/step - loss: 0.3208 - accuracy: 0.9131\n",
            "Epoch 41/150\n",
            "77/77 [==============================] - 61s 797ms/step - loss: 0.2645 - accuracy: 0.9188\n",
            "Epoch 42/150\n",
            "77/77 [==============================] - 61s 798ms/step - loss: 0.1784 - accuracy: 0.9423\n",
            "Epoch 43/150\n",
            "77/77 [==============================] - 61s 796ms/step - loss: 0.1950 - accuracy: 0.9439\n",
            "Epoch 44/150\n",
            "77/77 [==============================] - 61s 796ms/step - loss: 0.1243 - accuracy: 0.9594\n",
            "Epoch 45/150\n",
            "77/77 [==============================] - 61s 797ms/step - loss: 0.0758 - accuracy: 0.9748\n",
            "Epoch 46/150\n",
            "77/77 [==============================] - 61s 797ms/step - loss: 0.1316 - accuracy: 0.9626\n",
            "Epoch 47/150\n",
            "77/77 [==============================] - 61s 797ms/step - loss: 0.1464 - accuracy: 0.9537\n",
            "Epoch 48/150\n",
            "77/77 [==============================] - 61s 795ms/step - loss: 0.1267 - accuracy: 0.9610\n",
            "Epoch 49/150\n",
            "77/77 [==============================] - 61s 798ms/step - loss: 0.1547 - accuracy: 0.9505\n",
            "Epoch 50/150\n",
            "77/77 [==============================] - 61s 794ms/step - loss: 0.1745 - accuracy: 0.9488\n",
            "Epoch 51/150\n",
            "77/77 [==============================] - 61s 796ms/step - loss: 0.1472 - accuracy: 0.9570\n",
            "Epoch 52/150\n",
            "77/77 [==============================] - 61s 794ms/step - loss: 0.1240 - accuracy: 0.9602\n",
            "Epoch 53/150\n",
            "77/77 [==============================] - 61s 794ms/step - loss: 0.1304 - accuracy: 0.9627\n",
            "Epoch 54/150\n",
            "77/77 [==============================] - 61s 794ms/step - loss: 0.2226 - accuracy: 0.9423\n",
            "Epoch 55/150\n",
            "77/77 [==============================] - 61s 796ms/step - loss: 0.2317 - accuracy: 0.9326\n",
            "Epoch 56/150\n",
            "77/77 [==============================] - 61s 796ms/step - loss: 0.1290 - accuracy: 0.9618\n",
            "Epoch 57/150\n",
            "77/77 [==============================] - 61s 795ms/step - loss: 0.1305 - accuracy: 0.9675\n",
            "Epoch 58/150\n",
            "77/77 [==============================] - 61s 796ms/step - loss: 0.1221 - accuracy: 0.9651\n",
            "Epoch 59/150\n",
            "77/77 [==============================] - 61s 797ms/step - loss: 0.1206 - accuracy: 0.9683\n",
            "Epoch 60/150\n",
            "77/77 [==============================] - 61s 793ms/step - loss: 0.0483 - accuracy: 0.9870\n",
            "Epoch 61/150\n",
            "77/77 [==============================] - 61s 793ms/step - loss: 0.1046 - accuracy: 0.9675\n",
            "Epoch 62/150\n",
            "77/77 [==============================] - 61s 790ms/step - loss: 0.1626 - accuracy: 0.9553\n",
            "Epoch 63/150\n",
            "77/77 [==============================] - 61s 791ms/step - loss: 0.1103 - accuracy: 0.9708\n",
            "Epoch 64/150\n",
            "77/77 [==============================] - 61s 790ms/step - loss: 0.0822 - accuracy: 0.9797\n",
            "Epoch 65/150\n",
            "77/77 [==============================] - 61s 790ms/step - loss: 0.1413 - accuracy: 0.9651\n",
            "Epoch 66/150\n",
            "77/77 [==============================] - 61s 791ms/step - loss: 0.1056 - accuracy: 0.9643\n",
            "Epoch 67/150\n",
            "77/77 [==============================] - 61s 789ms/step - loss: 0.1219 - accuracy: 0.9626\n",
            "Epoch 68/150\n",
            "77/77 [==============================] - 61s 791ms/step - loss: 0.2232 - accuracy: 0.9350\n",
            "Epoch 69/150\n",
            "77/77 [==============================] - 61s 791ms/step - loss: 0.2038 - accuracy: 0.9440\n",
            "Epoch 70/150\n",
            "77/77 [==============================] - 61s 790ms/step - loss: 0.1438 - accuracy: 0.9643\n",
            "Epoch 71/150\n",
            "77/77 [==============================] - 61s 789ms/step - loss: 0.0851 - accuracy: 0.9756\n",
            "Epoch 72/150\n",
            "77/77 [==============================] - 61s 789ms/step - loss: 0.0724 - accuracy: 0.9821\n",
            "Epoch 73/150\n",
            "77/77 [==============================] - 61s 788ms/step - loss: 0.0688 - accuracy: 0.9780\n",
            "Epoch 74/150\n",
            "77/77 [==============================] - 61s 789ms/step - loss: 0.0862 - accuracy: 0.9740\n",
            "Epoch 75/150\n",
            "77/77 [==============================] - 61s 789ms/step - loss: 0.0616 - accuracy: 0.9838\n",
            "Epoch 76/150\n",
            "77/77 [==============================] - 61s 788ms/step - loss: 0.0395 - accuracy: 0.9894\n",
            "Epoch 77/150\n",
            "77/77 [==============================] - 61s 789ms/step - loss: 0.1695 - accuracy: 0.9521\n",
            "Epoch 78/150\n",
            "77/77 [==============================] - 61s 788ms/step - loss: 0.1281 - accuracy: 0.9659\n",
            "Epoch 79/150\n",
            "77/77 [==============================] - 61s 788ms/step - loss: 0.1122 - accuracy: 0.9643\n",
            "Epoch 80/150\n",
            "77/77 [==============================] - 61s 789ms/step - loss: 0.1757 - accuracy: 0.9513\n",
            "Epoch 81/150\n",
            "77/77 [==============================] - 61s 789ms/step - loss: 0.0670 - accuracy: 0.9781\n",
            "Epoch 82/150\n",
            "77/77 [==============================] - 61s 788ms/step - loss: 0.1138 - accuracy: 0.9651\n",
            "Epoch 83/150\n",
            "77/77 [==============================] - 61s 788ms/step - loss: 0.1104 - accuracy: 0.9699\n",
            "Epoch 84/150\n",
            "77/77 [==============================] - 61s 789ms/step - loss: 0.1834 - accuracy: 0.9513\n",
            "Epoch 85/150\n",
            "77/77 [==============================] - 61s 789ms/step - loss: 0.2086 - accuracy: 0.9464\n",
            "Epoch 86/150\n",
            "77/77 [==============================] - 61s 786ms/step - loss: 0.1405 - accuracy: 0.9618\n",
            "Epoch 87/150\n",
            "77/77 [==============================] - 61s 787ms/step - loss: 0.0349 - accuracy: 0.9935\n",
            "Epoch 88/150\n",
            "77/77 [==============================] - 61s 788ms/step - loss: 0.0815 - accuracy: 0.9756\n",
            "Epoch 89/150\n",
            "77/77 [==============================] - 61s 790ms/step - loss: 0.1229 - accuracy: 0.9619\n",
            "Epoch 90/150\n",
            "77/77 [==============================] - 61s 788ms/step - loss: 0.0303 - accuracy: 0.9919\n",
            "Epoch 91/150\n",
            "77/77 [==============================] - 61s 789ms/step - loss: 0.1110 - accuracy: 0.9691\n",
            "Epoch 92/150\n",
            "77/77 [==============================] - 61s 788ms/step - loss: 0.0613 - accuracy: 0.9821\n",
            "Epoch 93/150\n",
            "77/77 [==============================] - 61s 789ms/step - loss: 0.1100 - accuracy: 0.9683\n",
            "Epoch 94/150\n",
            "77/77 [==============================] - 61s 788ms/step - loss: 0.1056 - accuracy: 0.9740\n",
            "Epoch 95/150\n",
            "77/77 [==============================] - 61s 788ms/step - loss: 0.0443 - accuracy: 0.9919\n",
            "Epoch 96/150\n",
            "77/77 [==============================] - 61s 788ms/step - loss: 0.1172 - accuracy: 0.9692\n",
            "Epoch 97/150\n",
            "77/77 [==============================] - 61s 787ms/step - loss: 0.0845 - accuracy: 0.9699\n",
            "Epoch 98/150\n",
            "77/77 [==============================] - 61s 787ms/step - loss: 0.1209 - accuracy: 0.9643\n",
            "Epoch 99/150\n",
            "77/77 [==============================] - 61s 787ms/step - loss: 0.1475 - accuracy: 0.9586\n",
            "Epoch 100/150\n",
            "77/77 [==============================] - 60s 786ms/step - loss: 0.0378 - accuracy: 0.9870\n",
            "Epoch 101/150\n",
            "77/77 [==============================] - 61s 786ms/step - loss: 0.1198 - accuracy: 0.9691\n",
            "Epoch 102/150\n",
            "77/77 [==============================] - 61s 788ms/step - loss: 0.1627 - accuracy: 0.9610\n",
            "Epoch 103/150\n",
            "77/77 [==============================] - 60s 785ms/step - loss: 0.0659 - accuracy: 0.9829\n",
            "Epoch 104/150\n",
            "77/77 [==============================] - 61s 787ms/step - loss: 0.0873 - accuracy: 0.9756\n",
            "Epoch 105/150\n",
            "77/77 [==============================] - 61s 786ms/step - loss: 0.0784 - accuracy: 0.9797\n",
            "Epoch 106/150\n",
            "77/77 [==============================] - 61s 787ms/step - loss: 0.1015 - accuracy: 0.9716\n",
            "Epoch 107/150\n",
            "77/77 [==============================] - 60s 786ms/step - loss: 0.2757 - accuracy: 0.9423\n",
            "Epoch 108/150\n",
            "77/77 [==============================] - 61s 788ms/step - loss: 0.1322 - accuracy: 0.9577\n",
            "Epoch 109/150\n",
            "77/77 [==============================] - 61s 787ms/step - loss: 0.0635 - accuracy: 0.9854\n",
            "Epoch 110/150\n",
            "77/77 [==============================] - 61s 787ms/step - loss: 0.0702 - accuracy: 0.9781\n",
            "Epoch 111/150\n",
            "77/77 [==============================] - 60s 786ms/step - loss: 0.0390 - accuracy: 0.9854\n",
            "Epoch 112/150\n",
            "77/77 [==============================] - 61s 786ms/step - loss: 0.0426 - accuracy: 0.9854\n",
            "Epoch 113/150\n",
            "77/77 [==============================] - 60s 785ms/step - loss: 0.1786 - accuracy: 0.9504\n",
            "Epoch 114/150\n",
            "77/77 [==============================] - 61s 786ms/step - loss: 0.0536 - accuracy: 0.9862\n",
            "Epoch 115/150\n",
            "77/77 [==============================] - 60s 784ms/step - loss: 0.1577 - accuracy: 0.9650\n",
            "Epoch 116/150\n",
            "77/77 [==============================] - 60s 785ms/step - loss: 0.2029 - accuracy: 0.9562\n",
            "Epoch 117/150\n",
            "77/77 [==============================] - 60s 784ms/step - loss: 0.0727 - accuracy: 0.9813\n",
            "Epoch 118/150\n",
            "77/77 [==============================] - 60s 784ms/step - loss: 0.0336 - accuracy: 0.9903\n",
            "Epoch 119/150\n",
            "77/77 [==============================] - 60s 784ms/step - loss: 0.0721 - accuracy: 0.9797\n",
            "Epoch 120/150\n",
            "77/77 [==============================] - 60s 782ms/step - loss: 0.0812 - accuracy: 0.9813\n",
            "Epoch 121/150\n",
            "77/77 [==============================] - 60s 783ms/step - loss: 0.0677 - accuracy: 0.9838\n",
            "Epoch 122/150\n",
            "77/77 [==============================] - 60s 785ms/step - loss: 0.0764 - accuracy: 0.9781\n",
            "Epoch 123/150\n",
            "77/77 [==============================] - 61s 787ms/step - loss: 0.0784 - accuracy: 0.9756\n",
            "Epoch 124/150\n",
            "77/77 [==============================] - 61s 787ms/step - loss: 0.0855 - accuracy: 0.9756\n",
            "Epoch 125/150\n",
            "77/77 [==============================] - 60s 785ms/step - loss: 0.0407 - accuracy: 0.9854\n",
            "Epoch 126/150\n",
            "77/77 [==============================] - 60s 785ms/step - loss: 0.0231 - accuracy: 0.9935\n",
            "Epoch 127/150\n",
            "77/77 [==============================] - 60s 784ms/step - loss: 0.0495 - accuracy: 0.9862\n",
            "Epoch 128/150\n",
            "77/77 [==============================] - 60s 784ms/step - loss: 0.0977 - accuracy: 0.9748\n",
            "Epoch 129/150\n",
            "77/77 [==============================] - 60s 784ms/step - loss: 0.0752 - accuracy: 0.9716\n",
            "Epoch 130/150\n",
            "77/77 [==============================] - 60s 785ms/step - loss: 0.0902 - accuracy: 0.9699\n",
            "Epoch 131/150\n",
            "77/77 [==============================] - 61s 787ms/step - loss: 0.1058 - accuracy: 0.9740\n",
            "Epoch 132/150\n",
            "77/77 [==============================] - 61s 786ms/step - loss: 0.0924 - accuracy: 0.9772\n",
            "Epoch 133/150\n",
            "77/77 [==============================] - 60s 784ms/step - loss: 0.0602 - accuracy: 0.9821\n",
            "Epoch 134/150\n",
            "77/77 [==============================] - 60s 785ms/step - loss: 0.0430 - accuracy: 0.9862\n",
            "Epoch 135/150\n",
            "77/77 [==============================] - 60s 783ms/step - loss: 0.0674 - accuracy: 0.9797\n",
            "Epoch 136/150\n",
            "77/77 [==============================] - 60s 784ms/step - loss: 0.0430 - accuracy: 0.9870\n",
            "Epoch 137/150\n",
            "77/77 [==============================] - 60s 786ms/step - loss: 0.1371 - accuracy: 0.9716\n",
            "Epoch 138/150\n",
            "77/77 [==============================] - 60s 782ms/step - loss: 0.0490 - accuracy: 0.9886\n",
            "Epoch 139/150\n",
            "77/77 [==============================] - 60s 784ms/step - loss: 0.0828 - accuracy: 0.9781\n",
            "Epoch 140/150\n",
            "77/77 [==============================] - 60s 784ms/step - loss: 0.1363 - accuracy: 0.9602\n",
            "Epoch 141/150\n",
            "77/77 [==============================] - 60s 784ms/step - loss: 0.0857 - accuracy: 0.9724\n",
            "Epoch 142/150\n",
            "77/77 [==============================] - 60s 782ms/step - loss: 0.0529 - accuracy: 0.9878\n",
            "Epoch 143/150\n",
            "77/77 [==============================] - 60s 784ms/step - loss: 0.2128 - accuracy: 0.9440\n",
            "Epoch 144/150\n",
            "77/77 [==============================] - 60s 783ms/step - loss: 0.0678 - accuracy: 0.9821\n",
            "Epoch 145/150\n",
            "77/77 [==============================] - 60s 782ms/step - loss: 0.0855 - accuracy: 0.9773\n",
            "Epoch 146/150\n",
            "77/77 [==============================] - 60s 782ms/step - loss: 0.0736 - accuracy: 0.9789\n",
            "Epoch 147/150\n",
            "77/77 [==============================] - 60s 782ms/step - loss: 0.1366 - accuracy: 0.9716\n",
            "Epoch 148/150\n",
            "77/77 [==============================] - 60s 781ms/step - loss: 0.0451 - accuracy: 0.9870\n",
            "Epoch 149/150\n",
            "77/77 [==============================] - 60s 782ms/step - loss: 0.0762 - accuracy: 0.9789\n",
            "Epoch 150/150\n",
            "77/77 [==============================] - 60s 781ms/step - loss: 0.0739 - accuracy: 0.9862\n",
            "eval_out [0.8480327092111111, 0.80456024]\n",
            "prediction for IMG_1589.jpg...\n",
            "prediction for IMG_299.jpg...\n",
            "prediction for IMG_1307.jpg...\n",
            "prediction for IMG_264.jpg...\n",
            "prediction for IMG_1501.jpg...\n",
            "prediction for IMG_2017.jpg...\n",
            "prediction for IMG_455.jpg...\n",
            "prediction for IMG_329.jpg...\n",
            "prediction for IMG_815.jpg...\n",
            "prediction for IMG_664.jpg...\n",
            "prediction for IMG_113.jpg...\n",
            "prediction for IMG_682.jpg...\n",
            "prediction for IMG_59.jpg...\n",
            "prediction for IMG_497.jpg...\n",
            "prediction for IMG_1382.jpg...\n",
            "prediction for IMG_1322.jpg...\n",
            "prediction for IMG_877.jpg...\n",
            "prediction for IMG_837.jpg...\n",
            "prediction for IMG_1771.jpg...\n",
            "prediction for IMG_117.jpg...\n",
            "prediction for IMG_1429.jpg...\n",
            "prediction for IMG_1620.jpg...\n",
            "prediction for IMG_1907.jpg...\n",
            "prediction for IMG_1289.jpg...\n",
            "prediction for IMG_420.jpg...\n",
            "prediction for IMG_1219.jpg...\n",
            "prediction for IMG_1197.jpg...\n",
            "prediction for IMG_234.jpg...\n",
            "prediction for IMG_1543.jpg...\n",
            "prediction for IMG_2023.jpg...\n",
            "prediction for IMG_2052.jpg...\n",
            "prediction for IMG_2041.jpg...\n",
            "prediction for IMG_106.jpg...\n",
            "prediction for IMG_635.jpg...\n",
            "prediction for IMG_1890.jpg...\n",
            "prediction for IMG_1808.jpg...\n",
            "prediction for IMG_249.jpg...\n",
            "prediction for IMG_1334.jpg...\n",
            "prediction for IMG_1820.jpg...\n",
            "prediction for IMG_1444.jpg...\n",
            "prediction for IMG_1728.jpg...\n",
            "prediction for IMG_296.jpg...\n",
            "prediction for IMG_1080.jpg...\n",
            "prediction for IMG_58.jpg...\n",
            "prediction for IMG_1084.jpg...\n",
            "prediction for IMG_1854.jpg...\n",
            "prediction for IMG_845.jpg...\n",
            "prediction for IMG_1459.jpg...\n",
            "prediction for IMG_1871.jpg...\n",
            "prediction for IMG_1280.jpg...\n",
            "prediction for IMG_695.jpg...\n",
            "prediction for IMG_397.jpg...\n",
            "prediction for IMG_1342.jpg...\n",
            "prediction for IMG_2047.jpg...\n",
            "prediction for IMG_1042.jpg...\n",
            "prediction for IMG_2010.jpg...\n",
            "prediction for IMG_1849.jpg...\n",
            "prediction for IMG_1819.jpg...\n",
            "prediction for IMG_2007.jpg...\n",
            "prediction for IMG_37.jpg...\n",
            "prediction for IMG_1657.jpg...\n",
            "prediction for IMG_1117.jpg...\n",
            "prediction for IMG_1538.jpg...\n",
            "prediction for IMG_19.jpg...\n",
            "prediction for IMG_1031.jpg...\n",
            "prediction for IMG_1466.jpg...\n",
            "prediction for IMG_712.jpg...\n",
            "prediction for IMG_932.jpg...\n",
            "prediction for IMG_1560.jpg...\n",
            "prediction for IMG_480.jpg...\n",
            "prediction for IMG_2042.jpg...\n",
            "prediction for IMG_1229.jpg...\n",
            "prediction for IMG_485.jpg...\n",
            "prediction for IMG_1546.jpg...\n",
            "prediction for IMG_1744.jpg...\n",
            "prediction for IMG_1741.jpg...\n",
            "prediction for IMG_1551.jpg...\n",
            "prediction for IMG_2005.jpg...\n",
            "prediction for IMG_513.jpg...\n",
            "prediction for IMG_1798.jpg...\n",
            "prediction for IMG_2018.jpg...\n",
            "prediction for IMG_1206.jpg...\n",
            "prediction for IMG_1276.jpg...\n",
            "prediction for IMG_1919.jpg...\n",
            "prediction for IMG_1509.jpg...\n",
            "prediction for IMG_66.jpg...\n",
            "prediction for IMG_1011.jpg...\n",
            "prediction for IMG_467.jpg...\n",
            "prediction for IMG_1264.jpg...\n",
            "prediction for IMG_2031.jpg...\n",
            "prediction for IMG_1194.jpg...\n",
            "prediction for IMG_1831.jpg...\n",
            "prediction for IMG_1646.jpg...\n",
            "prediction for IMG_1283.jpg...\n",
            "prediction for IMG_233.jpg...\n",
            "prediction for IMG_1500.jpg...\n",
            "prediction for IMG_1979.jpg...\n",
            "prediction for IMG_603.jpg...\n",
            "prediction for IMG_1991.jpg...\n",
            "prediction for IMG_717.jpg...\n",
            "prediction for IMG_1622.jpg...\n",
            "prediction for IMG_1359.jpg...\n",
            "prediction for IMG_1452.jpg...\n",
            "prediction for IMG_606.jpg...\n",
            "prediction for IMG_873.jpg...\n",
            "prediction for IMG_543.jpg...\n",
            "prediction for IMG_1183.jpg...\n",
            "prediction for IMG_572.jpg...\n",
            "prediction for IMG_1971.jpg...\n",
            "prediction for IMG_607.jpg...\n",
            "prediction for IMG_1187.jpg...\n",
            "prediction for IMG_938.jpg...\n",
            "prediction for IMG_1377.jpg...\n",
            "prediction for IMG_813.jpg...\n",
            "prediction for IMG_1155.jpg...\n",
            "prediction for IMG_616.jpg...\n",
            "prediction for IMG_551.jpg...\n",
            "prediction for IMG_89.jpg...\n",
            "prediction for IMG_1436.jpg...\n",
            "prediction for IMG_645.jpg...\n",
            "prediction for IMG_278.jpg...\n",
            "prediction for IMG_1370.jpg...\n",
            "prediction for IMG_1137.jpg...\n",
            "prediction for IMG_68.jpg...\n",
            "prediction for IMG_478.jpg...\n",
            "prediction for IMG_312.jpg...\n",
            "prediction for IMG_917.jpg...\n",
            "prediction for IMG_1101.jpg...\n",
            "prediction for IMG_826.jpg...\n",
            "prediction for IMG_473.jpg...\n",
            "prediction for IMG_404.jpg...\n",
            "prediction for IMG_1575.jpg...\n",
            "prediction for IMG_1023.jpg...\n",
            "prediction for IMG_744.jpg...\n",
            "prediction for IMG_308.jpg...\n",
            "prediction for IMG_1330.jpg...\n",
            "prediction for IMG_6.jpg...\n",
            "prediction for IMG_1664.jpg...\n",
            "prediction for IMG_1915.jpg...\n",
            "prediction for IMG_561.jpg...\n",
            "prediction for IMG_982.jpg...\n",
            "prediction for IMG_270.jpg...\n",
            "prediction for IMG_1684.jpg...\n",
            "prediction for IMG_1541.jpg...\n",
            "prediction for IMG_1929.jpg...\n",
            "prediction for IMG_844.jpg...\n",
            "prediction for IMG_805.jpg...\n",
            "prediction for IMG_1052.jpg...\n",
            "prediction for IMG_72.jpg...\n",
            "prediction for IMG_1238.jpg...\n",
            "prediction for IMG_775.jpg...\n",
            "prediction for IMG_1406.jpg...\n",
            "prediction for IMG_1209.jpg...\n",
            "prediction for IMG_322.jpg...\n",
            "prediction for IMG_1046.jpg...\n",
            "prediction for IMG_405.jpg...\n",
            "prediction for IMG_722.jpg...\n",
            "prediction for IMG_1235.jpg...\n",
            "prediction for IMG_1989.jpg...\n",
            "prediction for IMG_1419.jpg...\n",
            "prediction for IMG_1384.jpg...\n",
            "prediction for IMG_383.jpg...\n",
            "prediction for IMG_1494.jpg...\n",
            "prediction for IMG_1591.jpg...\n",
            "prediction for IMG_1645.jpg...\n",
            "prediction for IMG_1442.jpg...\n",
            "prediction for IMG_261.jpg...\n",
            "prediction for IMG_1354.jpg...\n",
            "prediction for IMG_1799.jpg...\n",
            "prediction for IMG_647.jpg...\n",
            "prediction for IMG_217.jpg...\n",
            "prediction for IMG_880.jpg...\n",
            "prediction for IMG_702.jpg...\n",
            "prediction for IMG_384.jpg...\n",
            "prediction for IMG_708.jpg...\n",
            "prediction for IMG_1768.jpg...\n",
            "prediction for IMG_621.jpg...\n",
            "prediction for IMG_1811.jpg...\n",
            "prediction for IMG_400.jpg...\n",
            "prediction for IMG_1882.jpg...\n",
            "prediction for IMG_1420.jpg...\n",
            "prediction for IMG_1474.jpg...\n",
            "prediction for IMG_755.jpg...\n",
            "prediction for IMG_105.jpg...\n",
            "prediction for IMG_706.jpg...\n",
            "prediction for IMG_1308.jpg...\n",
            "prediction for IMG_923.jpg...\n",
            "prediction for IMG_592.jpg...\n",
            "prediction for IMG_876.jpg...\n",
            "prediction for IMG_671.jpg...\n",
            "prediction for IMG_823.jpg...\n",
            "prediction for IMG_709.jpg...\n",
            "prediction for IMG_1468.jpg...\n",
            "prediction for IMG_451.jpg...\n",
            "prediction for IMG_1814.jpg...\n",
            "prediction for IMG_206.jpg...\n",
            "prediction for IMG_223.jpg...\n",
            "prediction for IMG_119.jpg...\n",
            "prediction for IMG_144.jpg...\n",
            "prediction for IMG_195.jpg...\n",
            "prediction for IMG_1495.jpg...\n",
            "prediction for IMG_986.jpg...\n",
            "prediction for IMG_1618.jpg...\n",
            "prediction for IMG_273.jpg...\n",
            "prediction for IMG_785.jpg...\n",
            "prediction for IMG_1090.jpg...\n",
            "prediction for IMG_914.jpg...\n",
            "prediction for IMG_379.jpg...\n",
            "prediction for IMG_802.jpg...\n",
            "prediction for IMG_1232.jpg...\n",
            "prediction for IMG_1158.jpg...\n",
            "prediction for IMG_1147.jpg...\n",
            "prediction for IMG_1349.jpg...\n",
            "prediction for IMG_739.jpg...\n",
            "prediction for IMG_542.jpg...\n",
            "prediction for IMG_679.jpg...\n",
            "prediction for IMG_1842.jpg...\n",
            "prediction for IMG_1703.jpg...\n",
            "prediction for IMG_1094.jpg...\n",
            "prediction for IMG_835.jpg...\n",
            "prediction for IMG_421.jpg...\n",
            "prediction for IMG_67.jpg...\n",
            "prediction for IMG_121.jpg...\n",
            "prediction for IMG_912.jpg...\n",
            "prediction for IMG_1723.jpg...\n",
            "prediction for IMG_1483.jpg...\n",
            "prediction for IMG_31.jpg...\n",
            "prediction for IMG_48.jpg...\n",
            "prediction for IMG_53.jpg...\n",
            "prediction for IMG_1978.jpg...\n",
            "prediction for IMG_183.jpg...\n",
            "prediction for IMG_293.jpg...\n",
            "prediction for IMG_220.jpg...\n",
            "prediction for IMG_1966.jpg...\n",
            "prediction for IMG_752.jpg...\n",
            "prediction for IMG_1217.jpg...\n",
            "prediction for IMG_967.jpg...\n",
            "prediction for IMG_245.jpg...\n",
            "prediction for IMG_546.jpg...\n",
            "prediction for IMG_1422.jpg...\n",
            "prediction for IMG_74.jpg...\n",
            "prediction for IMG_96.jpg...\n",
            "prediction for IMG_794.jpg...\n",
            "prediction for IMG_1127.jpg...\n",
            "prediction for IMG_1661.jpg...\n",
            "prediction for IMG_1883.jpg...\n",
            "prediction for IMG_691.jpg...\n",
            "prediction for IMG_338.jpg...\n",
            "prediction for IMG_1858.jpg...\n",
            "prediction for IMG_1344.jpg...\n",
            "prediction for IMG_69.jpg...\n",
            "prediction for IMG_1865.jpg...\n",
            "prediction for IMG_581.jpg...\n",
            "prediction for IMG_285.jpg...\n",
            "prediction for IMG_1475.jpg...\n",
            "prediction for IMG_272.jpg...\n",
            "prediction for IMG_1734.jpg...\n",
            "prediction for IMG_1918.jpg...\n",
            "prediction for IMG_1544.jpg...\n",
            "prediction for IMG_674.jpg...\n",
            "prediction for IMG_1650.jpg...\n",
            "prediction for IMG_32.jpg...\n",
            "prediction for IMG_1593.jpg...\n",
            "prediction for IMG_597.jpg...\n",
            "prediction for IMG_1059.jpg...\n",
            "prediction for IMG_601.jpg...\n",
            "prediction for IMG_1214.jpg...\n",
            "prediction for IMG_0.jpg...\n",
            "prediction for IMG_487.jpg...\n",
            "prediction for IMG_1071.jpg...\n",
            "prediction for IMG_263.jpg...\n",
            "prediction for IMG_1826.jpg...\n",
            "prediction for IMG_298.jpg...\n",
            "prediction for IMG_1339.jpg...\n",
            "prediction for IMG_803.jpg...\n",
            "prediction for IMG_1961.jpg...\n",
            "prediction for IMG_35.jpg...\n",
            "prediction for IMG_1001.jpg...\n",
            "prediction for IMG_123.jpg...\n",
            "prediction for IMG_1899.jpg...\n",
            "prediction for IMG_2020.jpg...\n",
            "prediction for IMG_608.jpg...\n",
            "prediction for IMG_1603.jpg...\n",
            "prediction for IMG_280.jpg...\n",
            "prediction for IMG_267.jpg...\n",
            "prediction for IMG_2053.jpg...\n",
            "prediction for IMG_1240.jpg...\n",
            "prediction for IMG_167.jpg...\n",
            "prediction for IMG_887.jpg...\n",
            "prediction for IMG_1058.jpg...\n",
            "prediction for IMG_1143.jpg...\n",
            "prediction for IMG_104.jpg...\n",
            "prediction for IMG_922.jpg...\n",
            "prediction for IMG_535.jpg...\n",
            "prediction for IMG_852.jpg...\n",
            "prediction for IMG_952.jpg...\n",
            "prediction for IMG_756.jpg...\n",
            "prediction for IMG_797.jpg...\n",
            "prediction for IMG_1706.jpg...\n",
            "prediction for IMG_134.jpg...\n",
            "prediction for IMG_897.jpg...\n",
            "prediction for IMG_1623.jpg...\n",
            "prediction for IMG_1941.jpg...\n",
            "prediction for IMG_517.jpg...\n",
            "prediction for IMG_1179.jpg...\n",
            "prediction for IMG_959.jpg...\n",
            "prediction for IMG_1892.jpg...\n",
            "prediction for IMG_1346.jpg...\n",
            "prediction for IMG_1506.jpg...\n",
            "prediction for IMG_1552.jpg...\n",
            "prediction for IMG_1511.jpg...\n",
            "prediction for IMG_598.jpg...\n",
            "prediction for IMG_558.jpg...\n",
            "prediction for IMG_1502.jpg...\n",
            "prediction for IMG_1199.jpg...\n",
            "prediction for IMG_1242.jpg...\n",
            "prediction for IMG_1936.jpg...\n",
            "prediction for IMG_710.jpg...\n",
            "prediction for IMG_884.jpg...\n",
            "prediction for IMG_355.jpg...\n",
            "prediction for IMG_1228.jpg...\n",
            "prediction for IMG_878.jpg...\n",
            "prediction for IMG_1074.jpg...\n",
            "prediction for IMG_214.jpg...\n",
            "prediction for IMG_1600.jpg...\n",
            "prediction for IMG_907.jpg...\n",
            "prediction for IMG_1908.jpg...\n",
            "prediction for IMG_893.jpg...\n",
            "prediction for IMG_563.jpg...\n",
            "prediction for IMG_956.jpg...\n",
            "prediction for IMG_703.jpg...\n",
            "prediction for IMG_1119.jpg...\n",
            "prediction for IMG_129.jpg...\n",
            "prediction for IMG_1803.jpg...\n",
            "prediction for IMG_864.jpg...\n",
            "prediction for IMG_867.jpg...\n",
            "prediction for IMG_1609.jpg...\n",
            "prediction for IMG_828.jpg...\n",
            "prediction for IMG_1949.jpg...\n",
            "prediction for IMG_1604.jpg...\n",
            "prediction for IMG_1674.jpg...\n",
            "prediction for IMG_51.jpg...\n",
            "prediction for IMG_34.jpg...\n",
            "prediction for IMG_1851.jpg...\n",
            "prediction for IMG_1512.jpg...\n",
            "prediction for IMG_705.jpg...\n",
            "prediction for IMG_174.jpg...\n",
            "prediction for IMG_1241.jpg...\n",
            "prediction for IMG_2000.jpg...\n",
            "prediction for IMG_1977.jpg...\n",
            "prediction for IMG_904.jpg...\n",
            "prediction for IMG_1050.jpg...\n",
            "prediction for IMG_1852.jpg...\n",
            "prediction for IMG_30.jpg...\n",
            "prediction for IMG_942.jpg...\n",
            "prediction for IMG_461.jpg...\n",
            "prediction for IMG_1536.jpg...\n",
            "prediction for IMG_1462.jpg...\n",
            "prediction for IMG_1912.jpg...\n",
            "prediction for IMG_1878.jpg...\n",
            "prediction for IMG_1172.jpg...\n",
            "prediction for IMG_159.jpg...\n",
            "prediction for IMG_582.jpg...\n",
            "prediction for IMG_1780.jpg...\n",
            "prediction for IMG_371.jpg...\n",
            "prediction for IMG_269.jpg...\n",
            "prediction for IMG_2021.jpg...\n",
            "prediction for IMG_1885.jpg...\n",
            "prediction for IMG_1901.jpg...\n",
            "prediction for IMG_1836.jpg...\n",
            "prediction for IMG_999.jpg...\n",
            "prediction for IMG_1437.jpg...\n",
            "prediction for IMG_1516.jpg...\n",
            "prediction for IMG_135.jpg...\n",
            "prediction for IMG_1962.jpg...\n",
            "prediction for IMG_227.jpg...\n",
            "prediction for IMG_1363.jpg...\n",
            "prediction for IMG_295.jpg...\n",
            "prediction for IMG_913.jpg...\n",
            "prediction for IMG_137.jpg...\n",
            "prediction for IMG_2025.jpg...\n",
            "prediction for IMG_136.jpg...\n",
            "prediction for IMG_98.jpg...\n",
            "prediction for IMG_1699.jpg...\n",
            "prediction for IMG_279.jpg...\n",
            "prediction for IMG_1306.jpg...\n",
            "prediction for IMG_602.jpg...\n",
            "prediction for IMG_550.jpg...\n",
            "prediction for IMG_367.jpg...\n",
            "prediction for IMG_583.jpg...\n",
            "prediction for IMG_1713.jpg...\n",
            "prediction for IMG_641.jpg...\n",
            "prediction for IMG_567.jpg...\n",
            "prediction for IMG_163.jpg...\n",
            "prediction for IMG_1213.jpg...\n",
            "prediction for IMG_92.jpg...\n",
            "prediction for IMG_943.jpg...\n",
            "prediction for IMG_1415.jpg...\n",
            "prediction for IMG_1872.jpg...\n",
            "prediction for IMG_262.jpg...\n",
            "prediction for IMG_1270.jpg...\n",
            "prediction for IMG_1550.jpg...\n",
            "prediction for IMG_1133.jpg...\n",
            "prediction for IMG_1211.jpg...\n",
            "prediction for IMG_1073.jpg...\n",
            "prediction for IMG_515.jpg...\n",
            "prediction for IMG_1163.jpg...\n",
            "prediction for IMG_1532.jpg...\n",
            "prediction for IMG_848.jpg...\n",
            "prediction for IMG_1268.jpg...\n",
            "prediction for IMG_240.jpg...\n",
            "prediction for IMG_539.jpg...\n",
            "prediction for IMG_660.jpg...\n",
            "prediction for IMG_252.jpg...\n",
            "prediction for IMG_1174.jpg...\n",
            "prediction for IMG_1435.jpg...\n",
            "prediction for IMG_862.jpg...\n",
            "prediction for IMG_1756.jpg...\n",
            "prediction for IMG_791.jpg...\n",
            "prediction for IMG_1481.jpg...\n",
            "prediction for IMG_410.jpg...\n",
            "prediction for IMG_1148.jpg...\n",
            "prediction for IMG_1251.jpg...\n",
            "prediction for IMG_1982.jpg...\n",
            "prediction for IMG_153.jpg...\n",
            "prediction for IMG_1659.jpg...\n",
            "prediction for IMG_1248.jpg...\n",
            "prediction for IMG_1902.jpg...\n",
            "prediction for IMG_764.jpg...\n",
            "prediction for IMG_1318.jpg...\n",
            "prediction for IMG_1557.jpg...\n",
            "prediction for IMG_1975.jpg...\n",
            "prediction for IMG_1529.jpg...\n",
            "prediction for IMG_866.jpg...\n",
            "prediction for IMG_169.jpg...\n",
            "prediction for IMG_1520.jpg...\n",
            "prediction for IMG_24.jpg...\n",
            "prediction for IMG_965.jpg...\n",
            "prediction for IMG_512.jpg...\n",
            "prediction for IMG_1480.jpg...\n",
            "prediction for IMG_505.jpg...\n",
            "prediction for IMG_1035.jpg...\n",
            "prediction for IMG_789.jpg...\n",
            "prediction for IMG_667.jpg...\n",
            "prediction for IMG_385.jpg...\n",
            "prediction for IMG_1212.jpg...\n",
            "prediction for IMG_1037.jpg...\n",
            "prediction for IMG_588.jpg...\n",
            "prediction for IMG_524.jpg...\n",
            "prediction for IMG_711.jpg...\n",
            "prediction for IMG_94.jpg...\n",
            "prediction for IMG_1397.jpg...\n",
            "prediction for IMG_151.jpg...\n",
            "prediction for IMG_1764.jpg...\n",
            "prediction for IMG_1202.jpg...\n",
            "prediction for IMG_1099.jpg...\n",
            "prediction for IMG_1285.jpg...\n",
            "prediction for IMG_1643.jpg...\n",
            "prediction for IMG_1072.jpg...\n",
            "prediction for IMG_1837.jpg...\n",
            "prediction for IMG_1298.jpg...\n",
            "prediction for IMG_1196.jpg...\n",
            "prediction for IMG_730.jpg...\n",
            "prediction for IMG_228.jpg...\n",
            "prediction for IMG_919.jpg...\n",
            "prediction for IMG_1007.jpg...\n",
            "prediction for IMG_1761.jpg...\n",
            "prediction for IMG_507.jpg...\n",
            "prediction for IMG_237.jpg...\n",
            "prediction for IMG_1628.jpg...\n",
            "prediction for IMG_681.jpg...\n",
            "prediction for IMG_61.jpg...\n",
            "prediction for IMG_817.jpg...\n",
            "prediction for IMG_175.jpg...\n",
            "prediction for IMG_1449.jpg...\n",
            "prediction for IMG_1633.jpg...\n",
            "prediction for IMG_1923.jpg...\n",
            "prediction for IMG_307.jpg...\n",
            "prediction for IMG_13.jpg...\n",
            "prediction for IMG_950.jpg...\n",
            "prediction for IMG_727.jpg...\n",
            "prediction for IMG_423.jpg...\n",
            "prediction for IMG_1097.jpg...\n",
            "prediction for IMG_501.jpg...\n",
            "prediction for IMG_1484.jpg...\n",
            "prediction for IMG_414.jpg...\n",
            "prediction for IMG_251.jpg...\n",
            "prediction for IMG_377.jpg...\n",
            "prediction for IMG_1909.jpg...\n",
            "prediction for IMG_508.jpg...\n",
            "prediction for IMG_57.jpg...\n",
            "prediction for IMG_944.jpg...\n",
            "prediction for IMG_1747.jpg...\n",
            "prediction for IMG_321.jpg...\n",
            "prediction for IMG_638.jpg...\n",
            "prediction for IMG_1813.jpg...\n",
            "prediction for IMG_499.jpg...\n",
            "prediction for IMG_1935.jpg...\n",
            "prediction for IMG_1709.jpg...\n",
            "prediction for IMG_1802.jpg...\n",
            "\n",
            "Generating submission csv ... \n",
            "{'IMG_0.jpg': 'sword',\n",
            " 'IMG_1001.jpg': 'bear',\n",
            " 'IMG_1007.jpg': 'fireworks',\n",
            " 'IMG_1011.jpg': 'computer-monitor',\n",
            " 'IMG_1023.jpg': 'owl',\n",
            " 'IMG_1031.jpg': 'grand-piano',\n",
            " 'IMG_1035.jpg': 'mountain-bike',\n",
            " 'IMG_1037.jpg': 'school-bus',\n",
            " 'IMG_104.jpg': 'calculator',\n",
            " 'IMG_1042.jpg': 'laptop',\n",
            " 'IMG_1046.jpg': 'laptop',\n",
            " 'IMG_105.jpg': 'school-bus',\n",
            " 'IMG_1050.jpg': 'owl',\n",
            " 'IMG_1052.jpg': 'bear',\n",
            " 'IMG_1058.jpg': 'airplanes',\n",
            " 'IMG_1059.jpg': 'airplanes',\n",
            " 'IMG_106.jpg': 'sheet-music',\n",
            " 'IMG_1071.jpg': 'owl',\n",
            " 'IMG_1072.jpg': 'fireworks',\n",
            " 'IMG_1073.jpg': 'school-bus',\n",
            " 'IMG_1074.jpg': 'school-bus',\n",
            " 'IMG_1080.jpg': 'wine-bottle',\n",
            " 'IMG_1084.jpg': 'waterfall',\n",
            " 'IMG_1090.jpg': 'airplanes',\n",
            " 'IMG_1094.jpg': 'school-bus',\n",
            " 'IMG_1097.jpg': 'kangaroo',\n",
            " 'IMG_1099.jpg': 'lightbulb',\n",
            " 'IMG_1101.jpg': 'mountain-bike',\n",
            " 'IMG_1117.jpg': 'airplanes',\n",
            " 'IMG_1119.jpg': 't-shirt',\n",
            " 'IMG_1127.jpg': 'school-bus',\n",
            " 'IMG_113.jpg': 'computer-monitor',\n",
            " 'IMG_1133.jpg': 'skyscraper',\n",
            " 'IMG_1137.jpg': 'fireworks',\n",
            " 'IMG_1143.jpg': 'computer-monitor',\n",
            " 'IMG_1147.jpg': 'wine-bottle',\n",
            " 'IMG_1148.jpg': 'bear',\n",
            " 'IMG_1155.jpg': 'calculator',\n",
            " 'IMG_1158.jpg': 'waterfall',\n",
            " 'IMG_1163.jpg': 'grand-piano',\n",
            " 'IMG_117.jpg': 'laptop',\n",
            " 'IMG_1172.jpg': 'computer-monitor',\n",
            " 'IMG_1174.jpg': 'skyscraper',\n",
            " 'IMG_1179.jpg': 'lightbulb',\n",
            " 'IMG_1183.jpg': 'fireworks',\n",
            " 'IMG_1187.jpg': 'skyscraper',\n",
            " 'IMG_119.jpg': 'sheet-music',\n",
            " 'IMG_1194.jpg': 'computer-monitor',\n",
            " 'IMG_1196.jpg': 'galaxy',\n",
            " 'IMG_1197.jpg': 'lightning',\n",
            " 'IMG_1199.jpg': 'sword',\n",
            " 'IMG_1202.jpg': 'mountain-bike',\n",
            " 'IMG_1206.jpg': 'sword',\n",
            " 'IMG_1209.jpg': 'grand-piano',\n",
            " 'IMG_121.jpg': 'lightning',\n",
            " 'IMG_1211.jpg': 'wine-bottle',\n",
            " 'IMG_1212.jpg': 't-shirt',\n",
            " 'IMG_1213.jpg': 'airplanes',\n",
            " 'IMG_1214.jpg': 'computer-monitor',\n",
            " 'IMG_1217.jpg': 'wine-bottle',\n",
            " 'IMG_1219.jpg': 'lightning',\n",
            " 'IMG_1228.jpg': 'wine-bottle',\n",
            " 'IMG_1229.jpg': 'lightning',\n",
            " 'IMG_123.jpg': 'school-bus',\n",
            " 'IMG_1232.jpg': 'skyscraper',\n",
            " 'IMG_1235.jpg': 'fireworks',\n",
            " 'IMG_1238.jpg': 'waterfall',\n",
            " 'IMG_1240.jpg': 'sheet-music',\n",
            " 'IMG_1241.jpg': 'waterfall',\n",
            " 'IMG_1242.jpg': 'owl',\n",
            " 'IMG_1248.jpg': 'owl',\n",
            " 'IMG_1251.jpg': 'calculator',\n",
            " 'IMG_1264.jpg': 'grand-piano',\n",
            " 'IMG_1268.jpg': 'skyscraper',\n",
            " 'IMG_1270.jpg': 'calculator',\n",
            " 'IMG_1276.jpg': 'grand-piano',\n",
            " 'IMG_1280.jpg': 'owl',\n",
            " 'IMG_1283.jpg': 'lightning',\n",
            " 'IMG_1285.jpg': 'owl',\n",
            " 'IMG_1289.jpg': 'wine-bottle',\n",
            " 'IMG_129.jpg': 'bear',\n",
            " 'IMG_1298.jpg': 'kangaroo',\n",
            " 'IMG_13.jpg': 'mountain-bike',\n",
            " 'IMG_1306.jpg': 'sword',\n",
            " 'IMG_1307.jpg': 'skyscraper',\n",
            " 'IMG_1308.jpg': 'wine-bottle',\n",
            " 'IMG_1318.jpg': 'kangaroo',\n",
            " 'IMG_1322.jpg': 'skyscraper',\n",
            " 'IMG_1330.jpg': 'laptop',\n",
            " 'IMG_1334.jpg': 'laptop',\n",
            " 'IMG_1339.jpg': 'lightning',\n",
            " 'IMG_134.jpg': 'skyscraper',\n",
            " 'IMG_1342.jpg': 'skyscraper',\n",
            " 'IMG_1344.jpg': 'waterfall',\n",
            " 'IMG_1346.jpg': 'fireworks',\n",
            " 'IMG_1349.jpg': 'bear',\n",
            " 'IMG_135.jpg': 'airplanes',\n",
            " 'IMG_1354.jpg': 'laptop',\n",
            " 'IMG_1359.jpg': 'wine-bottle',\n",
            " 'IMG_136.jpg': 't-shirt',\n",
            " 'IMG_1363.jpg': 'sheet-music',\n",
            " 'IMG_137.jpg': 'skyscraper',\n",
            " 'IMG_1370.jpg': 'kangaroo',\n",
            " 'IMG_1377.jpg': 'computer-monitor',\n",
            " 'IMG_1382.jpg': 't-shirt',\n",
            " 'IMG_1384.jpg': 'airplanes',\n",
            " 'IMG_1397.jpg': 'grand-piano',\n",
            " 'IMG_1406.jpg': 'lightbulb',\n",
            " 'IMG_1415.jpg': 'skyscraper',\n",
            " 'IMG_1419.jpg': 'lightning',\n",
            " 'IMG_1420.jpg': 'fireworks',\n",
            " 'IMG_1422.jpg': 'grand-piano',\n",
            " 'IMG_1429.jpg': 'fireworks',\n",
            " 'IMG_1435.jpg': 'sheet-music',\n",
            " 'IMG_1436.jpg': 'skyscraper',\n",
            " 'IMG_1437.jpg': 'sword',\n",
            " 'IMG_144.jpg': 'sword',\n",
            " 'IMG_1442.jpg': 'kangaroo',\n",
            " 'IMG_1444.jpg': 'lightning',\n",
            " 'IMG_1449.jpg': 'laptop',\n",
            " 'IMG_1452.jpg': 'skyscraper',\n",
            " 'IMG_1459.jpg': 'lightbulb',\n",
            " 'IMG_1462.jpg': 'grand-piano',\n",
            " 'IMG_1466.jpg': 'airplanes',\n",
            " 'IMG_1468.jpg': 'bear',\n",
            " 'IMG_1474.jpg': 'lightning',\n",
            " 'IMG_1475.jpg': 'fireworks',\n",
            " 'IMG_1480.jpg': 'kangaroo',\n",
            " 'IMG_1481.jpg': 't-shirt',\n",
            " 'IMG_1483.jpg': 'owl',\n",
            " 'IMG_1484.jpg': 'owl',\n",
            " 'IMG_1494.jpg': 'calculator',\n",
            " 'IMG_1495.jpg': 'school-bus',\n",
            " 'IMG_1500.jpg': 'computer-monitor',\n",
            " 'IMG_1501.jpg': 'fireworks',\n",
            " 'IMG_1502.jpg': 'fireworks',\n",
            " 'IMG_1506.jpg': 'sword',\n",
            " 'IMG_1509.jpg': 't-shirt',\n",
            " 'IMG_151.jpg': 'school-bus',\n",
            " 'IMG_1511.jpg': 'lightbulb',\n",
            " 'IMG_1512.jpg': 'computer-monitor',\n",
            " 'IMG_1516.jpg': 'airplanes',\n",
            " 'IMG_1520.jpg': 'computer-monitor',\n",
            " 'IMG_1529.jpg': 'lightning',\n",
            " 'IMG_153.jpg': 'bear',\n",
            " 'IMG_1532.jpg': 't-shirt',\n",
            " 'IMG_1536.jpg': 'lightning',\n",
            " 'IMG_1538.jpg': 'calculator',\n",
            " 'IMG_1541.jpg': 'laptop',\n",
            " 'IMG_1543.jpg': 'grand-piano',\n",
            " 'IMG_1544.jpg': 'grand-piano',\n",
            " 'IMG_1546.jpg': 'owl',\n",
            " 'IMG_1550.jpg': 't-shirt',\n",
            " 'IMG_1551.jpg': 'lightning',\n",
            " 'IMG_1552.jpg': 'grand-piano',\n",
            " 'IMG_1557.jpg': 'skyscraper',\n",
            " 'IMG_1560.jpg': 'sword',\n",
            " 'IMG_1575.jpg': 'mountain-bike',\n",
            " 'IMG_1589.jpg': 'galaxy',\n",
            " 'IMG_159.jpg': 'fireworks',\n",
            " 'IMG_1591.jpg': 'skyscraper',\n",
            " 'IMG_1593.jpg': 'skyscraper',\n",
            " 'IMG_1600.jpg': 't-shirt',\n",
            " 'IMG_1603.jpg': 'fireworks',\n",
            " 'IMG_1604.jpg': 'bear',\n",
            " 'IMG_1609.jpg': 'owl',\n",
            " 'IMG_1618.jpg': 'lightbulb',\n",
            " 'IMG_1620.jpg': 'mountain-bike',\n",
            " 'IMG_1622.jpg': 'mountain-bike',\n",
            " 'IMG_1623.jpg': 'skyscraper',\n",
            " 'IMG_1628.jpg': 'airplanes',\n",
            " 'IMG_163.jpg': 'galaxy',\n",
            " 'IMG_1633.jpg': 'fireworks',\n",
            " 'IMG_1643.jpg': 'computer-monitor',\n",
            " 'IMG_1645.jpg': 'computer-monitor',\n",
            " 'IMG_1646.jpg': 'lightning',\n",
            " 'IMG_1650.jpg': 'bear',\n",
            " 'IMG_1657.jpg': 'sword',\n",
            " 'IMG_1659.jpg': 'fireworks',\n",
            " 'IMG_1661.jpg': 'lightbulb',\n",
            " 'IMG_1664.jpg': 'skyscraper',\n",
            " 'IMG_167.jpg': 'sword',\n",
            " 'IMG_1674.jpg': 'fireworks',\n",
            " 'IMG_1684.jpg': 'sword',\n",
            " 'IMG_169.jpg': 'grand-piano',\n",
            " 'IMG_1699.jpg': 'mountain-bike',\n",
            " 'IMG_1703.jpg': 'computer-monitor',\n",
            " 'IMG_1706.jpg': 'computer-monitor',\n",
            " 'IMG_1709.jpg': 'mountain-bike',\n",
            " 'IMG_1713.jpg': 'mountain-bike',\n",
            " 'IMG_1723.jpg': 'airplanes',\n",
            " 'IMG_1728.jpg': 'sword',\n",
            " 'IMG_1734.jpg': 'wine-bottle',\n",
            " 'IMG_174.jpg': 'galaxy',\n",
            " 'IMG_1741.jpg': 'lightbulb',\n",
            " 'IMG_1744.jpg': 't-shirt',\n",
            " 'IMG_1747.jpg': 'galaxy',\n",
            " 'IMG_175.jpg': 'lightbulb',\n",
            " 'IMG_1756.jpg': 't-shirt',\n",
            " 'IMG_1761.jpg': 'bear',\n",
            " 'IMG_1764.jpg': 'fireworks',\n",
            " 'IMG_1768.jpg': 'mountain-bike',\n",
            " 'IMG_1771.jpg': 'airplanes',\n",
            " 'IMG_1780.jpg': 'mountain-bike',\n",
            " 'IMG_1798.jpg': 'bear',\n",
            " 'IMG_1799.jpg': 'bear',\n",
            " 'IMG_1802.jpg': 'waterfall',\n",
            " 'IMG_1803.jpg': 'kangaroo',\n",
            " 'IMG_1808.jpg': 'computer-monitor',\n",
            " 'IMG_1811.jpg': 'lightbulb',\n",
            " 'IMG_1813.jpg': 'school-bus',\n",
            " 'IMG_1814.jpg': 'waterfall',\n",
            " 'IMG_1819.jpg': 'calculator',\n",
            " 'IMG_1820.jpg': 'sheet-music',\n",
            " 'IMG_1826.jpg': 'airplanes',\n",
            " 'IMG_183.jpg': 'computer-monitor',\n",
            " 'IMG_1831.jpg': 'bear',\n",
            " 'IMG_1836.jpg': 'grand-piano',\n",
            " 'IMG_1837.jpg': 'airplanes',\n",
            " 'IMG_1842.jpg': 'galaxy',\n",
            " 'IMG_1849.jpg': 'lightbulb',\n",
            " 'IMG_1851.jpg': 'kangaroo',\n",
            " 'IMG_1852.jpg': 'calculator',\n",
            " 'IMG_1854.jpg': 'waterfall',\n",
            " 'IMG_1858.jpg': 'owl',\n",
            " 'IMG_1865.jpg': 'computer-monitor',\n",
            " 'IMG_1871.jpg': 'sheet-music',\n",
            " 'IMG_1872.jpg': 'laptop',\n",
            " 'IMG_1878.jpg': 'kangaroo',\n",
            " 'IMG_1882.jpg': 't-shirt',\n",
            " 'IMG_1883.jpg': 'lightning',\n",
            " 'IMG_1885.jpg': 'skyscraper',\n",
            " 'IMG_1890.jpg': 'sword',\n",
            " 'IMG_1892.jpg': 'sword',\n",
            " 'IMG_1899.jpg': 'mountain-bike',\n",
            " 'IMG_19.jpg': 'grand-piano',\n",
            " 'IMG_1901.jpg': 'calculator',\n",
            " 'IMG_1902.jpg': 'sword',\n",
            " 'IMG_1907.jpg': 'galaxy',\n",
            " 'IMG_1908.jpg': 'grand-piano',\n",
            " 'IMG_1909.jpg': 'owl',\n",
            " 'IMG_1912.jpg': 'skyscraper',\n",
            " 'IMG_1915.jpg': 'school-bus',\n",
            " 'IMG_1918.jpg': 'mountain-bike',\n",
            " 'IMG_1919.jpg': 'bear',\n",
            " 'IMG_1923.jpg': 'school-bus',\n",
            " 'IMG_1929.jpg': 'lightbulb',\n",
            " 'IMG_1935.jpg': 'grand-piano',\n",
            " 'IMG_1936.jpg': 'airplanes',\n",
            " 'IMG_1941.jpg': 'school-bus',\n",
            " 'IMG_1949.jpg': 'lightning',\n",
            " 'IMG_195.jpg': 'school-bus',\n",
            " 'IMG_1961.jpg': 'mountain-bike',\n",
            " 'IMG_1962.jpg': 'calculator',\n",
            " 'IMG_1966.jpg': 'galaxy',\n",
            " 'IMG_1971.jpg': 'laptop',\n",
            " 'IMG_1975.jpg': 'school-bus',\n",
            " 'IMG_1977.jpg': 'kangaroo',\n",
            " 'IMG_1978.jpg': 't-shirt',\n",
            " 'IMG_1979.jpg': 'sheet-music',\n",
            " 'IMG_1982.jpg': 'school-bus',\n",
            " 'IMG_1989.jpg': 'galaxy',\n",
            " 'IMG_1991.jpg': 'kangaroo',\n",
            " 'IMG_2000.jpg': 'lightbulb',\n",
            " 'IMG_2005.jpg': 'bear',\n",
            " 'IMG_2007.jpg': 't-shirt',\n",
            " 'IMG_2010.jpg': 'lightning',\n",
            " 'IMG_2017.jpg': 'airplanes',\n",
            " 'IMG_2018.jpg': 'bear',\n",
            " 'IMG_2020.jpg': 'kangaroo',\n",
            " 'IMG_2021.jpg': 'mountain-bike',\n",
            " 'IMG_2023.jpg': 'grand-piano',\n",
            " 'IMG_2025.jpg': 'galaxy',\n",
            " 'IMG_2031.jpg': 't-shirt',\n",
            " 'IMG_2041.jpg': 'sword',\n",
            " 'IMG_2042.jpg': 'sword',\n",
            " 'IMG_2047.jpg': 'lightning',\n",
            " 'IMG_2052.jpg': 'fireworks',\n",
            " 'IMG_2053.jpg': 'wine-bottle',\n",
            " 'IMG_206.jpg': 'waterfall',\n",
            " 'IMG_214.jpg': 'grand-piano',\n",
            " 'IMG_217.jpg': 'calculator',\n",
            " 'IMG_220.jpg': 'sword',\n",
            " 'IMG_223.jpg': 'kangaroo',\n",
            " 'IMG_227.jpg': 'mountain-bike',\n",
            " 'IMG_228.jpg': 'kangaroo',\n",
            " 'IMG_233.jpg': 't-shirt',\n",
            " 'IMG_234.jpg': 'kangaroo',\n",
            " 'IMG_237.jpg': 'grand-piano',\n",
            " 'IMG_24.jpg': 'wine-bottle',\n",
            " 'IMG_240.jpg': 't-shirt',\n",
            " 'IMG_245.jpg': 'kangaroo',\n",
            " 'IMG_249.jpg': 'galaxy',\n",
            " 'IMG_251.jpg': 'grand-piano',\n",
            " 'IMG_252.jpg': 'sword',\n",
            " 'IMG_261.jpg': 'fireworks',\n",
            " 'IMG_262.jpg': 'mountain-bike',\n",
            " 'IMG_263.jpg': 'school-bus',\n",
            " 'IMG_264.jpg': 'school-bus',\n",
            " 'IMG_267.jpg': 'wine-bottle',\n",
            " 'IMG_269.jpg': 'calculator',\n",
            " 'IMG_270.jpg': 't-shirt',\n",
            " 'IMG_272.jpg': 'lightbulb',\n",
            " 'IMG_273.jpg': 'school-bus',\n",
            " 'IMG_278.jpg': 'sheet-music',\n",
            " 'IMG_279.jpg': 'galaxy',\n",
            " 'IMG_280.jpg': 't-shirt',\n",
            " 'IMG_285.jpg': 'bear',\n",
            " 'IMG_293.jpg': 'wine-bottle',\n",
            " 'IMG_295.jpg': 'grand-piano',\n",
            " 'IMG_296.jpg': 'computer-monitor',\n",
            " 'IMG_298.jpg': 'bear',\n",
            " 'IMG_299.jpg': 'fireworks',\n",
            " 'IMG_30.jpg': 'airplanes',\n",
            " 'IMG_307.jpg': 'school-bus',\n",
            " 'IMG_308.jpg': 't-shirt',\n",
            " 'IMG_31.jpg': 'computer-monitor',\n",
            " 'IMG_312.jpg': 'sheet-music',\n",
            " 'IMG_32.jpg': 'computer-monitor',\n",
            " 'IMG_321.jpg': 'computer-monitor',\n",
            " 'IMG_322.jpg': 'calculator',\n",
            " 'IMG_329.jpg': 'fireworks',\n",
            " 'IMG_338.jpg': 'computer-monitor',\n",
            " 'IMG_34.jpg': 'owl',\n",
            " 'IMG_35.jpg': 'airplanes',\n",
            " 'IMG_355.jpg': 'bear',\n",
            " 'IMG_367.jpg': 'kangaroo',\n",
            " 'IMG_37.jpg': 'galaxy',\n",
            " 'IMG_371.jpg': 'skyscraper',\n",
            " 'IMG_377.jpg': 'waterfall',\n",
            " 'IMG_379.jpg': 'school-bus',\n",
            " 'IMG_383.jpg': 'galaxy',\n",
            " 'IMG_384.jpg': 't-shirt',\n",
            " 'IMG_385.jpg': 'computer-monitor',\n",
            " 'IMG_397.jpg': 'school-bus',\n",
            " 'IMG_400.jpg': 'sheet-music',\n",
            " 'IMG_404.jpg': 'fireworks',\n",
            " 'IMG_405.jpg': 'school-bus',\n",
            " 'IMG_410.jpg': 'airplanes',\n",
            " 'IMG_414.jpg': 'kangaroo',\n",
            " 'IMG_420.jpg': 'bear',\n",
            " 'IMG_421.jpg': 'lightning',\n",
            " 'IMG_423.jpg': 'wine-bottle',\n",
            " 'IMG_451.jpg': 'waterfall',\n",
            " 'IMG_455.jpg': 'bear',\n",
            " 'IMG_461.jpg': 'calculator',\n",
            " 'IMG_467.jpg': 'grand-piano',\n",
            " 'IMG_473.jpg': 'calculator',\n",
            " 'IMG_478.jpg': 'computer-monitor',\n",
            " 'IMG_48.jpg': 'laptop',\n",
            " 'IMG_480.jpg': 'bear',\n",
            " 'IMG_485.jpg': 'school-bus',\n",
            " 'IMG_487.jpg': 'calculator',\n",
            " 'IMG_497.jpg': 'computer-monitor',\n",
            " 'IMG_499.jpg': 'calculator',\n",
            " 'IMG_501.jpg': 'owl',\n",
            " 'IMG_505.jpg': 'bear',\n",
            " 'IMG_507.jpg': 'laptop',\n",
            " 'IMG_508.jpg': 'lightning',\n",
            " 'IMG_51.jpg': 'calculator',\n",
            " 'IMG_512.jpg': 'airplanes',\n",
            " 'IMG_513.jpg': 'mountain-bike',\n",
            " 'IMG_515.jpg': 'galaxy',\n",
            " 'IMG_517.jpg': 'computer-monitor',\n",
            " 'IMG_524.jpg': 'lightbulb',\n",
            " 'IMG_53.jpg': 'fireworks',\n",
            " 'IMG_535.jpg': 'calculator',\n",
            " 'IMG_539.jpg': 't-shirt',\n",
            " 'IMG_542.jpg': 'computer-monitor',\n",
            " 'IMG_543.jpg': 'skyscraper',\n",
            " 'IMG_546.jpg': 'kangaroo',\n",
            " 'IMG_550.jpg': 'lightning',\n",
            " 'IMG_551.jpg': 'lightbulb',\n",
            " 'IMG_558.jpg': 'computer-monitor',\n",
            " 'IMG_561.jpg': 'airplanes',\n",
            " 'IMG_563.jpg': 'laptop',\n",
            " 'IMG_567.jpg': 'owl',\n",
            " 'IMG_57.jpg': 'lightning',\n",
            " 'IMG_572.jpg': 'lightning',\n",
            " 'IMG_58.jpg': 'lightning',\n",
            " 'IMG_581.jpg': 'laptop',\n",
            " 'IMG_582.jpg': 'fireworks',\n",
            " 'IMG_583.jpg': 't-shirt',\n",
            " 'IMG_588.jpg': 'lightbulb',\n",
            " 'IMG_59.jpg': 'computer-monitor',\n",
            " 'IMG_592.jpg': 'sheet-music',\n",
            " 'IMG_597.jpg': 'kangaroo',\n",
            " 'IMG_598.jpg': 'bear',\n",
            " 'IMG_6.jpg': 'wine-bottle',\n",
            " 'IMG_601.jpg': 'owl',\n",
            " 'IMG_602.jpg': 'skyscraper',\n",
            " 'IMG_603.jpg': 'lightning',\n",
            " 'IMG_606.jpg': 'fireworks',\n",
            " 'IMG_607.jpg': 'calculator',\n",
            " 'IMG_608.jpg': 'computer-monitor',\n",
            " 'IMG_61.jpg': 'computer-monitor',\n",
            " 'IMG_616.jpg': 'lightbulb',\n",
            " 'IMG_621.jpg': 'skyscraper',\n",
            " 'IMG_635.jpg': 'skyscraper',\n",
            " 'IMG_638.jpg': 'grand-piano',\n",
            " 'IMG_641.jpg': 'school-bus',\n",
            " 'IMG_645.jpg': 'skyscraper',\n",
            " 'IMG_647.jpg': 'fireworks',\n",
            " 'IMG_66.jpg': 't-shirt',\n",
            " 'IMG_660.jpg': 'calculator',\n",
            " 'IMG_664.jpg': 'owl',\n",
            " 'IMG_667.jpg': 'laptop',\n",
            " 'IMG_67.jpg': 'wine-bottle',\n",
            " 'IMG_671.jpg': 'mountain-bike',\n",
            " 'IMG_674.jpg': 'sheet-music',\n",
            " 'IMG_679.jpg': 'kangaroo',\n",
            " 'IMG_68.jpg': 'lightning',\n",
            " 'IMG_681.jpg': 'fireworks',\n",
            " 'IMG_682.jpg': 'computer-monitor',\n",
            " 'IMG_69.jpg': 'bear',\n",
            " 'IMG_691.jpg': 'sheet-music',\n",
            " 'IMG_695.jpg': 'laptop',\n",
            " 'IMG_702.jpg': 'galaxy',\n",
            " 'IMG_703.jpg': 'airplanes',\n",
            " 'IMG_705.jpg': 'wine-bottle',\n",
            " 'IMG_706.jpg': 'sheet-music',\n",
            " 'IMG_708.jpg': 'laptop',\n",
            " 'IMG_709.jpg': 'grand-piano',\n",
            " 'IMG_710.jpg': 't-shirt',\n",
            " 'IMG_711.jpg': 'skyscraper',\n",
            " 'IMG_712.jpg': 'bear',\n",
            " 'IMG_717.jpg': 'kangaroo',\n",
            " 'IMG_72.jpg': 'galaxy',\n",
            " 'IMG_722.jpg': 'laptop',\n",
            " 'IMG_727.jpg': 'mountain-bike',\n",
            " 'IMG_730.jpg': 'airplanes',\n",
            " 'IMG_739.jpg': 'kangaroo',\n",
            " 'IMG_74.jpg': 'skyscraper',\n",
            " 'IMG_744.jpg': 'sheet-music',\n",
            " 'IMG_752.jpg': 'skyscraper',\n",
            " 'IMG_755.jpg': 'sheet-music',\n",
            " 'IMG_756.jpg': 'lightning',\n",
            " 'IMG_764.jpg': 'owl',\n",
            " 'IMG_775.jpg': 'sheet-music',\n",
            " 'IMG_785.jpg': 'galaxy',\n",
            " 'IMG_789.jpg': 't-shirt',\n",
            " 'IMG_791.jpg': 'waterfall',\n",
            " 'IMG_794.jpg': 'airplanes',\n",
            " 'IMG_797.jpg': 'wine-bottle',\n",
            " 'IMG_802.jpg': 'computer-monitor',\n",
            " 'IMG_803.jpg': 'airplanes',\n",
            " 'IMG_805.jpg': 'airplanes',\n",
            " 'IMG_813.jpg': 'sword',\n",
            " 'IMG_815.jpg': 'mountain-bike',\n",
            " 'IMG_817.jpg': 'kangaroo',\n",
            " 'IMG_823.jpg': 'sword',\n",
            " 'IMG_826.jpg': 'school-bus',\n",
            " 'IMG_828.jpg': 'galaxy',\n",
            " 'IMG_835.jpg': 'mountain-bike',\n",
            " 'IMG_837.jpg': 'sheet-music',\n",
            " 'IMG_844.jpg': 'grand-piano',\n",
            " 'IMG_845.jpg': 'lightning',\n",
            " 'IMG_848.jpg': 'kangaroo',\n",
            " 'IMG_852.jpg': 'lightbulb',\n",
            " 'IMG_862.jpg': 'school-bus',\n",
            " 'IMG_864.jpg': 't-shirt',\n",
            " 'IMG_866.jpg': 'kangaroo',\n",
            " 'IMG_867.jpg': 'airplanes',\n",
            " 'IMG_873.jpg': 'owl',\n",
            " 'IMG_876.jpg': 'sheet-music',\n",
            " 'IMG_877.jpg': 'bear',\n",
            " 'IMG_878.jpg': 'fireworks',\n",
            " 'IMG_880.jpg': 'bear',\n",
            " 'IMG_884.jpg': 'kangaroo',\n",
            " 'IMG_887.jpg': 'waterfall',\n",
            " 'IMG_89.jpg': 'waterfall',\n",
            " 'IMG_893.jpg': 'wine-bottle',\n",
            " 'IMG_897.jpg': 'kangaroo',\n",
            " 'IMG_904.jpg': 'lightning',\n",
            " 'IMG_907.jpg': 'computer-monitor',\n",
            " 'IMG_912.jpg': 'lightbulb',\n",
            " 'IMG_913.jpg': 'galaxy',\n",
            " 'IMG_914.jpg': 'sheet-music',\n",
            " 'IMG_917.jpg': 't-shirt',\n",
            " 'IMG_919.jpg': 'sheet-music',\n",
            " 'IMG_92.jpg': 'mountain-bike',\n",
            " 'IMG_922.jpg': 'laptop',\n",
            " 'IMG_923.jpg': 'fireworks',\n",
            " 'IMG_932.jpg': 'airplanes',\n",
            " 'IMG_938.jpg': 'computer-monitor',\n",
            " 'IMG_94.jpg': 'wine-bottle',\n",
            " 'IMG_942.jpg': 'lightning',\n",
            " 'IMG_943.jpg': 'school-bus',\n",
            " 'IMG_944.jpg': 't-shirt',\n",
            " 'IMG_950.jpg': 'wine-bottle',\n",
            " 'IMG_952.jpg': 'fireworks',\n",
            " 'IMG_956.jpg': 't-shirt',\n",
            " 'IMG_959.jpg': 'bear',\n",
            " 'IMG_96.jpg': 'airplanes',\n",
            " 'IMG_965.jpg': 'grand-piano',\n",
            " 'IMG_967.jpg': 'calculator',\n",
            " 'IMG_98.jpg': 'wine-bottle',\n",
            " 'IMG_982.jpg': 'laptop',\n",
            " 'IMG_986.jpg': 'wine-bottle',\n",
            " 'IMG_999.jpg': 'lightning'}\n",
            "Num. of labeled images 500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "V3Rp00GfLmIx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a98f1b95-efb5-4262-a54c-e1717d4863cc"
      },
      "source": [
        "#############################################################\n",
        "##   CNN\n",
        "if cnn:\n",
        "    class CNNClassifier(tf.keras.Model):\n",
        "\n",
        "        # Define two groups of layers: feature (convolutions) and classification (dense)\n",
        "\n",
        "        def __init__(self, depth, num_filters, pool_size, kernel_size, num_classes):\n",
        "            super(CNNClassifier, self).__init__()\n",
        "\n",
        "            ## Convolution layers ##\n",
        "            self.feature_extractor = tf.keras.Sequential()\n",
        "\n",
        "            for i in range(depth):\n",
        "                self.feature_extractor.add(ConvBlock(num_filters, pool_size, kernel_size))\n",
        "                num_filters *= 2\n",
        "\n",
        "            ## Flatten layer to feed data to fully connected layers ##\n",
        "            self.flatten = tf.keras.layers.Flatten()  # output of a convolutional layer is a n-D tensor\n",
        "\n",
        "            ## Classification layers ##\n",
        "            self.classifier = tf.keras.Sequential()\n",
        "\n",
        "            # Fully connected\n",
        "            self.classifier.add(tf.keras.layers.Dense(units=512,\n",
        "                                                      activation='relu'))\n",
        "            self.classifier.add(tf.keras.layers.Dense(units=512,\n",
        "                                                      activation='relu'))\n",
        "            self.classifier.add(tf.keras.layers.Dense(units=512,\n",
        "                                                      activation='relu'))\n",
        "            self.classifier.add(tf.keras.layers.Dropout(0.1))\n",
        "\n",
        "            # output layer with one unit for each class.\n",
        "            # Use softmax activation because it's a non-binary classification problem\n",
        "            self.classifier.add(tf.keras.layers.Dense(units=num_classes,\n",
        "                                                      activation='softmax'))\n",
        "\n",
        "        # create complete model = Sequential(feature_layers + classification_layers)\n",
        "        def call(self, inputs):\n",
        "            x = self.feature_extractor(inputs)\n",
        "            x = self.flatten(x)\n",
        "            x = self.classifier(x)\n",
        "            return x\n",
        "\n",
        "\n",
        "    # Create convolutional layer\n",
        "    class ConvBlock(tf.keras.Model):\n",
        "\n",
        "        def __init__(self, num_filters, pool_size, kernel_size):\n",
        "            super(ConvBlock, self).__init__()\n",
        "\n",
        "            self.conv2d = tf.keras.layers.Conv2D(filters=num_filters,\n",
        "                                                 kernel_size=kernel_size,  # (3, 3)\n",
        "                                                 # how much you move your filter when doing convolution\n",
        "                                                 strides=(1, 1),\n",
        "                                                 # 0 pad the input such that the output\n",
        "                                                 # has the same dimensions as the original input\n",
        "                                                 padding='same')\n",
        "\n",
        "            self.activation = tf.keras.layers.ReLU()\n",
        "            self.pooling = tf.keras.layers.MaxPool2D(pool_size=pool_size)  # (2, 2))\n",
        "            # self.dropout.add(tf.keras.layers.Dropout(0.25))\n",
        "\n",
        "        def call(self, inputs):\n",
        "            x = self.conv2d(inputs)\n",
        "            x = self.activation(x)\n",
        "            x = self.pooling(x)\n",
        "            # x = self.dropout(x)\n",
        "            return x\n",
        "\n",
        "        \n",
        "    # Create CNN model\n",
        "    # ------------\n",
        "    model_name = 'CNN'\n",
        "\n",
        "    # depth of the input volume i.e. different color channels of an image\n",
        "    depth = 5\n",
        "\n",
        "    # number of convolutional filter kernels to use\n",
        "    #  weights where each is used for a convolution: trainable variables defining the filter.\n",
        "    num_filters = 32\n",
        "\n",
        "    # size of pooling area for max pooling\n",
        "    pool_size = 2\n",
        "\n",
        "    # convolution kernel size\n",
        "    kernel_size = 3\n",
        "\n",
        "    # Create Model instance\n",
        "    model = CNNClassifier(depth=depth,\n",
        "                      num_filters=num_filters,\n",
        "                      pool_size=pool_size,\n",
        "                      kernel_size=kernel_size,\n",
        "                      num_classes=num_classes)\n",
        "\n",
        "    # Build Model (Required)\n",
        "    model.build(input_shape=(None, img_h, img_w, channels))\n",
        "\n",
        "    # Visualize created model as a table\n",
        "    # model.feature_extractor.summary()\n",
        "    # Visualize initialized weights\n",
        "    # print('initial model weights', model.weights)\n",
        "\n",
        "    # Prepare the model for training\n",
        "    # ------------------------------\n",
        "    loss = tf.keras.losses.CategoricalCrossentropy()\n",
        "\n",
        "    lr = 1e-4  # learning rate\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n",
        "\n",
        "    metrics = ['accuracy']  # validation metrics to monitor\n",
        "\n",
        "    model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
        "\n",
        "    # Train the model\n",
        "    # ---------------\n",
        "    with_early_stopping = True\n",
        "\n",
        "    callbacks = []\n",
        "    if with_early_stopping:\n",
        "        callbacks.append(\n",
        "            tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
        "                                             patience=epochs * 0.2))\n",
        "\n",
        "    trained_model = model.fit_generator(generator=train_generator,\n",
        "                                        epochs=epochs,\n",
        "                                        steps_per_epoch=len(train_generator),\n",
        "                                        validation_data=valid_generator,\n",
        "                                        validation_steps=len(valid_generator))\n",
        "\n",
        "    # Model evaluation\n",
        "    # ----------------\n",
        "    # model.load_weights('/path/to/checkpoint')  # use this if you want to restore saved model\n",
        "\n",
        "    cnn_eval_output = model.evaluate_generator(valid_generator,\n",
        "                                                steps=len(valid_generator),\n",
        "                                                verbose=0)\n",
        "\n",
        "    print('eval_out', cnn_eval_output)\n",
        "    "
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n",
            "78/78 [==============================] - 38s 493ms/step - loss: 2.9514 - accuracy: 0.0678 - val_loss: 2.8623 - val_accuracy: 0.0879\n",
            "Epoch 2/150\n",
            "78/78 [==============================] - 35s 445ms/step - loss: 2.7945 - accuracy: 0.1241 - val_loss: 2.7075 - val_accuracy: 0.1401\n",
            "Epoch 3/150\n",
            "78/78 [==============================] - 35s 444ms/step - loss: 2.6456 - accuracy: 0.1528 - val_loss: 2.5625 - val_accuracy: 0.2182\n",
            "Epoch 4/150\n",
            "78/78 [==============================] - 35s 451ms/step - loss: 2.5501 - accuracy: 0.1782 - val_loss: 2.5293 - val_accuracy: 0.2280\n",
            "Epoch 5/150\n",
            "78/78 [==============================] - 35s 443ms/step - loss: 2.3871 - accuracy: 0.2281 - val_loss: 2.3734 - val_accuracy: 0.2476\n",
            "Epoch 6/150\n",
            "78/78 [==============================] - 35s 448ms/step - loss: 2.2972 - accuracy: 0.2642 - val_loss: 2.2199 - val_accuracy: 0.3257\n",
            "Epoch 7/150\n",
            "78/78 [==============================] - 35s 452ms/step - loss: 2.1674 - accuracy: 0.3215 - val_loss: 2.1964 - val_accuracy: 0.3160\n",
            "Epoch 8/150\n",
            "78/78 [==============================] - 35s 449ms/step - loss: 2.0664 - accuracy: 0.3435 - val_loss: 2.1055 - val_accuracy: 0.3453\n",
            "Epoch 9/150\n",
            "78/78 [==============================] - 35s 452ms/step - loss: 1.9583 - accuracy: 0.3734 - val_loss: 2.0331 - val_accuracy: 0.3746\n",
            "Epoch 10/150\n",
            "78/78 [==============================] - 35s 445ms/step - loss: 1.8796 - accuracy: 0.4197 - val_loss: 2.0602 - val_accuracy: 0.3583\n",
            "Epoch 11/150\n",
            "78/78 [==============================] - 35s 450ms/step - loss: 1.7935 - accuracy: 0.4323 - val_loss: 1.9552 - val_accuracy: 0.4072\n",
            "Epoch 12/150\n",
            "78/78 [==============================] - 35s 447ms/step - loss: 1.6988 - accuracy: 0.4892 - val_loss: 1.8277 - val_accuracy: 0.4365\n",
            "Epoch 13/150\n",
            "78/78 [==============================] - 36s 457ms/step - loss: 1.6181 - accuracy: 0.4532 - val_loss: 1.8757 - val_accuracy: 0.4430\n",
            "Epoch 14/150\n",
            "78/78 [==============================] - 35s 445ms/step - loss: 1.5766 - accuracy: 0.5044 - val_loss: 1.8478 - val_accuracy: 0.4300\n",
            "Epoch 15/150\n",
            "78/78 [==============================] - 36s 457ms/step - loss: 1.4940 - accuracy: 0.4746 - val_loss: 1.8714 - val_accuracy: 0.4560\n",
            "Epoch 16/150\n",
            "78/78 [==============================] - 35s 447ms/step - loss: 1.4599 - accuracy: 0.5533 - val_loss: 1.7893 - val_accuracy: 0.4463\n",
            "Epoch 17/150\n",
            "78/78 [==============================] - 35s 452ms/step - loss: 1.3537 - accuracy: 0.5615 - val_loss: 1.8460 - val_accuracy: 0.4528\n",
            "Epoch 18/150\n",
            "78/78 [==============================] - 35s 449ms/step - loss: 1.3105 - accuracy: 0.6025 - val_loss: 1.8888 - val_accuracy: 0.4495\n",
            "Epoch 19/150\n",
            "78/78 [==============================] - 35s 453ms/step - loss: 1.2860 - accuracy: 0.5575 - val_loss: 1.7324 - val_accuracy: 0.4919\n",
            "Epoch 20/150\n",
            "78/78 [==============================] - 35s 451ms/step - loss: 1.2333 - accuracy: 0.6104 - val_loss: 1.6541 - val_accuracy: 0.5016\n",
            "Epoch 21/150\n",
            "78/78 [==============================] - 35s 451ms/step - loss: 1.1382 - accuracy: 0.6437 - val_loss: 1.8376 - val_accuracy: 0.4365\n",
            "Epoch 22/150\n",
            "78/78 [==============================] - 35s 451ms/step - loss: 1.1545 - accuracy: 0.6323 - val_loss: 1.7742 - val_accuracy: 0.4691\n",
            "Epoch 23/150\n",
            "78/78 [==============================] - 35s 453ms/step - loss: 1.0667 - accuracy: 0.6398 - val_loss: 1.8570 - val_accuracy: 0.4984\n",
            "Epoch 24/150\n",
            "78/78 [==============================] - 35s 448ms/step - loss: 0.9862 - accuracy: 0.6789 - val_loss: 1.7778 - val_accuracy: 0.5244\n",
            "Epoch 25/150\n",
            "78/78 [==============================] - 35s 453ms/step - loss: 0.9954 - accuracy: 0.6994 - val_loss: 1.6924 - val_accuracy: 0.5375\n",
            "Epoch 26/150\n",
            "78/78 [==============================] - 35s 448ms/step - loss: 0.9626 - accuracy: 0.7200 - val_loss: 1.9264 - val_accuracy: 0.4821\n",
            "Epoch 27/150\n",
            "78/78 [==============================] - 35s 451ms/step - loss: 0.8869 - accuracy: 0.7311 - val_loss: 1.7981 - val_accuracy: 0.5049\n",
            "Epoch 28/150\n",
            "78/78 [==============================] - 35s 448ms/step - loss: 0.8846 - accuracy: 0.6860 - val_loss: 1.8573 - val_accuracy: 0.4919\n",
            "Epoch 29/150\n",
            "78/78 [==============================] - 35s 448ms/step - loss: 0.8271 - accuracy: 0.7316 - val_loss: 1.9928 - val_accuracy: 0.5016\n",
            "Epoch 30/150\n",
            "78/78 [==============================] - 35s 446ms/step - loss: 0.8348 - accuracy: 0.7328 - val_loss: 1.8361 - val_accuracy: 0.4886\n",
            "Epoch 31/150\n",
            "78/78 [==============================] - 35s 454ms/step - loss: 0.7718 - accuracy: 0.7384 - val_loss: 1.8966 - val_accuracy: 0.5147\n",
            "Epoch 32/150\n",
            "78/78 [==============================] - 35s 444ms/step - loss: 0.7337 - accuracy: 0.7695 - val_loss: 1.9365 - val_accuracy: 0.4919\n",
            "Epoch 33/150\n",
            "78/78 [==============================] - 35s 451ms/step - loss: 0.7219 - accuracy: 0.7933 - val_loss: 1.9094 - val_accuracy: 0.4984\n",
            "Epoch 34/150\n",
            "78/78 [==============================] - 34s 440ms/step - loss: 0.7089 - accuracy: 0.7605 - val_loss: 1.9096 - val_accuracy: 0.5277\n",
            "Epoch 35/150\n",
            "78/78 [==============================] - 35s 452ms/step - loss: 0.6493 - accuracy: 0.7827 - val_loss: 2.0558 - val_accuracy: 0.5049\n",
            "Epoch 36/150\n",
            "78/78 [==============================] - 35s 445ms/step - loss: 0.5854 - accuracy: 0.7922 - val_loss: 2.0395 - val_accuracy: 0.5212\n",
            "Epoch 37/150\n",
            "78/78 [==============================] - 35s 446ms/step - loss: 0.5920 - accuracy: 0.7911 - val_loss: 2.1546 - val_accuracy: 0.5081\n",
            "Epoch 38/150\n",
            "78/78 [==============================] - 34s 442ms/step - loss: 0.5562 - accuracy: 0.8241 - val_loss: 2.0752 - val_accuracy: 0.4984\n",
            "Epoch 39/150\n",
            "78/78 [==============================] - 35s 449ms/step - loss: 0.6015 - accuracy: 0.8204 - val_loss: 1.8385 - val_accuracy: 0.5407\n",
            "Epoch 40/150\n",
            "78/78 [==============================] - 35s 446ms/step - loss: 0.5563 - accuracy: 0.8165 - val_loss: 1.9809 - val_accuracy: 0.5277\n",
            "Epoch 41/150\n",
            "78/78 [==============================] - 35s 447ms/step - loss: 0.4490 - accuracy: 0.8573 - val_loss: 2.1755 - val_accuracy: 0.5147\n",
            "Epoch 42/150\n",
            "78/78 [==============================] - 35s 449ms/step - loss: 0.4870 - accuracy: 0.8665 - val_loss: 2.0982 - val_accuracy: 0.5537\n",
            "Epoch 43/150\n",
            "78/78 [==============================] - 35s 449ms/step - loss: 0.4595 - accuracy: 0.8486 - val_loss: 2.1535 - val_accuracy: 0.5147\n",
            "Epoch 44/150\n",
            "78/78 [==============================] - 35s 452ms/step - loss: 0.4073 - accuracy: 0.8767 - val_loss: 2.3676 - val_accuracy: 0.5016\n",
            "Epoch 45/150\n",
            "78/78 [==============================] - 35s 445ms/step - loss: 0.4915 - accuracy: 0.8312 - val_loss: 2.2303 - val_accuracy: 0.5179\n",
            "Epoch 46/150\n",
            "78/78 [==============================] - 35s 447ms/step - loss: 0.4826 - accuracy: 0.8538 - val_loss: 2.1061 - val_accuracy: 0.5309\n",
            "Epoch 47/150\n",
            "78/78 [==============================] - 34s 441ms/step - loss: 0.4031 - accuracy: 0.8714 - val_loss: 2.2308 - val_accuracy: 0.5309\n",
            "Epoch 48/150\n",
            "78/78 [==============================] - 35s 447ms/step - loss: 0.3763 - accuracy: 0.8694 - val_loss: 2.2370 - val_accuracy: 0.5537\n",
            "Epoch 49/150\n",
            "78/78 [==============================] - 35s 444ms/step - loss: 0.4147 - accuracy: 0.8712 - val_loss: 2.3383 - val_accuracy: 0.4951\n",
            "Epoch 50/150\n",
            "78/78 [==============================] - 35s 454ms/step - loss: 0.3127 - accuracy: 0.9034 - val_loss: 2.3885 - val_accuracy: 0.5244\n",
            "Epoch 51/150\n",
            "78/78 [==============================] - 35s 452ms/step - loss: 0.3288 - accuracy: 0.9003 - val_loss: 2.4195 - val_accuracy: 0.5147\n",
            "Epoch 52/150\n",
            "78/78 [==============================] - 35s 454ms/step - loss: 0.3078 - accuracy: 0.8958 - val_loss: 2.3796 - val_accuracy: 0.5342\n",
            "Epoch 53/150\n",
            "78/78 [==============================] - 36s 458ms/step - loss: 0.3015 - accuracy: 0.9069 - val_loss: 2.3731 - val_accuracy: 0.5472\n",
            "Epoch 54/150\n",
            "78/78 [==============================] - 36s 457ms/step - loss: 0.3511 - accuracy: 0.8937 - val_loss: 2.5767 - val_accuracy: 0.5147\n",
            "Epoch 55/150\n",
            "78/78 [==============================] - 35s 454ms/step - loss: 0.2908 - accuracy: 0.9090 - val_loss: 2.5982 - val_accuracy: 0.5049\n",
            "Epoch 56/150\n",
            "78/78 [==============================] - 35s 453ms/step - loss: 0.3107 - accuracy: 0.8981 - val_loss: 2.4205 - val_accuracy: 0.5081\n",
            "Epoch 57/150\n",
            "78/78 [==============================] - 35s 454ms/step - loss: 0.2929 - accuracy: 0.9092 - val_loss: 2.6875 - val_accuracy: 0.4886\n",
            "Epoch 58/150\n",
            "78/78 [==============================] - 35s 452ms/step - loss: 0.3026 - accuracy: 0.8994 - val_loss: 2.6966 - val_accuracy: 0.5147\n",
            "Epoch 59/150\n",
            "78/78 [==============================] - 35s 452ms/step - loss: 0.2547 - accuracy: 0.9210 - val_loss: 2.5886 - val_accuracy: 0.5342\n",
            "Epoch 60/150\n",
            "78/78 [==============================] - 35s 452ms/step - loss: 0.2134 - accuracy: 0.9348 - val_loss: 2.5705 - val_accuracy: 0.5375\n",
            "Epoch 61/150\n",
            "78/78 [==============================] - 35s 455ms/step - loss: 0.2470 - accuracy: 0.9170 - val_loss: 2.5598 - val_accuracy: 0.5244\n",
            "Epoch 62/150\n",
            "78/78 [==============================] - 35s 455ms/step - loss: 0.1918 - accuracy: 0.9389 - val_loss: 2.6719 - val_accuracy: 0.5081\n",
            "Epoch 63/150\n",
            "78/78 [==============================] - 36s 458ms/step - loss: 0.2181 - accuracy: 0.9464 - val_loss: 2.7301 - val_accuracy: 0.5277\n",
            "Epoch 64/150\n",
            "78/78 [==============================] - 35s 453ms/step - loss: 0.2113 - accuracy: 0.9400 - val_loss: 2.7410 - val_accuracy: 0.5244\n",
            "Epoch 65/150\n",
            "78/78 [==============================] - 35s 450ms/step - loss: 0.2044 - accuracy: 0.9432 - val_loss: 2.4920 - val_accuracy: 0.5147\n",
            "Epoch 66/150\n",
            "78/78 [==============================] - 35s 454ms/step - loss: 0.1787 - accuracy: 0.9442 - val_loss: 2.9854 - val_accuracy: 0.5081\n",
            "Epoch 67/150\n",
            "78/78 [==============================] - 35s 451ms/step - loss: 0.2384 - accuracy: 0.9177 - val_loss: 2.6403 - val_accuracy: 0.5212\n",
            "Epoch 68/150\n",
            "78/78 [==============================] - 36s 456ms/step - loss: 0.2101 - accuracy: 0.9264 - val_loss: 2.5864 - val_accuracy: 0.5016\n",
            "Epoch 69/150\n",
            "78/78 [==============================] - 35s 445ms/step - loss: 0.1991 - accuracy: 0.9392 - val_loss: 2.7954 - val_accuracy: 0.5081\n",
            "Epoch 70/150\n",
            "78/78 [==============================] - 35s 449ms/step - loss: 0.1700 - accuracy: 0.9397 - val_loss: 2.8856 - val_accuracy: 0.5440\n",
            "Epoch 71/150\n",
            "78/78 [==============================] - 35s 449ms/step - loss: 0.1603 - accuracy: 0.9573 - val_loss: 2.8884 - val_accuracy: 0.4886\n",
            "Epoch 72/150\n",
            "78/78 [==============================] - 35s 449ms/step - loss: 0.1872 - accuracy: 0.9346 - val_loss: 2.6672 - val_accuracy: 0.5375\n",
            "Epoch 73/150\n",
            "78/78 [==============================] - 34s 441ms/step - loss: 0.1677 - accuracy: 0.9520 - val_loss: 2.6668 - val_accuracy: 0.5375\n",
            "Epoch 74/150\n",
            "78/78 [==============================] - 35s 446ms/step - loss: 0.1464 - accuracy: 0.9591 - val_loss: 2.7167 - val_accuracy: 0.5570\n",
            "Epoch 75/150\n",
            "78/78 [==============================] - 35s 451ms/step - loss: 0.2507 - accuracy: 0.9276 - val_loss: 2.9277 - val_accuracy: 0.4723\n",
            "Epoch 76/150\n",
            "78/78 [==============================] - 34s 441ms/step - loss: 0.1459 - accuracy: 0.9513 - val_loss: 2.6535 - val_accuracy: 0.4919\n",
            "Epoch 77/150\n",
            "78/78 [==============================] - 35s 445ms/step - loss: 0.1464 - accuracy: 0.9543 - val_loss: 2.8657 - val_accuracy: 0.5309\n",
            "Epoch 78/150\n",
            "78/78 [==============================] - 35s 443ms/step - loss: 0.1392 - accuracy: 0.9654 - val_loss: 2.8963 - val_accuracy: 0.5114\n",
            "Epoch 79/150\n",
            "78/78 [==============================] - 35s 446ms/step - loss: 0.1384 - accuracy: 0.9642 - val_loss: 2.9505 - val_accuracy: 0.5081\n",
            "Epoch 80/150\n",
            "78/78 [==============================] - 35s 447ms/step - loss: 0.1328 - accuracy: 0.9560 - val_loss: 2.6941 - val_accuracy: 0.5342\n",
            "Epoch 81/150\n",
            "78/78 [==============================] - 35s 452ms/step - loss: 0.1914 - accuracy: 0.9522 - val_loss: 2.6329 - val_accuracy: 0.5212\n",
            "Epoch 82/150\n",
            "78/78 [==============================] - 35s 445ms/step - loss: 0.1854 - accuracy: 0.9458 - val_loss: 2.6744 - val_accuracy: 0.5147\n",
            "Epoch 83/150\n",
            "78/78 [==============================] - 35s 444ms/step - loss: 0.1204 - accuracy: 0.9600 - val_loss: 2.9059 - val_accuracy: 0.5244\n",
            "Epoch 84/150\n",
            "78/78 [==============================] - 35s 446ms/step - loss: 0.1287 - accuracy: 0.9638 - val_loss: 3.0745 - val_accuracy: 0.4984\n",
            "Epoch 85/150\n",
            "78/78 [==============================] - 35s 448ms/step - loss: 0.1030 - accuracy: 0.9657 - val_loss: 2.9599 - val_accuracy: 0.4984\n",
            "Epoch 86/150\n",
            "78/78 [==============================] - 35s 450ms/step - loss: 0.1633 - accuracy: 0.9602 - val_loss: 2.8383 - val_accuracy: 0.5244\n",
            "Epoch 87/150\n",
            "78/78 [==============================] - 35s 446ms/step - loss: 0.1708 - accuracy: 0.9373 - val_loss: 2.6901 - val_accuracy: 0.5309\n",
            "Epoch 88/150\n",
            "78/78 [==============================] - 35s 449ms/step - loss: 0.1534 - accuracy: 0.9540 - val_loss: 2.8335 - val_accuracy: 0.5244\n",
            "Epoch 89/150\n",
            "78/78 [==============================] - 35s 451ms/step - loss: 0.1135 - accuracy: 0.9575 - val_loss: 2.8918 - val_accuracy: 0.5179\n",
            "Epoch 90/150\n",
            "78/78 [==============================] - 35s 444ms/step - loss: 0.1379 - accuracy: 0.9586 - val_loss: 2.9384 - val_accuracy: 0.5244\n",
            "Epoch 91/150\n",
            "78/78 [==============================] - 35s 450ms/step - loss: 0.1049 - accuracy: 0.9686 - val_loss: 2.9944 - val_accuracy: 0.5309\n",
            "Epoch 92/150\n",
            "78/78 [==============================] - 35s 445ms/step - loss: 0.1245 - accuracy: 0.9672 - val_loss: 3.1452 - val_accuracy: 0.4984\n",
            "Epoch 93/150\n",
            "78/78 [==============================] - 36s 456ms/step - loss: 0.1268 - accuracy: 0.9596 - val_loss: 3.1198 - val_accuracy: 0.5016\n",
            "Epoch 94/150\n",
            "78/78 [==============================] - 35s 450ms/step - loss: 0.1407 - accuracy: 0.9570 - val_loss: 3.0159 - val_accuracy: 0.5472\n",
            "Epoch 95/150\n",
            "78/78 [==============================] - 35s 454ms/step - loss: 0.1380 - accuracy: 0.9585 - val_loss: 3.1708 - val_accuracy: 0.5016\n",
            "Epoch 96/150\n",
            "78/78 [==============================] - 35s 450ms/step - loss: 0.1369 - accuracy: 0.9562 - val_loss: 3.2914 - val_accuracy: 0.4821\n",
            "Epoch 97/150\n",
            "78/78 [==============================] - 35s 452ms/step - loss: 0.1247 - accuracy: 0.9500 - val_loss: 2.7067 - val_accuracy: 0.5798\n",
            "Epoch 98/150\n",
            "78/78 [==============================] - 35s 451ms/step - loss: 0.0806 - accuracy: 0.9833 - val_loss: 2.9733 - val_accuracy: 0.5179\n",
            "Epoch 99/150\n",
            "78/78 [==============================] - 35s 447ms/step - loss: 0.1322 - accuracy: 0.9512 - val_loss: 2.8465 - val_accuracy: 0.5016\n",
            "Epoch 100/150\n",
            "78/78 [==============================] - 35s 449ms/step - loss: 0.1098 - accuracy: 0.9682 - val_loss: 2.8479 - val_accuracy: 0.5440\n",
            "Epoch 101/150\n",
            "78/78 [==============================] - 35s 449ms/step - loss: 0.1139 - accuracy: 0.9676 - val_loss: 2.8903 - val_accuracy: 0.5342\n",
            "Epoch 102/150\n",
            "78/78 [==============================] - 35s 446ms/step - loss: 0.1054 - accuracy: 0.9712 - val_loss: 2.8853 - val_accuracy: 0.5537\n",
            "Epoch 103/150\n",
            "78/78 [==============================] - 35s 452ms/step - loss: 0.1185 - accuracy: 0.9641 - val_loss: 3.1117 - val_accuracy: 0.5081\n",
            "Epoch 104/150\n",
            "78/78 [==============================] - 35s 448ms/step - loss: 0.0612 - accuracy: 0.9888 - val_loss: 3.1371 - val_accuracy: 0.5505\n",
            "Epoch 105/150\n",
            "78/78 [==============================] - 35s 451ms/step - loss: 0.1150 - accuracy: 0.9802 - val_loss: 2.9887 - val_accuracy: 0.5342\n",
            "Epoch 106/150\n",
            "78/78 [==============================] - 35s 442ms/step - loss: 0.1284 - accuracy: 0.9553 - val_loss: 2.9497 - val_accuracy: 0.4919\n",
            "Epoch 107/150\n",
            "78/78 [==============================] - 35s 444ms/step - loss: 0.1052 - accuracy: 0.9696 - val_loss: 2.9373 - val_accuracy: 0.5114\n",
            "Epoch 108/150\n",
            "78/78 [==============================] - 35s 445ms/step - loss: 0.0494 - accuracy: 0.9902 - val_loss: 3.1138 - val_accuracy: 0.5505\n",
            "Epoch 109/150\n",
            "78/78 [==============================] - 35s 447ms/step - loss: 0.0664 - accuracy: 0.9834 - val_loss: 3.1815 - val_accuracy: 0.5277\n",
            "Epoch 110/150\n",
            "78/78 [==============================] - 35s 443ms/step - loss: 0.0814 - accuracy: 0.9677 - val_loss: 3.1276 - val_accuracy: 0.5179\n",
            "Epoch 111/150\n",
            "78/78 [==============================] - 35s 448ms/step - loss: 0.1116 - accuracy: 0.9578 - val_loss: 3.1576 - val_accuracy: 0.5179\n",
            "Epoch 112/150\n",
            "78/78 [==============================] - 34s 441ms/step - loss: 0.0959 - accuracy: 0.9751 - val_loss: 3.0898 - val_accuracy: 0.5244\n",
            "Epoch 113/150\n",
            "78/78 [==============================] - 35s 447ms/step - loss: 0.1131 - accuracy: 0.9592 - val_loss: 3.0851 - val_accuracy: 0.5244\n",
            "Epoch 114/150\n",
            "78/78 [==============================] - 35s 445ms/step - loss: 0.1697 - accuracy: 0.9558 - val_loss: 3.0358 - val_accuracy: 0.5049\n",
            "Epoch 115/150\n",
            "78/78 [==============================] - 35s 448ms/step - loss: 0.1374 - accuracy: 0.9528 - val_loss: 2.8048 - val_accuracy: 0.5147\n",
            "Epoch 116/150\n",
            "78/78 [==============================] - 34s 441ms/step - loss: 0.0939 - accuracy: 0.9738 - val_loss: 2.7048 - val_accuracy: 0.5765\n",
            "Epoch 117/150\n",
            "78/78 [==============================] - 35s 446ms/step - loss: 0.0516 - accuracy: 0.9883 - val_loss: 2.9859 - val_accuracy: 0.5114\n",
            "Epoch 118/150\n",
            "78/78 [==============================] - 34s 442ms/step - loss: 0.0972 - accuracy: 0.9681 - val_loss: 3.0981 - val_accuracy: 0.5342\n",
            "Epoch 119/150\n",
            "78/78 [==============================] - 35s 450ms/step - loss: 0.0682 - accuracy: 0.9896 - val_loss: 2.8366 - val_accuracy: 0.5277\n",
            "Epoch 120/150\n",
            "78/78 [==============================] - 34s 441ms/step - loss: 0.0559 - accuracy: 0.9724 - val_loss: 3.1264 - val_accuracy: 0.5407\n",
            "Epoch 121/150\n",
            "78/78 [==============================] - 35s 448ms/step - loss: 0.0286 - accuracy: 0.9926 - val_loss: 2.9710 - val_accuracy: 0.5537\n",
            "Epoch 122/150\n",
            "78/78 [==============================] - 35s 444ms/step - loss: 0.0599 - accuracy: 0.9800 - val_loss: 3.1328 - val_accuracy: 0.5668\n",
            "Epoch 123/150\n",
            "78/78 [==============================] - 36s 456ms/step - loss: 0.1445 - accuracy: 0.9597 - val_loss: 3.2521 - val_accuracy: 0.4951\n",
            "Epoch 124/150\n",
            "78/78 [==============================] - 35s 449ms/step - loss: 0.1495 - accuracy: 0.9265 - val_loss: 2.9420 - val_accuracy: 0.5537\n",
            "Epoch 125/150\n",
            "78/78 [==============================] - 35s 451ms/step - loss: 0.0879 - accuracy: 0.9808 - val_loss: 2.9942 - val_accuracy: 0.5537\n",
            "Epoch 126/150\n",
            "78/78 [==============================] - 35s 448ms/step - loss: 0.0603 - accuracy: 0.9731 - val_loss: 3.0863 - val_accuracy: 0.5277\n",
            "Epoch 127/150\n",
            "78/78 [==============================] - 35s 446ms/step - loss: 0.0724 - accuracy: 0.9865 - val_loss: 3.2281 - val_accuracy: 0.5244\n",
            "Epoch 128/150\n",
            "78/78 [==============================] - 35s 448ms/step - loss: 0.0551 - accuracy: 0.9750 - val_loss: 3.3510 - val_accuracy: 0.4984\n",
            "Epoch 129/150\n",
            "78/78 [==============================] - 36s 457ms/step - loss: 0.0847 - accuracy: 0.9833 - val_loss: 3.6094 - val_accuracy: 0.5277\n",
            "Epoch 130/150\n",
            "78/78 [==============================] - 35s 444ms/step - loss: 0.1515 - accuracy: 0.9553 - val_loss: 3.1818 - val_accuracy: 0.5375\n",
            "Epoch 131/150\n",
            "78/78 [==============================] - 35s 453ms/step - loss: 0.1045 - accuracy: 0.9777 - val_loss: 2.9503 - val_accuracy: 0.5570\n",
            "Epoch 132/150\n",
            "78/78 [==============================] - 35s 445ms/step - loss: 0.0907 - accuracy: 0.9764 - val_loss: 2.8242 - val_accuracy: 0.5635\n",
            "Epoch 133/150\n",
            "78/78 [==============================] - 35s 455ms/step - loss: 0.0608 - accuracy: 0.9815 - val_loss: 3.0408 - val_accuracy: 0.5147\n",
            "Epoch 134/150\n",
            "78/78 [==============================] - 35s 452ms/step - loss: 0.0720 - accuracy: 0.9789 - val_loss: 3.0027 - val_accuracy: 0.5179\n",
            "Epoch 135/150\n",
            "78/78 [==============================] - 35s 447ms/step - loss: 0.0590 - accuracy: 0.9780 - val_loss: 3.1649 - val_accuracy: 0.5147\n",
            "Epoch 136/150\n",
            "78/78 [==============================] - 35s 449ms/step - loss: 0.0614 - accuracy: 0.9770 - val_loss: 3.3782 - val_accuracy: 0.5179\n",
            "Epoch 137/150\n",
            "78/78 [==============================] - 35s 445ms/step - loss: 0.1196 - accuracy: 0.9586 - val_loss: 3.2026 - val_accuracy: 0.4984\n",
            "Epoch 138/150\n",
            "78/78 [==============================] - 35s 447ms/step - loss: 0.0644 - accuracy: 0.9807 - val_loss: 3.3025 - val_accuracy: 0.5375\n",
            "Epoch 139/150\n",
            "78/78 [==============================] - 35s 450ms/step - loss: 0.0744 - accuracy: 0.9770 - val_loss: 3.2177 - val_accuracy: 0.5179\n",
            "Epoch 140/150\n",
            "78/78 [==============================] - 35s 446ms/step - loss: 0.1395 - accuracy: 0.9549 - val_loss: 3.2048 - val_accuracy: 0.5114\n",
            "Epoch 141/150\n",
            "78/78 [==============================] - 35s 453ms/step - loss: 0.0804 - accuracy: 0.9759 - val_loss: 3.2323 - val_accuracy: 0.5309\n",
            "Epoch 142/150\n",
            "78/78 [==============================] - 36s 455ms/step - loss: 0.1084 - accuracy: 0.9692 - val_loss: 2.7542 - val_accuracy: 0.5635\n",
            "Epoch 143/150\n",
            "78/78 [==============================] - 34s 442ms/step - loss: 0.0737 - accuracy: 0.9839 - val_loss: 2.9883 - val_accuracy: 0.5537\n",
            "Epoch 144/150\n",
            "78/78 [==============================] - 34s 441ms/step - loss: 0.0761 - accuracy: 0.9786 - val_loss: 3.1799 - val_accuracy: 0.5342\n",
            "Epoch 145/150\n",
            "78/78 [==============================] - 35s 448ms/step - loss: 0.0835 - accuracy: 0.9807 - val_loss: 2.9671 - val_accuracy: 0.5309\n",
            "Epoch 146/150\n",
            "78/78 [==============================] - 35s 445ms/step - loss: 0.0426 - accuracy: 0.9847 - val_loss: 2.9755 - val_accuracy: 0.5472\n",
            "Epoch 147/150\n",
            "78/78 [==============================] - 35s 451ms/step - loss: 0.0431 - accuracy: 0.9863 - val_loss: 3.2033 - val_accuracy: 0.5212\n",
            "Epoch 148/150\n",
            "78/78 [==============================] - 34s 440ms/step - loss: 0.0349 - accuracy: 0.9884 - val_loss: 3.0955 - val_accuracy: 0.5668\n",
            "Epoch 149/150\n",
            "78/78 [==============================] - 35s 450ms/step - loss: 0.0599 - accuracy: 0.9827 - val_loss: 3.2175 - val_accuracy: 0.5342\n",
            "Epoch 150/150\n",
            "78/78 [==============================] - 34s 440ms/step - loss: 0.0323 - accuracy: 0.9938 - val_loss: 3.2957 - val_accuracy: 0.5505\n",
            "eval_out [3.114566683769226, 0.54723126]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZvDtHOfUBsI1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.classifier.to_json()\n",
        "backup_model = model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tHgZPUAerKXi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "outputId": "32fa9578-3615-441a-d0b8-49368e6d34c2"
      },
      "source": [
        "model.summary()\n",
        "\n",
        "model_filename = os.path.join('/content/drive/My Drive/Colab Notebooks/models', \"model_\"+model_name +\".json\")\n",
        "\n",
        "model_json = model.classifier.to_json()\n",
        "json_file = open(model_filename, \"a\")\n",
        "json_file.write(model_json)\n",
        "    \n",
        "# # serialize weights to HDF5\n",
        "model.save_weights(model_filename+\".h5\")\n",
        "\n",
        "\n",
        "model.save(model_filename + '.tf', save_format=\"tf\")\n",
        "model.save_weights(model_filename + '.weights', save_format=\"tf\")\n",
        "# Generate predictions\n",
        "# -------------------\n",
        "# generate_predictions(model, model_name)"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"cnn_classifier_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "sequential_4 (Sequential)    multiple                  1568576   \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          multiple                  0         \n",
            "_________________________________________________________________\n",
            "sequential_5 (Sequential)    multiple                  17313300  \n",
            "=================================================================\n",
            "Total params: 18,881,876\n",
            "Trainable params: 18,881,876\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/models/model_CNN.json.tf/assets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fslGHMFxJ_qW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8c630b39-150e-4f2d-fd45-6e29eca5a6bc"
      },
      "source": [
        "# dir(model)\n",
        "# loaded_model = tf.saved_model.load(model_filename+'.tf')\n",
        "# dir(loaded_model)\n",
        "# new_model.compile(loss='sparse_categorical_crossentropy',\n",
        "#                   optimizer=keras.optimizers.RMSprop())\n",
        "\n",
        "# # This initializes the variables used by the optimizers,\n",
        "# # as well as any stateful metric variables\n",
        "# new_model.train_on_batch(x_train[:1], y_train[:1])\n",
        "\n",
        "new_model = CNNClassifier(depth=depth,\n",
        "                      num_filters=num_filters,\n",
        "                      pool_size=pool_size,\n",
        "                      kernel_size=kernel_size,\n",
        "                      num_classes=num_classes)\n",
        "\n",
        "# Build Model (Required)\n",
        "new_model.build(input_shape=(None, img_h, img_w, channels))\n",
        "\n",
        "loss = tf.keras.losses.CategoricalCrossentropy()\n",
        "lr = 1e-4  # learning rate\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n",
        "metrics = ['accuracy']  # validation metrics to monitor\n",
        "\n",
        "new_model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
        "\n",
        "# Train the model\n",
        "# ---------------\n",
        "with_early_stopping = True\n",
        "\n",
        "callbacks = []\n",
        "if with_early_stopping:\n",
        "    callbacks.append(\n",
        "        tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
        "                                            patience=epochs * 0.2))\n",
        "\n",
        "# train on 0 epochs\n",
        "model.fit_generator(generator=train_generator,\n",
        "                                    epochs=0,\n",
        "                                    steps_per_epoch=len(train_generator),\n",
        "                                    validation_data=valid_generator,\n",
        "                                    validation_steps=len(valid_generator))\n",
        "\n",
        "# Load the state of the old model\n",
        "new_model.load_weights(model_filename + '.weights')"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['_TF_MODULE_IGNORED_PROPERTIES',\n",
              " '__call__',\n",
              " '__class__',\n",
              " '__delattr__',\n",
              " '__dict__',\n",
              " '__dir__',\n",
              " '__doc__',\n",
              " '__eq__',\n",
              " '__format__',\n",
              " '__ge__',\n",
              " '__getattribute__',\n",
              " '__gt__',\n",
              " '__hash__',\n",
              " '__init__',\n",
              " '__init_subclass__',\n",
              " '__le__',\n",
              " '__lt__',\n",
              " '__module__',\n",
              " '__ne__',\n",
              " '__new__',\n",
              " '__reduce__',\n",
              " '__reduce_ex__',\n",
              " '__repr__',\n",
              " '__setattr__',\n",
              " '__sizeof__',\n",
              " '__str__',\n",
              " '__subclasshook__',\n",
              " '__weakref__',\n",
              " '_activity_regularizer',\n",
              " '_add_inbound_node',\n",
              " '_add_unique_metric_name',\n",
              " '_add_variable_with_custom_getter',\n",
              " '_assert_compile_was_called',\n",
              " '_assert_weights_created',\n",
              " '_autocast',\n",
              " '_base_init',\n",
              " '_build_model_with_inputs',\n",
              " '_cache_output_metric_attributes',\n",
              " '_call_accepts_kwargs',\n",
              " '_call_arg_was_passed',\n",
              " '_call_fn_args',\n",
              " '_callable_losses',\n",
              " '_check_call_args',\n",
              " '_check_trainable_weights_consistency',\n",
              " '_checkpoint_dependencies',\n",
              " '_clear_losses',\n",
              " '_collect_input_masks',\n",
              " '_compile_distribution',\n",
              " '_compile_eagerly',\n",
              " '_compile_from_inputs',\n",
              " '_compile_metric_functions',\n",
              " '_compile_metrics',\n",
              " '_compile_time_distribution_strategy',\n",
              " '_compile_weighted_metrics',\n",
              " '_compile_weights_loss_and_weighted_metrics',\n",
              " '_compiled_trainable_state',\n",
              " '_compute_dtype',\n",
              " '_compute_output_and_mask_jointly',\n",
              " '_dedup_weights',\n",
              " '_deferred_dependencies',\n",
              " '_distributed_function_cache',\n",
              " '_distributed_model_cache',\n",
              " '_distribution_standardize_user_data',\n",
              " '_distribution_strategy',\n",
              " '_dtype',\n",
              " '_dtype_defaulted_to_floatx',\n",
              " '_dtype_policy',\n",
              " '_dynamic',\n",
              " '_eager_add_metric',\n",
              " '_eager_losses',\n",
              " '_expects_mask_arg',\n",
              " '_expects_training_arg',\n",
              " '_experimental_run_tf_function',\n",
              " '_feed_loss_fns',\n",
              " '_feed_output_names',\n",
              " '_feed_output_shapes',\n",
              " '_feed_sample_weights',\n",
              " '_feed_targets',\n",
              " '_flatten',\n",
              " '_gather_children_attribute',\n",
              " '_gather_saveables_for_checkpoint',\n",
              " '_get_call_arg_value',\n",
              " '_get_callback_model',\n",
              " '_get_existing_metric',\n",
              " '_get_node_attribute_at_index',\n",
              " '_get_trainable_state',\n",
              " '_get_training_eval_metrics',\n",
              " '_graph',\n",
              " '_graph_network_add_loss',\n",
              " '_graph_network_add_metric',\n",
              " '_handle_activity_regularization',\n",
              " '_handle_deferred_dependencies',\n",
              " '_handle_metrics',\n",
              " '_handle_per_output_metrics',\n",
              " '_handle_weight_regularization',\n",
              " '_inbound_nodes',\n",
              " '_init_call_fn_args',\n",
              " '_init_distributed_function_cache_if_not_compiled',\n",
              " '_init_graph_network',\n",
              " '_init_metric_attributes',\n",
              " '_init_set_name',\n",
              " '_init_subclassed_network',\n",
              " '_insert_layers',\n",
              " '_is_compiled',\n",
              " '_is_graph_network',\n",
              " '_is_layer',\n",
              " '_keras_api_names',\n",
              " '_keras_api_names_v1',\n",
              " '_layers',\n",
              " '_list_extra_dependencies_for_serialization',\n",
              " '_list_functions_for_serialization',\n",
              " '_lookup_dependency',\n",
              " '_loss_weights_list',\n",
              " '_losses',\n",
              " '_make_callback_model',\n",
              " '_make_execution_function',\n",
              " '_make_predict_function',\n",
              " '_make_test_function',\n",
              " '_make_train_function',\n",
              " '_maybe_build',\n",
              " '_maybe_cast_inputs',\n",
              " '_maybe_create_attribute',\n",
              " '_maybe_initialize_trackable',\n",
              " '_maybe_load_initial_epoch_from_ckpt',\n",
              " '_metrics',\n",
              " '_name',\n",
              " '_name_based_attribute_restore',\n",
              " '_name_based_restores',\n",
              " '_name_scope',\n",
              " '_no_dependency',\n",
              " '_non_trainable_weights',\n",
              " '_obj_reference_counts',\n",
              " '_obj_reference_counts_dict',\n",
              " '_object_identifier',\n",
              " '_outbound_nodes',\n",
              " '_output_loss_metrics',\n",
              " '_preload_simple_restoration',\n",
              " '_prepare_output_masks',\n",
              " '_prepare_sample_weights',\n",
              " '_prepare_skip_target_masks',\n",
              " '_prepare_total_loss',\n",
              " '_prepare_validation_data',\n",
              " '_process_target_tensor_for_compile',\n",
              " '_recompile_weights_loss_and_weighted_metrics',\n",
              " '_restore_from_checkpoint_position',\n",
              " '_reuse',\n",
              " '_run_eagerly',\n",
              " '_run_internal_graph',\n",
              " '_sample_weight_modes',\n",
              " '_scope',\n",
              " '_select_training_loop',\n",
              " '_self_name_based_restores',\n",
              " '_self_setattr_tracking',\n",
              " '_self_unconditional_checkpoint_dependencies',\n",
              " '_self_unconditional_deferred_dependencies',\n",
              " '_self_unconditional_dependency_names',\n",
              " '_self_update_uid',\n",
              " '_set_connectivity_metadata_',\n",
              " '_set_dtype_policy',\n",
              " '_set_input_attrs',\n",
              " '_set_inputs',\n",
              " '_set_mask_metadata',\n",
              " '_set_metric_attributes',\n",
              " '_set_optimizer',\n",
              " '_set_output_attrs',\n",
              " '_set_output_names',\n",
              " '_set_per_output_metric_attributes',\n",
              " '_set_trainable_state',\n",
              " '_setattr_tracking',\n",
              " '_should_compute_mask',\n",
              " '_single_restoration_from_checkpoint_position',\n",
              " '_standardize_user_data',\n",
              " '_symbolic_add_metric',\n",
              " '_symbolic_call',\n",
              " '_targets',\n",
              " '_tf_api_names',\n",
              " '_tf_api_names_v1',\n",
              " '_thread_local',\n",
              " '_track_layers',\n",
              " '_track_trackable',\n",
              " '_trackable_saved_model_saver',\n",
              " '_trackable_saver',\n",
              " '_tracking_metadata',\n",
              " '_trainable',\n",
              " '_trainable_weights',\n",
              " '_training_endpoints',\n",
              " '_unconditional_checkpoint_dependencies',\n",
              " '_unconditional_dependency_names',\n",
              " '_undeduplicated_weights',\n",
              " '_update_sample_weight_modes',\n",
              " '_update_uid',\n",
              " '_updated_config',\n",
              " '_updates',\n",
              " '_validate_compile_param_for_distribution_strategy',\n",
              " '_validate_graph_inputs_and_outputs',\n",
              " '_validate_or_infer_batch_size',\n",
              " '_warn_about_input_casting',\n",
              " 'activity_regularizer',\n",
              " 'add_loss',\n",
              " 'add_metric',\n",
              " 'add_update',\n",
              " 'add_variable',\n",
              " 'add_weight',\n",
              " 'apply',\n",
              " 'build',\n",
              " 'built',\n",
              " 'call',\n",
              " 'classifier',\n",
              " 'compile',\n",
              " 'compute_mask',\n",
              " 'compute_output_shape',\n",
              " 'compute_output_signature',\n",
              " 'count_params',\n",
              " 'dtype',\n",
              " 'dynamic',\n",
              " 'evaluate',\n",
              " 'evaluate_generator',\n",
              " 'feature_extractor',\n",
              " 'fit',\n",
              " 'fit_generator',\n",
              " 'flatten',\n",
              " 'from_config',\n",
              " 'get_config',\n",
              " 'get_input_at',\n",
              " 'get_input_mask_at',\n",
              " 'get_input_shape_at',\n",
              " 'get_layer',\n",
              " 'get_losses_for',\n",
              " 'get_output_at',\n",
              " 'get_output_mask_at',\n",
              " 'get_output_shape_at',\n",
              " 'get_updates_for',\n",
              " 'get_weights',\n",
              " 'inbound_nodes',\n",
              " 'input',\n",
              " 'input_mask',\n",
              " 'input_shape',\n",
              " 'input_spec',\n",
              " 'inputs',\n",
              " 'layers',\n",
              " 'load_weights',\n",
              " 'loss',\n",
              " 'loss_weights',\n",
              " 'losses',\n",
              " 'metrics',\n",
              " 'metrics_names',\n",
              " 'name',\n",
              " 'name_scope',\n",
              " 'non_trainable_variables',\n",
              " 'non_trainable_weights',\n",
              " 'optimizer',\n",
              " 'outbound_nodes',\n",
              " 'output',\n",
              " 'output_mask',\n",
              " 'output_shape',\n",
              " 'outputs',\n",
              " 'predict',\n",
              " 'predict_generator',\n",
              " 'predict_on_batch',\n",
              " 'reset_metrics',\n",
              " 'reset_states',\n",
              " 'run_eagerly',\n",
              " 'sample_weight_mode',\n",
              " 'sample_weights',\n",
              " 'save',\n",
              " 'save_weights',\n",
              " 'set_weights',\n",
              " 'state_updates',\n",
              " 'stateful',\n",
              " 'submodules',\n",
              " 'summary',\n",
              " 'supports_masking',\n",
              " 'test_on_batch',\n",
              " 'to_json',\n",
              " 'to_yaml',\n",
              " 'train_on_batch',\n",
              " 'trainable',\n",
              " 'trainable_variables',\n",
              " 'trainable_weights',\n",
              " 'updates',\n",
              " 'variables',\n",
              " 'weights',\n",
              " 'with_name_scope']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "09AZ1dFTLmI0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "4e3f75d4-3ec1-4c57-a6af-2357927db7f0"
      },
      "source": [
        "\n",
        "print('CNN Evaluation output', cnn_eval_output)\n",
        "print('Transfer Learning Evaluation output', tl_eval_output)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CNN Evaluation output [3.7348770022392275, 0.52117264]\n",
            "Transfer Learning Evaluation output \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kM2r4FtVDECt",
        "colab_type": "text"
      },
      "source": [
        "**Transfer learning using our CNN model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wSYeH1_MDCSr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "603aa144-d06c-4c78-a923-cc30efddb136"
      },
      "source": [
        "#load the entire model and check everything is correct \n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.models import model_from_json\n",
        "\n",
        "cnn_model = new_model\n",
        "cnn_model.summary()\n"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"cnn_classifier_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "sequential_6 (Sequential)    multiple                  1568576   \n",
            "_________________________________________________________________\n",
            "flatten_4 (Flatten)          multiple                  0         \n",
            "_________________________________________________________________\n",
            "sequential_7 (Sequential)    multiple                  17313300  \n",
            "=================================================================\n",
            "Total params: 18,881,876\n",
            "Trainable params: 18,881,876\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A1aU4TJpOWLE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ec133b36-c282-4a30-8141-00e0f5aa1069"
      },
      "source": [
        "\n",
        "model_name = 'Custom-CNN-TF'\n",
        "\n",
        "# build a classifier model to put on top of the convolutional model\n",
        "\n",
        "# Two types of transfer learning: feature extraction and fine-tuning\n",
        "fine_tuning = True\n",
        "\n",
        "if fine_tuning:\n",
        "    freeze_until = 8  # layer from which we want to fine-tune\n",
        "\n",
        "    # set the first freeze_until layers (up to the last conv block => depth = 5)\n",
        "    # to non-trainable (weights will not be updated)\n",
        "    for layer in cnn_model.layers[:freeze_until]:\n",
        "        layer.trainable = False\n",
        "\n",
        "else:\n",
        "    cnn_model.trainable = False\n",
        "\n",
        "model = tf.keras.Sequential()\n",
        "model.add(cnn_model)\n",
        "model.add(tf.keras.layers.Flatten())\n",
        "\n",
        "# dense layers\n",
        "model.add(tf.keras.layers.Dense(units=512, activation='relu'))\n",
        "model.add(tf.keras.layers.Dense(units=512, activation='relu'))\n",
        "model.add(tf.keras.layers.Dense(units=512, activation='relu'))\n",
        "model.add(tf.keras.layers.Dense(units=512, activation='relu'))\n",
        "model.add(tf.keras.layers.Dense(units=512, activation='relu'))\n",
        "model.add(tf.keras.layers.Dense(units=512, activation='relu'))\n",
        "\n",
        "# final layer with softmax activation\n",
        "model.add(tf.keras.layers.Dense(units=num_classes, activation='softmax'))\n",
        "\n",
        "# Visualize created model as a table\n",
        "# model.summary()\n",
        "\n",
        "# Visualize initialized weights\n",
        "# print(\"model.weights\", model.weights)\n",
        "\n",
        "# Prepare the model for training\n",
        "# ------------------------------\n",
        "loss = tf.keras.losses.CategoricalCrossentropy()\n",
        "\n",
        "# learning rate\n",
        "lr = 1e-4\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n",
        "\n",
        "metrics = ['accuracy']  # validation metrics to monitor\n",
        "\n",
        "model.compile(optimizer=optimizer,\n",
        "                loss=loss,\n",
        "                metrics=metrics)\n",
        "\n",
        "step_size_train = train_generator.n // train_generator.batch_size\n",
        "trained_model = model.fit_generator(generator=train_generator,\n",
        "                                    steps_per_epoch=step_size_train,\n",
        "                                    epochs=epochs)\n",
        "\n",
        "#     print('\\nhistory dict:', trained_model.history)\n",
        "\n",
        "\n",
        "# Model evaluation\n",
        "# ----------------\n",
        "\n",
        "eval_out = model.evaluate_generator(valid_generator,\n",
        "                                    steps=len(valid_generator),\n",
        "                                    verbose=0)\n",
        "\n",
        "print('eval_out', eval_out)\n",
        "\n",
        "# # /content/drive/My Drive/Colab Notebooks\n",
        "# save_model('/content/drive/My Drive/Colab Notebooks', model, model_name)\n",
        "\n",
        "# # Check Performance\n",
        "# # visualize_performance(trained_model)\n",
        "\n",
        "# # Generate predictions\n",
        "# # -------------------\n",
        "# generate_predictions(model, model_name)\n"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n",
            "77/77 [==============================] - 30s 389ms/step - loss: 2.5613 - accuracy: 0.5774\n",
            "Epoch 2/150\n",
            "77/77 [==============================] - 29s 378ms/step - loss: 0.3730 - accuracy: 0.9493\n",
            "Epoch 3/150\n",
            "77/77 [==============================] - 30s 383ms/step - loss: 0.0603 - accuracy: 0.9902\n",
            "Epoch 4/150\n",
            "77/77 [==============================] - 29s 380ms/step - loss: 0.0362 - accuracy: 0.9889\n",
            "Epoch 5/150\n",
            "77/77 [==============================] - 30s 387ms/step - loss: 0.0733 - accuracy: 0.9884\n",
            "Epoch 6/150\n",
            "77/77 [==============================] - 30s 385ms/step - loss: 0.0273 - accuracy: 0.9935\n",
            "Epoch 7/150\n",
            "77/77 [==============================] - 30s 387ms/step - loss: 0.0643 - accuracy: 0.9891\n",
            "Epoch 8/150\n",
            "77/77 [==============================] - 29s 381ms/step - loss: 0.0304 - accuracy: 0.9904\n",
            "Epoch 9/150\n",
            "77/77 [==============================] - 30s 389ms/step - loss: 0.0701 - accuracy: 0.9859\n",
            "Epoch 10/150\n",
            "77/77 [==============================] - 29s 381ms/step - loss: 0.0362 - accuracy: 0.9951\n",
            "Epoch 11/150\n",
            "77/77 [==============================] - 29s 382ms/step - loss: 0.0356 - accuracy: 0.9910\n",
            "Epoch 12/150\n",
            "77/77 [==============================] - 30s 388ms/step - loss: 0.0364 - accuracy: 0.9906\n",
            "Epoch 13/150\n",
            "77/77 [==============================] - 30s 384ms/step - loss: 0.0180 - accuracy: 0.9947\n",
            "Epoch 14/150\n",
            "77/77 [==============================] - 30s 385ms/step - loss: 0.0206 - accuracy: 0.9967\n",
            "Epoch 15/150\n",
            "77/77 [==============================] - 30s 389ms/step - loss: 0.0427 - accuracy: 0.9958\n",
            "Epoch 16/150\n",
            "77/77 [==============================] - 29s 382ms/step - loss: 0.0649 - accuracy: 0.9853\n",
            "Epoch 17/150\n",
            "77/77 [==============================] - 30s 388ms/step - loss: 0.0522 - accuracy: 0.9941\n",
            "Epoch 18/150\n",
            "77/77 [==============================] - 29s 381ms/step - loss: 0.0444 - accuracy: 0.9937\n",
            "Epoch 19/150\n",
            "77/77 [==============================] - 30s 388ms/step - loss: 0.0388 - accuracy: 0.9935\n",
            "Epoch 20/150\n",
            "77/77 [==============================] - 29s 380ms/step - loss: 0.0268 - accuracy: 0.9960\n",
            "Epoch 21/150\n",
            "77/77 [==============================] - 30s 386ms/step - loss: 0.0398 - accuracy: 0.9922\n",
            "Epoch 22/150\n",
            "77/77 [==============================] - 30s 388ms/step - loss: 0.0359 - accuracy: 0.9962\n",
            "Epoch 23/150\n",
            "77/77 [==============================] - 29s 380ms/step - loss: 0.0420 - accuracy: 0.9944\n",
            "Epoch 24/150\n",
            "77/77 [==============================] - 30s 383ms/step - loss: 0.0448 - accuracy: 0.9901\n",
            "Epoch 25/150\n",
            "77/77 [==============================] - 30s 396ms/step - loss: 0.0227 - accuracy: 0.9967\n",
            "Epoch 26/150\n",
            "77/77 [==============================] - 30s 387ms/step - loss: 0.0247 - accuracy: 0.9944\n",
            "Epoch 27/150\n",
            "77/77 [==============================] - 29s 378ms/step - loss: 0.0406 - accuracy: 0.9937\n",
            "Epoch 28/150\n",
            "77/77 [==============================] - 30s 389ms/step - loss: 0.0281 - accuracy: 0.9928\n",
            "Epoch 29/150\n",
            "77/77 [==============================] - 29s 377ms/step - loss: 0.0238 - accuracy: 0.9966\n",
            "Epoch 30/150\n",
            "77/77 [==============================] - 29s 377ms/step - loss: 0.0277 - accuracy: 0.9894\n",
            "Epoch 31/150\n",
            "77/77 [==============================] - 30s 385ms/step - loss: 0.0564 - accuracy: 0.9922\n",
            "Epoch 32/150\n",
            "77/77 [==============================] - 29s 381ms/step - loss: 0.0295 - accuracy: 0.9971\n",
            "Epoch 33/150\n",
            "77/77 [==============================] - 29s 380ms/step - loss: 0.0178 - accuracy: 0.9993\n",
            "Epoch 34/150\n",
            "77/77 [==============================] - 29s 375ms/step - loss: 0.0399 - accuracy: 0.9948\n",
            "Epoch 35/150\n",
            "77/77 [==============================] - 29s 377ms/step - loss: 0.0385 - accuracy: 0.9938\n",
            "Epoch 36/150\n",
            "77/77 [==============================] - 30s 395ms/step - loss: 0.0206 - accuracy: 0.9973\n",
            "Epoch 37/150\n",
            "77/77 [==============================] - 29s 383ms/step - loss: 0.0465 - accuracy: 0.9912\n",
            "Epoch 38/150\n",
            "77/77 [==============================] - 29s 380ms/step - loss: 0.0313 - accuracy: 0.9962\n",
            "Epoch 39/150\n",
            "77/77 [==============================] - 29s 381ms/step - loss: 0.0357 - accuracy: 0.9882\n",
            "Epoch 40/150\n",
            "77/77 [==============================] - 30s 384ms/step - loss: 0.0552 - accuracy: 0.9895\n",
            "Epoch 41/150\n",
            "77/77 [==============================] - 29s 376ms/step - loss: 0.0487 - accuracy: 0.9938\n",
            "Epoch 42/150\n",
            "77/77 [==============================] - 30s 383ms/step - loss: 0.0516 - accuracy: 0.9940\n",
            "Epoch 43/150\n",
            "77/77 [==============================] - 29s 382ms/step - loss: 0.0475 - accuracy: 0.9955\n",
            "Epoch 44/150\n",
            "77/77 [==============================] - 29s 381ms/step - loss: 0.0399 - accuracy: 0.9963\n",
            "Epoch 45/150\n",
            "77/77 [==============================] - 29s 376ms/step - loss: 0.0367 - accuracy: 0.9960\n",
            "Epoch 46/150\n",
            "77/77 [==============================] - 30s 389ms/step - loss: 0.0393 - accuracy: 0.9943\n",
            "Epoch 47/150\n",
            "77/77 [==============================] - 29s 378ms/step - loss: 0.0426 - accuracy: 0.9952\n",
            "Epoch 48/150\n",
            "77/77 [==============================] - 30s 387ms/step - loss: 0.0269 - accuracy: 0.9966\n",
            "Epoch 49/150\n",
            "77/77 [==============================] - 29s 379ms/step - loss: 0.0238 - accuracy: 0.9976\n",
            "Epoch 50/150\n",
            "77/77 [==============================] - 30s 386ms/step - loss: 0.0210 - accuracy: 0.9951\n",
            "Epoch 51/150\n",
            "77/77 [==============================] - 30s 390ms/step - loss: 0.0308 - accuracy: 0.9984\n",
            "Epoch 52/150\n",
            "77/77 [==============================] - 29s 379ms/step - loss: 0.0225 - accuracy: 0.9984\n",
            "Epoch 53/150\n",
            "77/77 [==============================] - 30s 391ms/step - loss: 0.0369 - accuracy: 0.9912\n",
            "Epoch 54/150\n",
            "77/77 [==============================] - 30s 384ms/step - loss: 0.0277 - accuracy: 0.9958\n",
            "Epoch 55/150\n",
            "77/77 [==============================] - 30s 385ms/step - loss: 0.0345 - accuracy: 0.9917\n",
            "Epoch 56/150\n",
            "77/77 [==============================] - 29s 382ms/step - loss: 0.0220 - accuracy: 0.9955\n",
            "Epoch 57/150\n",
            "77/77 [==============================] - 31s 399ms/step - loss: 0.0153 - accuracy: 0.9947\n",
            "Epoch 58/150\n",
            "77/77 [==============================] - 29s 380ms/step - loss: 0.0391 - accuracy: 0.9954\n",
            "Epoch 59/150\n",
            "77/77 [==============================] - 30s 390ms/step - loss: 0.0347 - accuracy: 0.9901\n",
            "Epoch 60/150\n",
            "77/77 [==============================] - 30s 386ms/step - loss: 0.0252 - accuracy: 0.9938\n",
            "Epoch 61/150\n",
            "77/77 [==============================] - 30s 387ms/step - loss: 0.0162 - accuracy: 0.9970\n",
            "Epoch 62/150\n",
            "77/77 [==============================] - 30s 387ms/step - loss: 0.0333 - accuracy: 0.9923\n",
            "Epoch 63/150\n",
            "77/77 [==============================] - 30s 387ms/step - loss: 0.0285 - accuracy: 0.9933\n",
            "Epoch 64/150\n",
            "77/77 [==============================] - 30s 384ms/step - loss: 0.0491 - accuracy: 0.9911\n",
            "Epoch 65/150\n",
            "77/77 [==============================] - 30s 387ms/step - loss: 0.0380 - accuracy: 0.9919\n",
            "Epoch 66/150\n",
            "77/77 [==============================] - 29s 383ms/step - loss: 0.0245 - accuracy: 0.9957\n",
            "Epoch 67/150\n",
            "77/77 [==============================] - 30s 389ms/step - loss: 0.0537 - accuracy: 0.9862\n",
            "Epoch 68/150\n",
            "77/77 [==============================] - 30s 386ms/step - loss: 0.0577 - accuracy: 0.9943\n",
            "Epoch 69/150\n",
            "77/77 [==============================] - 30s 383ms/step - loss: 0.0328 - accuracy: 0.9918\n",
            "Epoch 70/150\n",
            "77/77 [==============================] - 30s 386ms/step - loss: 0.0217 - accuracy: 0.9958\n",
            "Epoch 71/150\n",
            "77/77 [==============================] - 30s 384ms/step - loss: 0.0349 - accuracy: 0.9917\n",
            "Epoch 72/150\n",
            "77/77 [==============================] - 29s 377ms/step - loss: 0.0276 - accuracy: 0.9977\n",
            "Epoch 73/150\n",
            "77/77 [==============================] - 29s 377ms/step - loss: 0.0497 - accuracy: 0.9940\n",
            "Epoch 74/150\n",
            "77/77 [==============================] - 29s 379ms/step - loss: 0.0057 - accuracy: 0.9983\n",
            "Epoch 75/150\n",
            "77/77 [==============================] - 29s 380ms/step - loss: 0.0314 - accuracy: 0.9929\n",
            "Epoch 76/150\n",
            "77/77 [==============================] - 29s 378ms/step - loss: 0.0343 - accuracy: 0.9935\n",
            "Epoch 77/150\n",
            "77/77 [==============================] - 29s 381ms/step - loss: 0.0104 - accuracy: 0.9989\n",
            "Epoch 78/150\n",
            "77/77 [==============================] - 30s 383ms/step - loss: 0.0210 - accuracy: 0.9949\n",
            "Epoch 79/150\n",
            "77/77 [==============================] - 29s 381ms/step - loss: 0.0311 - accuracy: 0.9931\n",
            "Epoch 80/150\n",
            "77/77 [==============================] - 29s 380ms/step - loss: 0.0353 - accuracy: 0.9901\n",
            "Epoch 81/150\n",
            "77/77 [==============================] - 29s 381ms/step - loss: 0.0561 - accuracy: 0.9929\n",
            "Epoch 82/150\n",
            "77/77 [==============================] - 29s 380ms/step - loss: 0.0311 - accuracy: 0.9926\n",
            "Epoch 83/150\n",
            "77/77 [==============================] - 29s 380ms/step - loss: 0.0293 - accuracy: 0.9966\n",
            "Epoch 84/150\n",
            "77/77 [==============================] - 29s 379ms/step - loss: 0.0284 - accuracy: 0.9968\n",
            "Epoch 85/150\n",
            "77/77 [==============================] - 29s 381ms/step - loss: 0.0377 - accuracy: 0.9943\n",
            "Epoch 86/150\n",
            "77/77 [==============================] - 29s 378ms/step - loss: 0.0591 - accuracy: 0.9956\n",
            "Epoch 87/150\n",
            "77/77 [==============================] - 29s 378ms/step - loss: 0.0195 - accuracy: 0.9972\n",
            "Epoch 88/150\n",
            "77/77 [==============================] - 29s 377ms/step - loss: 0.0143 - accuracy: 0.9967\n",
            "Epoch 89/150\n",
            "77/77 [==============================] - 29s 379ms/step - loss: 0.0360 - accuracy: 0.9867\n",
            "Epoch 90/150\n",
            "77/77 [==============================] - 29s 382ms/step - loss: 0.0254 - accuracy: 0.9947\n",
            "Epoch 91/150\n",
            "77/77 [==============================] - 29s 377ms/step - loss: 0.0356 - accuracy: 0.9938\n",
            "Epoch 92/150\n",
            "77/77 [==============================] - 30s 387ms/step - loss: 0.0529 - accuracy: 0.9909\n",
            "Epoch 93/150\n",
            "77/77 [==============================] - 30s 384ms/step - loss: 0.0527 - accuracy: 0.9923\n",
            "Epoch 94/150\n",
            "77/77 [==============================] - 29s 380ms/step - loss: 0.0440 - accuracy: 0.9939\n",
            "Epoch 95/150\n",
            "77/77 [==============================] - 29s 382ms/step - loss: 0.0363 - accuracy: 0.9942\n",
            "Epoch 96/150\n",
            "77/77 [==============================] - 30s 383ms/step - loss: 0.0378 - accuracy: 0.9933\n",
            "Epoch 97/150\n",
            "77/77 [==============================] - 30s 386ms/step - loss: 0.0480 - accuracy: 0.9921\n",
            "Epoch 98/150\n",
            "77/77 [==============================] - 29s 382ms/step - loss: 0.0397 - accuracy: 0.9939\n",
            "Epoch 99/150\n",
            "77/77 [==============================] - 30s 385ms/step - loss: 0.0151 - accuracy: 0.9977\n",
            "Epoch 100/150\n",
            "77/77 [==============================] - 30s 387ms/step - loss: 0.0217 - accuracy: 0.9924\n",
            "Epoch 101/150\n",
            "77/77 [==============================] - 29s 382ms/step - loss: 0.0198 - accuracy: 0.9974\n",
            "Epoch 102/150\n",
            "77/77 [==============================] - 29s 382ms/step - loss: 0.0869 - accuracy: 0.9826\n",
            "Epoch 103/150\n",
            "77/77 [==============================] - 29s 379ms/step - loss: 0.0196 - accuracy: 0.9975\n",
            "Epoch 104/150\n",
            "77/77 [==============================] - 30s 388ms/step - loss: 0.0191 - accuracy: 0.9932\n",
            "Epoch 105/150\n",
            "77/77 [==============================] - 29s 378ms/step - loss: 0.0269 - accuracy: 0.9923\n",
            "Epoch 106/150\n",
            "77/77 [==============================] - 29s 382ms/step - loss: 0.0194 - accuracy: 0.9956\n",
            "Epoch 107/150\n",
            "77/77 [==============================] - 30s 384ms/step - loss: 0.0478 - accuracy: 0.9962\n",
            "Epoch 108/150\n",
            "77/77 [==============================] - 29s 382ms/step - loss: 0.0286 - accuracy: 0.9934\n",
            "Epoch 109/150\n",
            "77/77 [==============================] - 29s 381ms/step - loss: 0.0224 - accuracy: 0.9967\n",
            "Epoch 110/150\n",
            "77/77 [==============================] - 29s 382ms/step - loss: 0.0313 - accuracy: 0.9959\n",
            "Epoch 111/150\n",
            "77/77 [==============================] - 29s 383ms/step - loss: 0.0527 - accuracy: 0.9881\n",
            "Epoch 112/150\n",
            "77/77 [==============================] - 29s 383ms/step - loss: 0.0192 - accuracy: 0.9953\n",
            "Epoch 113/150\n",
            "77/77 [==============================] - 30s 385ms/step - loss: 0.0275 - accuracy: 0.9941\n",
            "Epoch 114/150\n",
            "77/77 [==============================] - 29s 378ms/step - loss: 0.0239 - accuracy: 0.9934\n",
            "Epoch 115/150\n",
            "77/77 [==============================] - 28s 369ms/step - loss: 0.0612 - accuracy: 0.9892\n",
            "Epoch 116/150\n",
            "77/77 [==============================] - 29s 382ms/step - loss: 0.0315 - accuracy: 0.9959\n",
            "Epoch 117/150\n",
            "77/77 [==============================] - 29s 374ms/step - loss: 0.0259 - accuracy: 0.9964\n",
            "Epoch 118/150\n",
            "77/77 [==============================] - 29s 376ms/step - loss: 0.0387 - accuracy: 0.9963\n",
            "Epoch 119/150\n",
            "77/77 [==============================] - 29s 379ms/step - loss: 0.0464 - accuracy: 0.9920\n",
            "Epoch 120/150\n",
            "77/77 [==============================] - 29s 373ms/step - loss: 0.0467 - accuracy: 0.9937\n",
            "Epoch 121/150\n",
            "77/77 [==============================] - 29s 382ms/step - loss: 0.0127 - accuracy: 0.9974\n",
            "Epoch 122/150\n",
            "77/77 [==============================] - 29s 372ms/step - loss: 0.0199 - accuracy: 0.9987\n",
            "Epoch 123/150\n",
            "77/77 [==============================] - 29s 379ms/step - loss: 0.0378 - accuracy: 0.9945\n",
            "Epoch 124/150\n",
            "77/77 [==============================] - 29s 371ms/step - loss: 0.0452 - accuracy: 0.9969\n",
            "Epoch 125/150\n",
            "77/77 [==============================] - 29s 379ms/step - loss: 0.0168 - accuracy: 0.9961\n",
            "Epoch 126/150\n",
            "77/77 [==============================] - 29s 375ms/step - loss: 0.0497 - accuracy: 0.9946\n",
            "Epoch 127/150\n",
            "77/77 [==============================] - 29s 380ms/step - loss: 0.0197 - accuracy: 0.9983\n",
            "Epoch 128/150\n",
            "77/77 [==============================] - 29s 373ms/step - loss: 0.0241 - accuracy: 0.9978\n",
            "Epoch 129/150\n",
            "77/77 [==============================] - 29s 378ms/step - loss: 0.0390 - accuracy: 0.9908\n",
            "Epoch 130/150\n",
            "77/77 [==============================] - 29s 376ms/step - loss: 0.0300 - accuracy: 0.9956\n",
            "Epoch 131/150\n",
            "77/77 [==============================] - 29s 381ms/step - loss: 0.0330 - accuracy: 0.9950\n",
            "Epoch 132/150\n",
            "77/77 [==============================] - 29s 376ms/step - loss: 0.0321 - accuracy: 0.9960\n",
            "Epoch 133/150\n",
            "77/77 [==============================] - 29s 381ms/step - loss: 0.0211 - accuracy: 0.9954\n",
            "Epoch 134/150\n",
            "77/77 [==============================] - 29s 375ms/step - loss: 0.0334 - accuracy: 0.9948\n",
            "Epoch 135/150\n",
            "77/77 [==============================] - 29s 381ms/step - loss: 0.0153 - accuracy: 0.9911\n",
            "Epoch 136/150\n",
            "77/77 [==============================] - 30s 388ms/step - loss: 0.0189 - accuracy: 0.9981\n",
            "Epoch 137/150\n",
            "77/77 [==============================] - 29s 376ms/step - loss: 0.0237 - accuracy: 0.9962\n",
            "Epoch 138/150\n",
            "77/77 [==============================] - 29s 381ms/step - loss: 0.0233 - accuracy: 0.9981\n",
            "Epoch 139/150\n",
            "77/77 [==============================] - 30s 384ms/step - loss: 0.0289 - accuracy: 0.9948\n",
            "Epoch 140/150\n",
            "77/77 [==============================] - 29s 374ms/step - loss: 0.0374 - accuracy: 0.9932\n",
            "Epoch 141/150\n",
            "77/77 [==============================] - 29s 383ms/step - loss: 0.0262 - accuracy: 0.9979\n",
            "Epoch 142/150\n",
            "77/77 [==============================] - 30s 384ms/step - loss: 0.0259 - accuracy: 0.9959\n",
            "Epoch 143/150\n",
            "77/77 [==============================] - 29s 381ms/step - loss: 0.0170 - accuracy: 0.9982\n",
            "Epoch 144/150\n",
            "77/77 [==============================] - 29s 383ms/step - loss: 0.0279 - accuracy: 0.9924\n",
            "Epoch 145/150\n",
            "77/77 [==============================] - 29s 380ms/step - loss: 0.0271 - accuracy: 0.9977\n",
            "Epoch 146/150\n",
            "77/77 [==============================] - 29s 380ms/step - loss: 0.0179 - accuracy: 0.9981\n",
            "Epoch 147/150\n",
            "77/77 [==============================] - 29s 380ms/step - loss: 0.0201 - accuracy: 0.9970\n",
            "Epoch 148/150\n",
            "77/77 [==============================] - 29s 381ms/step - loss: 0.0448 - accuracy: 0.9893\n",
            "Epoch 149/150\n",
            "77/77 [==============================] - 29s 383ms/step - loss: 0.0495 - accuracy: 0.9921\n",
            "Epoch 150/150\n",
            "77/77 [==============================] - 30s 387ms/step - loss: 0.0108 - accuracy: 0.9972\n",
            "eval_out [3.801963493973017, 0.5537459]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NotImplementedError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-77-e50899fb450b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;31m# /content/drive/My Drive/Colab Notebooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m \u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/My Drive/Colab Notebooks'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;31m# Check Performance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-64be0f5e221e>\u001b[0m in \u001b[0;36msave_model\u001b[0;34m(path, model, model_type)\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m     \u001b[0mmodel_filename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"model_\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mmodel_type\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"-\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrftime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%b%d_%H-%M-%S'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\".json\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m     \u001b[0mmodel_json\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m     \u001b[0mjson_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_filename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"a\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[0mjson_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_json\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.0.0/python3.6/tensorflow_core/python/keras/engine/network.py\u001b[0m in \u001b[0;36mto_json\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m   1207\u001b[0m         \u001b[0mA\u001b[0m \u001b[0mJSON\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1208\u001b[0m     \"\"\"\n\u001b[0;32m-> 1209\u001b[0;31m     \u001b[0mmodel_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_updated_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1210\u001b[0m     return json.dumps(\n\u001b[1;32m   1211\u001b[0m         model_config, default=serialization.get_json_type, **kwargs)\n",
            "\u001b[0;32m/tensorflow-2.0.0/python3.6/tensorflow_core/python/keras/engine/network.py\u001b[0m in \u001b[0;36m_updated_config\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1185\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m__version__\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mkeras_version\u001b[0m  \u001b[0;31m# pylint: disable=g-import-not-at-top\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1187\u001b[0;31m     \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1188\u001b[0m     model_config = {\n\u001b[1;32m   1189\u001b[0m         \u001b[0;34m'class_name'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.0.0/python3.6/tensorflow_core/python/keras/engine/sequential.py\u001b[0m in \u001b[0;36mget_config\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    336\u001b[0m       layer_configs.append({\n\u001b[1;32m    337\u001b[0m           \u001b[0;34m'class_name'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 338\u001b[0;31m           \u001b[0;34m'config'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    339\u001b[0m       })\n\u001b[1;32m    340\u001b[0m     \u001b[0;31m# When constructed using an `InputLayer` the first non-input layer may not\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.0.0/python3.6/tensorflow_core/python/keras/engine/network.py\u001b[0m in \u001b[0;36mget_config\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    884\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mget_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    885\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_graph_network\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 886\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    887\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_network_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNotImplementedError\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eIiBAgN992TQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "937dd85b-b3fa-41ec-ec1a-d87fc4435810"
      },
      "source": [
        "# Generate predictions\n",
        "# -------------------\n",
        "generate_predictions(model, model_name)\n"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "prediction for IMG_1589.jpg...\n",
            "prediction for IMG_299.jpg...\n",
            "prediction for IMG_1307.jpg...\n",
            "prediction for IMG_264.jpg...\n",
            "prediction for IMG_1501.jpg...\n",
            "prediction for IMG_2017.jpg...\n",
            "prediction for IMG_455.jpg...\n",
            "prediction for IMG_329.jpg...\n",
            "prediction for IMG_815.jpg...\n",
            "prediction for IMG_664.jpg...\n",
            "prediction for IMG_113.jpg...\n",
            "prediction for IMG_682.jpg...\n",
            "prediction for IMG_59.jpg...\n",
            "prediction for IMG_497.jpg...\n",
            "prediction for IMG_1382.jpg...\n",
            "prediction for IMG_1322.jpg...\n",
            "prediction for IMG_877.jpg...\n",
            "prediction for IMG_837.jpg...\n",
            "prediction for IMG_1771.jpg...\n",
            "prediction for IMG_117.jpg...\n",
            "prediction for IMG_1429.jpg...\n",
            "prediction for IMG_1620.jpg...\n",
            "prediction for IMG_1907.jpg...\n",
            "prediction for IMG_1289.jpg...\n",
            "prediction for IMG_420.jpg...\n",
            "prediction for IMG_1219.jpg...\n",
            "prediction for IMG_1197.jpg...\n",
            "prediction for IMG_234.jpg...\n",
            "prediction for IMG_1543.jpg...\n",
            "prediction for IMG_2023.jpg...\n",
            "prediction for IMG_2052.jpg...\n",
            "prediction for IMG_2041.jpg...\n",
            "prediction for IMG_106.jpg...\n",
            "prediction for IMG_635.jpg...\n",
            "prediction for IMG_1890.jpg...\n",
            "prediction for IMG_1808.jpg...\n",
            "prediction for IMG_249.jpg...\n",
            "prediction for IMG_1334.jpg...\n",
            "prediction for IMG_1820.jpg...\n",
            "prediction for IMG_1444.jpg...\n",
            "prediction for IMG_1728.jpg...\n",
            "prediction for IMG_296.jpg...\n",
            "prediction for IMG_1080.jpg...\n",
            "prediction for IMG_58.jpg...\n",
            "prediction for IMG_1084.jpg...\n",
            "prediction for IMG_1854.jpg...\n",
            "prediction for IMG_845.jpg...\n",
            "prediction for IMG_1459.jpg...\n",
            "prediction for IMG_1871.jpg...\n",
            "prediction for IMG_1280.jpg...\n",
            "prediction for IMG_695.jpg...\n",
            "prediction for IMG_397.jpg...\n",
            "prediction for IMG_1342.jpg...\n",
            "prediction for IMG_2047.jpg...\n",
            "prediction for IMG_1042.jpg...\n",
            "prediction for IMG_2010.jpg...\n",
            "prediction for IMG_1849.jpg...\n",
            "prediction for IMG_1819.jpg...\n",
            "prediction for IMG_2007.jpg...\n",
            "prediction for IMG_37.jpg...\n",
            "prediction for IMG_1657.jpg...\n",
            "prediction for IMG_1117.jpg...\n",
            "prediction for IMG_1538.jpg...\n",
            "prediction for IMG_19.jpg...\n",
            "prediction for IMG_1031.jpg...\n",
            "prediction for IMG_1466.jpg...\n",
            "prediction for IMG_712.jpg...\n",
            "prediction for IMG_932.jpg...\n",
            "prediction for IMG_1560.jpg...\n",
            "prediction for IMG_480.jpg...\n",
            "prediction for IMG_2042.jpg...\n",
            "prediction for IMG_1229.jpg...\n",
            "prediction for IMG_485.jpg...\n",
            "prediction for IMG_1546.jpg...\n",
            "prediction for IMG_1744.jpg...\n",
            "prediction for IMG_1741.jpg...\n",
            "prediction for IMG_1551.jpg...\n",
            "prediction for IMG_2005.jpg...\n",
            "prediction for IMG_513.jpg...\n",
            "prediction for IMG_1798.jpg...\n",
            "prediction for IMG_2018.jpg...\n",
            "prediction for IMG_1206.jpg...\n",
            "prediction for IMG_1276.jpg...\n",
            "prediction for IMG_1919.jpg...\n",
            "prediction for IMG_1509.jpg...\n",
            "prediction for IMG_66.jpg...\n",
            "prediction for IMG_1011.jpg...\n",
            "prediction for IMG_467.jpg...\n",
            "prediction for IMG_1264.jpg...\n",
            "prediction for IMG_2031.jpg...\n",
            "prediction for IMG_1194.jpg...\n",
            "prediction for IMG_1831.jpg...\n",
            "prediction for IMG_1646.jpg...\n",
            "prediction for IMG_1283.jpg...\n",
            "prediction for IMG_233.jpg...\n",
            "prediction for IMG_1500.jpg...\n",
            "prediction for IMG_1979.jpg...\n",
            "prediction for IMG_603.jpg...\n",
            "prediction for IMG_1991.jpg...\n",
            "prediction for IMG_717.jpg...\n",
            "prediction for IMG_1622.jpg...\n",
            "prediction for IMG_1359.jpg...\n",
            "prediction for IMG_1452.jpg...\n",
            "prediction for IMG_606.jpg...\n",
            "prediction for IMG_873.jpg...\n",
            "prediction for IMG_543.jpg...\n",
            "prediction for IMG_1183.jpg...\n",
            "prediction for IMG_572.jpg...\n",
            "prediction for IMG_1971.jpg...\n",
            "prediction for IMG_607.jpg...\n",
            "prediction for IMG_1187.jpg...\n",
            "prediction for IMG_938.jpg...\n",
            "prediction for IMG_1377.jpg...\n",
            "prediction for IMG_813.jpg...\n",
            "prediction for IMG_1155.jpg...\n",
            "prediction for IMG_616.jpg...\n",
            "prediction for IMG_551.jpg...\n",
            "prediction for IMG_89.jpg...\n",
            "prediction for IMG_1436.jpg...\n",
            "prediction for IMG_645.jpg...\n",
            "prediction for IMG_278.jpg...\n",
            "prediction for IMG_1370.jpg...\n",
            "prediction for IMG_1137.jpg...\n",
            "prediction for IMG_68.jpg...\n",
            "prediction for IMG_478.jpg...\n",
            "prediction for IMG_312.jpg...\n",
            "prediction for IMG_917.jpg...\n",
            "prediction for IMG_1101.jpg...\n",
            "prediction for IMG_826.jpg...\n",
            "prediction for IMG_473.jpg...\n",
            "prediction for IMG_404.jpg...\n",
            "prediction for IMG_1575.jpg...\n",
            "prediction for IMG_1023.jpg...\n",
            "prediction for IMG_744.jpg...\n",
            "prediction for IMG_308.jpg...\n",
            "prediction for IMG_1330.jpg...\n",
            "prediction for IMG_6.jpg...\n",
            "prediction for IMG_1664.jpg...\n",
            "prediction for IMG_1915.jpg...\n",
            "prediction for IMG_561.jpg...\n",
            "prediction for IMG_982.jpg...\n",
            "prediction for IMG_270.jpg...\n",
            "prediction for IMG_1684.jpg...\n",
            "prediction for IMG_1541.jpg...\n",
            "prediction for IMG_1929.jpg...\n",
            "prediction for IMG_844.jpg...\n",
            "prediction for IMG_805.jpg...\n",
            "prediction for IMG_1052.jpg...\n",
            "prediction for IMG_72.jpg...\n",
            "prediction for IMG_1238.jpg...\n",
            "prediction for IMG_775.jpg...\n",
            "prediction for IMG_1406.jpg...\n",
            "prediction for IMG_1209.jpg...\n",
            "prediction for IMG_322.jpg...\n",
            "prediction for IMG_1046.jpg...\n",
            "prediction for IMG_405.jpg...\n",
            "prediction for IMG_722.jpg...\n",
            "prediction for IMG_1235.jpg...\n",
            "prediction for IMG_1989.jpg...\n",
            "prediction for IMG_1419.jpg...\n",
            "prediction for IMG_1384.jpg...\n",
            "prediction for IMG_383.jpg...\n",
            "prediction for IMG_1494.jpg...\n",
            "prediction for IMG_1591.jpg...\n",
            "prediction for IMG_1645.jpg...\n",
            "prediction for IMG_1442.jpg...\n",
            "prediction for IMG_261.jpg...\n",
            "prediction for IMG_1354.jpg...\n",
            "prediction for IMG_1799.jpg...\n",
            "prediction for IMG_647.jpg...\n",
            "prediction for IMG_217.jpg...\n",
            "prediction for IMG_880.jpg...\n",
            "prediction for IMG_702.jpg...\n",
            "prediction for IMG_384.jpg...\n",
            "prediction for IMG_708.jpg...\n",
            "prediction for IMG_1768.jpg...\n",
            "prediction for IMG_621.jpg...\n",
            "prediction for IMG_1811.jpg...\n",
            "prediction for IMG_400.jpg...\n",
            "prediction for IMG_1882.jpg...\n",
            "prediction for IMG_1420.jpg...\n",
            "prediction for IMG_1474.jpg...\n",
            "prediction for IMG_755.jpg...\n",
            "prediction for IMG_105.jpg...\n",
            "prediction for IMG_706.jpg...\n",
            "prediction for IMG_1308.jpg...\n",
            "prediction for IMG_923.jpg...\n",
            "prediction for IMG_592.jpg...\n",
            "prediction for IMG_876.jpg...\n",
            "prediction for IMG_671.jpg...\n",
            "prediction for IMG_823.jpg...\n",
            "prediction for IMG_709.jpg...\n",
            "prediction for IMG_1468.jpg...\n",
            "prediction for IMG_451.jpg...\n",
            "prediction for IMG_1814.jpg...\n",
            "prediction for IMG_206.jpg...\n",
            "prediction for IMG_223.jpg...\n",
            "prediction for IMG_119.jpg...\n",
            "prediction for IMG_144.jpg...\n",
            "prediction for IMG_195.jpg...\n",
            "prediction for IMG_1495.jpg...\n",
            "prediction for IMG_986.jpg...\n",
            "prediction for IMG_1618.jpg...\n",
            "prediction for IMG_273.jpg...\n",
            "prediction for IMG_785.jpg...\n",
            "prediction for IMG_1090.jpg...\n",
            "prediction for IMG_914.jpg...\n",
            "prediction for IMG_379.jpg...\n",
            "prediction for IMG_802.jpg...\n",
            "prediction for IMG_1232.jpg...\n",
            "prediction for IMG_1158.jpg...\n",
            "prediction for IMG_1147.jpg...\n",
            "prediction for IMG_1349.jpg...\n",
            "prediction for IMG_739.jpg...\n",
            "prediction for IMG_542.jpg...\n",
            "prediction for IMG_679.jpg...\n",
            "prediction for IMG_1842.jpg...\n",
            "prediction for IMG_1703.jpg...\n",
            "prediction for IMG_1094.jpg...\n",
            "prediction for IMG_835.jpg...\n",
            "prediction for IMG_421.jpg...\n",
            "prediction for IMG_67.jpg...\n",
            "prediction for IMG_121.jpg...\n",
            "prediction for IMG_912.jpg...\n",
            "prediction for IMG_1723.jpg...\n",
            "prediction for IMG_1483.jpg...\n",
            "prediction for IMG_31.jpg...\n",
            "prediction for IMG_48.jpg...\n",
            "prediction for IMG_53.jpg...\n",
            "prediction for IMG_1978.jpg...\n",
            "prediction for IMG_183.jpg...\n",
            "prediction for IMG_293.jpg...\n",
            "prediction for IMG_220.jpg...\n",
            "prediction for IMG_1966.jpg...\n",
            "prediction for IMG_752.jpg...\n",
            "prediction for IMG_1217.jpg...\n",
            "prediction for IMG_967.jpg...\n",
            "prediction for IMG_245.jpg...\n",
            "prediction for IMG_546.jpg...\n",
            "prediction for IMG_1422.jpg...\n",
            "prediction for IMG_74.jpg...\n",
            "prediction for IMG_96.jpg...\n",
            "prediction for IMG_794.jpg...\n",
            "prediction for IMG_1127.jpg...\n",
            "prediction for IMG_1661.jpg...\n",
            "prediction for IMG_1883.jpg...\n",
            "prediction for IMG_691.jpg...\n",
            "prediction for IMG_338.jpg...\n",
            "prediction for IMG_1858.jpg...\n",
            "prediction for IMG_1344.jpg...\n",
            "prediction for IMG_69.jpg...\n",
            "prediction for IMG_1865.jpg...\n",
            "prediction for IMG_581.jpg...\n",
            "prediction for IMG_285.jpg...\n",
            "prediction for IMG_1475.jpg...\n",
            "prediction for IMG_272.jpg...\n",
            "prediction for IMG_1734.jpg...\n",
            "prediction for IMG_1918.jpg...\n",
            "prediction for IMG_1544.jpg...\n",
            "prediction for IMG_674.jpg...\n",
            "prediction for IMG_1650.jpg...\n",
            "prediction for IMG_32.jpg...\n",
            "prediction for IMG_1593.jpg...\n",
            "prediction for IMG_597.jpg...\n",
            "prediction for IMG_1059.jpg...\n",
            "prediction for IMG_601.jpg...\n",
            "prediction for IMG_1214.jpg...\n",
            "prediction for IMG_0.jpg...\n",
            "prediction for IMG_487.jpg...\n",
            "prediction for IMG_1071.jpg...\n",
            "prediction for IMG_263.jpg...\n",
            "prediction for IMG_1826.jpg...\n",
            "prediction for IMG_298.jpg...\n",
            "prediction for IMG_1339.jpg...\n",
            "prediction for IMG_803.jpg...\n",
            "prediction for IMG_1961.jpg...\n",
            "prediction for IMG_35.jpg...\n",
            "prediction for IMG_1001.jpg...\n",
            "prediction for IMG_123.jpg...\n",
            "prediction for IMG_1899.jpg...\n",
            "prediction for IMG_2020.jpg...\n",
            "prediction for IMG_608.jpg...\n",
            "prediction for IMG_1603.jpg...\n",
            "prediction for IMG_280.jpg...\n",
            "prediction for IMG_267.jpg...\n",
            "prediction for IMG_2053.jpg...\n",
            "prediction for IMG_1240.jpg...\n",
            "prediction for IMG_167.jpg...\n",
            "prediction for IMG_887.jpg...\n",
            "prediction for IMG_1058.jpg...\n",
            "prediction for IMG_1143.jpg...\n",
            "prediction for IMG_104.jpg...\n",
            "prediction for IMG_922.jpg...\n",
            "prediction for IMG_535.jpg...\n",
            "prediction for IMG_852.jpg...\n",
            "prediction for IMG_952.jpg...\n",
            "prediction for IMG_756.jpg...\n",
            "prediction for IMG_797.jpg...\n",
            "prediction for IMG_1706.jpg...\n",
            "prediction for IMG_134.jpg...\n",
            "prediction for IMG_897.jpg...\n",
            "prediction for IMG_1623.jpg...\n",
            "prediction for IMG_1941.jpg...\n",
            "prediction for IMG_517.jpg...\n",
            "prediction for IMG_1179.jpg...\n",
            "prediction for IMG_959.jpg...\n",
            "prediction for IMG_1892.jpg...\n",
            "prediction for IMG_1346.jpg...\n",
            "prediction for IMG_1506.jpg...\n",
            "prediction for IMG_1552.jpg...\n",
            "prediction for IMG_1511.jpg...\n",
            "prediction for IMG_598.jpg...\n",
            "prediction for IMG_558.jpg...\n",
            "prediction for IMG_1502.jpg...\n",
            "prediction for IMG_1199.jpg...\n",
            "prediction for IMG_1242.jpg...\n",
            "prediction for IMG_1936.jpg...\n",
            "prediction for IMG_710.jpg...\n",
            "prediction for IMG_884.jpg...\n",
            "prediction for IMG_355.jpg...\n",
            "prediction for IMG_1228.jpg...\n",
            "prediction for IMG_878.jpg...\n",
            "prediction for IMG_1074.jpg...\n",
            "prediction for IMG_214.jpg...\n",
            "prediction for IMG_1600.jpg...\n",
            "prediction for IMG_907.jpg...\n",
            "prediction for IMG_1908.jpg...\n",
            "prediction for IMG_893.jpg...\n",
            "prediction for IMG_563.jpg...\n",
            "prediction for IMG_956.jpg...\n",
            "prediction for IMG_703.jpg...\n",
            "prediction for IMG_1119.jpg...\n",
            "prediction for IMG_129.jpg...\n",
            "prediction for IMG_1803.jpg...\n",
            "prediction for IMG_864.jpg...\n",
            "prediction for IMG_867.jpg...\n",
            "prediction for IMG_1609.jpg...\n",
            "prediction for IMG_828.jpg...\n",
            "prediction for IMG_1949.jpg...\n",
            "prediction for IMG_1604.jpg...\n",
            "prediction for IMG_1674.jpg...\n",
            "prediction for IMG_51.jpg...\n",
            "prediction for IMG_34.jpg...\n",
            "prediction for IMG_1851.jpg...\n",
            "prediction for IMG_1512.jpg...\n",
            "prediction for IMG_705.jpg...\n",
            "prediction for IMG_174.jpg...\n",
            "prediction for IMG_1241.jpg...\n",
            "prediction for IMG_2000.jpg...\n",
            "prediction for IMG_1977.jpg...\n",
            "prediction for IMG_904.jpg...\n",
            "prediction for IMG_1050.jpg...\n",
            "prediction for IMG_1852.jpg...\n",
            "prediction for IMG_30.jpg...\n",
            "prediction for IMG_942.jpg...\n",
            "prediction for IMG_461.jpg...\n",
            "prediction for IMG_1536.jpg...\n",
            "prediction for IMG_1462.jpg...\n",
            "prediction for IMG_1912.jpg...\n",
            "prediction for IMG_1878.jpg...\n",
            "prediction for IMG_1172.jpg...\n",
            "prediction for IMG_159.jpg...\n",
            "prediction for IMG_582.jpg...\n",
            "prediction for IMG_1780.jpg...\n",
            "prediction for IMG_371.jpg...\n",
            "prediction for IMG_269.jpg...\n",
            "prediction for IMG_2021.jpg...\n",
            "prediction for IMG_1885.jpg...\n",
            "prediction for IMG_1901.jpg...\n",
            "prediction for IMG_1836.jpg...\n",
            "prediction for IMG_999.jpg...\n",
            "prediction for IMG_1437.jpg...\n",
            "prediction for IMG_1516.jpg...\n",
            "prediction for IMG_135.jpg...\n",
            "prediction for IMG_1962.jpg...\n",
            "prediction for IMG_227.jpg...\n",
            "prediction for IMG_1363.jpg...\n",
            "prediction for IMG_295.jpg...\n",
            "prediction for IMG_913.jpg...\n",
            "prediction for IMG_137.jpg...\n",
            "prediction for IMG_2025.jpg...\n",
            "prediction for IMG_136.jpg...\n",
            "prediction for IMG_98.jpg...\n",
            "prediction for IMG_1699.jpg...\n",
            "prediction for IMG_279.jpg...\n",
            "prediction for IMG_1306.jpg...\n",
            "prediction for IMG_602.jpg...\n",
            "prediction for IMG_550.jpg...\n",
            "prediction for IMG_367.jpg...\n",
            "prediction for IMG_583.jpg...\n",
            "prediction for IMG_1713.jpg...\n",
            "prediction for IMG_641.jpg...\n",
            "prediction for IMG_567.jpg...\n",
            "prediction for IMG_163.jpg...\n",
            "prediction for IMG_1213.jpg...\n",
            "prediction for IMG_92.jpg...\n",
            "prediction for IMG_943.jpg...\n",
            "prediction for IMG_1415.jpg...\n",
            "prediction for IMG_1872.jpg...\n",
            "prediction for IMG_262.jpg...\n",
            "prediction for IMG_1270.jpg...\n",
            "prediction for IMG_1550.jpg...\n",
            "prediction for IMG_1133.jpg...\n",
            "prediction for IMG_1211.jpg...\n",
            "prediction for IMG_1073.jpg...\n",
            "prediction for IMG_515.jpg...\n",
            "prediction for IMG_1163.jpg...\n",
            "prediction for IMG_1532.jpg...\n",
            "prediction for IMG_848.jpg...\n",
            "prediction for IMG_1268.jpg...\n",
            "prediction for IMG_240.jpg...\n",
            "prediction for IMG_539.jpg...\n",
            "prediction for IMG_660.jpg...\n",
            "prediction for IMG_252.jpg...\n",
            "prediction for IMG_1174.jpg...\n",
            "prediction for IMG_1435.jpg...\n",
            "prediction for IMG_862.jpg...\n",
            "prediction for IMG_1756.jpg...\n",
            "prediction for IMG_791.jpg...\n",
            "prediction for IMG_1481.jpg...\n",
            "prediction for IMG_410.jpg...\n",
            "prediction for IMG_1148.jpg...\n",
            "prediction for IMG_1251.jpg...\n",
            "prediction for IMG_1982.jpg...\n",
            "prediction for IMG_153.jpg...\n",
            "prediction for IMG_1659.jpg...\n",
            "prediction for IMG_1248.jpg...\n",
            "prediction for IMG_1902.jpg...\n",
            "prediction for IMG_764.jpg...\n",
            "prediction for IMG_1318.jpg...\n",
            "prediction for IMG_1557.jpg...\n",
            "prediction for IMG_1975.jpg...\n",
            "prediction for IMG_1529.jpg...\n",
            "prediction for IMG_866.jpg...\n",
            "prediction for IMG_169.jpg...\n",
            "prediction for IMG_1520.jpg...\n",
            "prediction for IMG_24.jpg...\n",
            "prediction for IMG_965.jpg...\n",
            "prediction for IMG_512.jpg...\n",
            "prediction for IMG_1480.jpg...\n",
            "prediction for IMG_505.jpg...\n",
            "prediction for IMG_1035.jpg...\n",
            "prediction for IMG_789.jpg...\n",
            "prediction for IMG_667.jpg...\n",
            "prediction for IMG_385.jpg...\n",
            "prediction for IMG_1212.jpg...\n",
            "prediction for IMG_1037.jpg...\n",
            "prediction for IMG_588.jpg...\n",
            "prediction for IMG_524.jpg...\n",
            "prediction for IMG_711.jpg...\n",
            "prediction for IMG_94.jpg...\n",
            "prediction for IMG_1397.jpg...\n",
            "prediction for IMG_151.jpg...\n",
            "prediction for IMG_1764.jpg...\n",
            "prediction for IMG_1202.jpg...\n",
            "prediction for IMG_1099.jpg...\n",
            "prediction for IMG_1285.jpg...\n",
            "prediction for IMG_1643.jpg...\n",
            "prediction for IMG_1072.jpg...\n",
            "prediction for IMG_1837.jpg...\n",
            "prediction for IMG_1298.jpg...\n",
            "prediction for IMG_1196.jpg...\n",
            "prediction for IMG_730.jpg...\n",
            "prediction for IMG_228.jpg...\n",
            "prediction for IMG_919.jpg...\n",
            "prediction for IMG_1007.jpg...\n",
            "prediction for IMG_1761.jpg...\n",
            "prediction for IMG_507.jpg...\n",
            "prediction for IMG_237.jpg...\n",
            "prediction for IMG_1628.jpg...\n",
            "prediction for IMG_681.jpg...\n",
            "prediction for IMG_61.jpg...\n",
            "prediction for IMG_817.jpg...\n",
            "prediction for IMG_175.jpg...\n",
            "prediction for IMG_1449.jpg...\n",
            "prediction for IMG_1633.jpg...\n",
            "prediction for IMG_1923.jpg...\n",
            "prediction for IMG_307.jpg...\n",
            "prediction for IMG_13.jpg...\n",
            "prediction for IMG_950.jpg...\n",
            "prediction for IMG_727.jpg...\n",
            "prediction for IMG_423.jpg...\n",
            "prediction for IMG_1097.jpg...\n",
            "prediction for IMG_501.jpg...\n",
            "prediction for IMG_1484.jpg...\n",
            "prediction for IMG_414.jpg...\n",
            "prediction for IMG_251.jpg...\n",
            "prediction for IMG_377.jpg...\n",
            "prediction for IMG_1909.jpg...\n",
            "prediction for IMG_508.jpg...\n",
            "prediction for IMG_57.jpg...\n",
            "prediction for IMG_944.jpg...\n",
            "prediction for IMG_1747.jpg...\n",
            "prediction for IMG_321.jpg...\n",
            "prediction for IMG_638.jpg...\n",
            "prediction for IMG_1813.jpg...\n",
            "prediction for IMG_499.jpg...\n",
            "prediction for IMG_1935.jpg...\n",
            "prediction for IMG_1709.jpg...\n",
            "prediction for IMG_1802.jpg...\n",
            "\n",
            "Generating submission csv ... \n",
            "{'IMG_0.jpg': 'waterfall',\n",
            " 'IMG_1001.jpg': 'bear',\n",
            " 'IMG_1007.jpg': 'fireworks',\n",
            " 'IMG_1011.jpg': 'computer-monitor',\n",
            " 'IMG_1023.jpg': 'wine-bottle',\n",
            " 'IMG_1031.jpg': 'fireworks',\n",
            " 'IMG_1035.jpg': 'sheet-music',\n",
            " 'IMG_1037.jpg': 'school-bus',\n",
            " 'IMG_104.jpg': 'skyscraper',\n",
            " 'IMG_1042.jpg': 'owl',\n",
            " 'IMG_1046.jpg': 'owl',\n",
            " 'IMG_105.jpg': 'school-bus',\n",
            " 'IMG_1050.jpg': 'owl',\n",
            " 'IMG_1052.jpg': 'skyscraper',\n",
            " 'IMG_1058.jpg': 'wine-bottle',\n",
            " 'IMG_1059.jpg': 'bear',\n",
            " 'IMG_106.jpg': 'sheet-music',\n",
            " 'IMG_1071.jpg': 'waterfall',\n",
            " 'IMG_1072.jpg': 'fireworks',\n",
            " 'IMG_1073.jpg': 'school-bus',\n",
            " 'IMG_1074.jpg': 'school-bus',\n",
            " 'IMG_1080.jpg': 'wine-bottle',\n",
            " 'IMG_1084.jpg': 'waterfall',\n",
            " 'IMG_1090.jpg': 'skyscraper',\n",
            " 'IMG_1094.jpg': 'school-bus',\n",
            " 'IMG_1097.jpg': 'owl',\n",
            " 'IMG_1099.jpg': 'lightbulb',\n",
            " 'IMG_1101.jpg': 'kangaroo',\n",
            " 'IMG_1117.jpg': 'airplanes',\n",
            " 'IMG_1119.jpg': 'lightbulb',\n",
            " 'IMG_1127.jpg': 'school-bus',\n",
            " 'IMG_113.jpg': 'laptop',\n",
            " 'IMG_1133.jpg': 'mountain-bike',\n",
            " 'IMG_1137.jpg': 'fireworks',\n",
            " 'IMG_1143.jpg': 't-shirt',\n",
            " 'IMG_1147.jpg': 'mountain-bike',\n",
            " 'IMG_1148.jpg': 'bear',\n",
            " 'IMG_1155.jpg': 'calculator',\n",
            " 'IMG_1158.jpg': 'waterfall',\n",
            " 'IMG_1163.jpg': 'fireworks',\n",
            " 'IMG_117.jpg': 'galaxy',\n",
            " 'IMG_1172.jpg': 'computer-monitor',\n",
            " 'IMG_1174.jpg': 'calculator',\n",
            " 'IMG_1179.jpg': 't-shirt',\n",
            " 'IMG_1183.jpg': 'lightning',\n",
            " 'IMG_1187.jpg': 'fireworks',\n",
            " 'IMG_119.jpg': 'sheet-music',\n",
            " 'IMG_1194.jpg': 'calculator',\n",
            " 'IMG_1196.jpg': 'galaxy',\n",
            " 'IMG_1197.jpg': 'lightning',\n",
            " 'IMG_1199.jpg': 't-shirt',\n",
            " 'IMG_1202.jpg': 'skyscraper',\n",
            " 'IMG_1206.jpg': 'wine-bottle',\n",
            " 'IMG_1209.jpg': 'calculator',\n",
            " 'IMG_121.jpg': 't-shirt',\n",
            " 'IMG_1211.jpg': 'wine-bottle',\n",
            " 'IMG_1212.jpg': 't-shirt',\n",
            " 'IMG_1213.jpg': 'airplanes',\n",
            " 'IMG_1214.jpg': 'laptop',\n",
            " 'IMG_1217.jpg': 'laptop',\n",
            " 'IMG_1219.jpg': 'lightning',\n",
            " 'IMG_1228.jpg': 'laptop',\n",
            " 'IMG_1229.jpg': 'lightning',\n",
            " 'IMG_123.jpg': 'bear',\n",
            " 'IMG_1232.jpg': 'skyscraper',\n",
            " 'IMG_1235.jpg': 'fireworks',\n",
            " 'IMG_1238.jpg': 'sheet-music',\n",
            " 'IMG_1240.jpg': 'sheet-music',\n",
            " 'IMG_1241.jpg': 'waterfall',\n",
            " 'IMG_1242.jpg': 'owl',\n",
            " 'IMG_1248.jpg': 'owl',\n",
            " 'IMG_1251.jpg': 'computer-monitor',\n",
            " 'IMG_1264.jpg': 'grand-piano',\n",
            " 'IMG_1268.jpg': 'fireworks',\n",
            " 'IMG_1270.jpg': 'sheet-music',\n",
            " 'IMG_1276.jpg': 'computer-monitor',\n",
            " 'IMG_1280.jpg': 'owl',\n",
            " 'IMG_1283.jpg': 'lightning',\n",
            " 'IMG_1285.jpg': 'owl',\n",
            " 'IMG_1289.jpg': 'wine-bottle',\n",
            " 'IMG_129.jpg': 'kangaroo',\n",
            " 'IMG_1298.jpg': 'bear',\n",
            " 'IMG_13.jpg': 'waterfall',\n",
            " 'IMG_1306.jpg': 'grand-piano',\n",
            " 'IMG_1307.jpg': 'calculator',\n",
            " 'IMG_1308.jpg': 'computer-monitor',\n",
            " 'IMG_1318.jpg': 'bear',\n",
            " 'IMG_1322.jpg': 'calculator',\n",
            " 'IMG_1330.jpg': 'laptop',\n",
            " 'IMG_1334.jpg': 'laptop',\n",
            " 'IMG_1339.jpg': 'lightning',\n",
            " 'IMG_134.jpg': 'laptop',\n",
            " 'IMG_1342.jpg': 'computer-monitor',\n",
            " 'IMG_1344.jpg': 'waterfall',\n",
            " 'IMG_1346.jpg': 'fireworks',\n",
            " 'IMG_1349.jpg': 'fireworks',\n",
            " 'IMG_135.jpg': 'airplanes',\n",
            " 'IMG_1354.jpg': 'laptop',\n",
            " 'IMG_1359.jpg': 'wine-bottle',\n",
            " 'IMG_136.jpg': 't-shirt',\n",
            " 'IMG_1363.jpg': 'sheet-music',\n",
            " 'IMG_137.jpg': 't-shirt',\n",
            " 'IMG_1370.jpg': 'kangaroo',\n",
            " 'IMG_1377.jpg': 'calculator',\n",
            " 'IMG_1382.jpg': 't-shirt',\n",
            " 'IMG_1384.jpg': 'airplanes',\n",
            " 'IMG_1397.jpg': 'grand-piano',\n",
            " 'IMG_1406.jpg': 'lightbulb',\n",
            " 'IMG_1415.jpg': 'laptop',\n",
            " 'IMG_1419.jpg': 'waterfall',\n",
            " 'IMG_1420.jpg': 'fireworks',\n",
            " 'IMG_1422.jpg': 'grand-piano',\n",
            " 'IMG_1429.jpg': 'fireworks',\n",
            " 'IMG_1435.jpg': 'kangaroo',\n",
            " 'IMG_1436.jpg': 'laptop',\n",
            " 'IMG_1437.jpg': 'wine-bottle',\n",
            " 'IMG_144.jpg': 'lightbulb',\n",
            " 'IMG_1442.jpg': 'bear',\n",
            " 'IMG_1444.jpg': 'lightning',\n",
            " 'IMG_1449.jpg': 'laptop',\n",
            " 'IMG_1452.jpg': 'skyscraper',\n",
            " 'IMG_1459.jpg': 'computer-monitor',\n",
            " 'IMG_1462.jpg': 't-shirt',\n",
            " 'IMG_1466.jpg': 'airplanes',\n",
            " 'IMG_1468.jpg': 'school-bus',\n",
            " 'IMG_1474.jpg': 'computer-monitor',\n",
            " 'IMG_1475.jpg': 'galaxy',\n",
            " 'IMG_1480.jpg': 'kangaroo',\n",
            " 'IMG_1481.jpg': 'laptop',\n",
            " 'IMG_1483.jpg': 'waterfall',\n",
            " 'IMG_1484.jpg': 'owl',\n",
            " 'IMG_1494.jpg': 'lightning',\n",
            " 'IMG_1495.jpg': 'school-bus',\n",
            " 'IMG_1500.jpg': 'computer-monitor',\n",
            " 'IMG_1501.jpg': 'fireworks',\n",
            " 'IMG_1502.jpg': 'fireworks',\n",
            " 'IMG_1506.jpg': 'laptop',\n",
            " 'IMG_1509.jpg': 't-shirt',\n",
            " 'IMG_151.jpg': 'mountain-bike',\n",
            " 'IMG_1511.jpg': 'lightbulb',\n",
            " 'IMG_1512.jpg': 'laptop',\n",
            " 'IMG_1516.jpg': 'airplanes',\n",
            " 'IMG_1520.jpg': 'computer-monitor',\n",
            " 'IMG_1529.jpg': 'lightbulb',\n",
            " 'IMG_153.jpg': 'sword',\n",
            " 'IMG_1532.jpg': 'grand-piano',\n",
            " 'IMG_1536.jpg': 'lightning',\n",
            " 'IMG_1538.jpg': 'laptop',\n",
            " 'IMG_1541.jpg': 'lightbulb',\n",
            " 'IMG_1543.jpg': 'calculator',\n",
            " 'IMG_1544.jpg': 'grand-piano',\n",
            " 'IMG_1546.jpg': 'owl',\n",
            " 'IMG_1550.jpg': 't-shirt',\n",
            " 'IMG_1551.jpg': 'lightning',\n",
            " 'IMG_1552.jpg': 'grand-piano',\n",
            " 'IMG_1557.jpg': 'kangaroo',\n",
            " 'IMG_1560.jpg': 'mountain-bike',\n",
            " 'IMG_1575.jpg': 'mountain-bike',\n",
            " 'IMG_1589.jpg': 'galaxy',\n",
            " 'IMG_159.jpg': 'bear',\n",
            " 'IMG_1591.jpg': 'skyscraper',\n",
            " 'IMG_1593.jpg': 'skyscraper',\n",
            " 'IMG_1600.jpg': 't-shirt',\n",
            " 'IMG_1603.jpg': 'galaxy',\n",
            " 'IMG_1604.jpg': 'kangaroo',\n",
            " 'IMG_1609.jpg': 't-shirt',\n",
            " 'IMG_1618.jpg': 'owl',\n",
            " 'IMG_1620.jpg': 'mountain-bike',\n",
            " 'IMG_1622.jpg': 'owl',\n",
            " 'IMG_1623.jpg': 'galaxy',\n",
            " 'IMG_1628.jpg': 'airplanes',\n",
            " 'IMG_163.jpg': 'lightbulb',\n",
            " 'IMG_1633.jpg': 'galaxy',\n",
            " 'IMG_1643.jpg': 'grand-piano',\n",
            " 'IMG_1645.jpg': 'computer-monitor',\n",
            " 'IMG_1646.jpg': 'lightning',\n",
            " 'IMG_1650.jpg': 'waterfall',\n",
            " 'IMG_1657.jpg': 'sword',\n",
            " 'IMG_1659.jpg': 'fireworks',\n",
            " 'IMG_1661.jpg': 'lightning',\n",
            " 'IMG_1664.jpg': 't-shirt',\n",
            " 'IMG_167.jpg': 'sword',\n",
            " 'IMG_1674.jpg': 'fireworks',\n",
            " 'IMG_1684.jpg': 'mountain-bike',\n",
            " 'IMG_169.jpg': 'grand-piano',\n",
            " 'IMG_1699.jpg': 'mountain-bike',\n",
            " 'IMG_1703.jpg': 'computer-monitor',\n",
            " 'IMG_1706.jpg': 'computer-monitor',\n",
            " 'IMG_1709.jpg': 't-shirt',\n",
            " 'IMG_1713.jpg': 'mountain-bike',\n",
            " 'IMG_1723.jpg': 'airplanes',\n",
            " 'IMG_1728.jpg': 'sword',\n",
            " 'IMG_1734.jpg': 'wine-bottle',\n",
            " 'IMG_174.jpg': 'galaxy',\n",
            " 'IMG_1741.jpg': 'lightbulb',\n",
            " 'IMG_1744.jpg': 't-shirt',\n",
            " 'IMG_1747.jpg': 'lightning',\n",
            " 'IMG_175.jpg': 'lightbulb',\n",
            " 'IMG_1756.jpg': 'bear',\n",
            " 'IMG_1761.jpg': 'bear',\n",
            " 'IMG_1764.jpg': 'fireworks',\n",
            " 'IMG_1768.jpg': 'mountain-bike',\n",
            " 'IMG_1771.jpg': 'airplanes',\n",
            " 'IMG_1780.jpg': 'fireworks',\n",
            " 'IMG_1798.jpg': 'mountain-bike',\n",
            " 'IMG_1799.jpg': 'kangaroo',\n",
            " 'IMG_1802.jpg': 'waterfall',\n",
            " 'IMG_1803.jpg': 'bear',\n",
            " 'IMG_1808.jpg': 'bear',\n",
            " 'IMG_1811.jpg': 'lightning',\n",
            " 'IMG_1813.jpg': 'school-bus',\n",
            " 'IMG_1814.jpg': 'sword',\n",
            " 'IMG_1819.jpg': 'calculator',\n",
            " 'IMG_1820.jpg': 'sheet-music',\n",
            " 'IMG_1826.jpg': 'airplanes',\n",
            " 'IMG_183.jpg': 'calculator',\n",
            " 'IMG_1831.jpg': 'laptop',\n",
            " 'IMG_1836.jpg': 'laptop',\n",
            " 'IMG_1837.jpg': 'airplanes',\n",
            " 'IMG_1842.jpg': 'galaxy',\n",
            " 'IMG_1849.jpg': 't-shirt',\n",
            " 'IMG_1851.jpg': 'kangaroo',\n",
            " 'IMG_1852.jpg': 'wine-bottle',\n",
            " 'IMG_1854.jpg': 'owl',\n",
            " 'IMG_1858.jpg': 'mountain-bike',\n",
            " 'IMG_1865.jpg': 'wine-bottle',\n",
            " 'IMG_1871.jpg': 'sheet-music',\n",
            " 'IMG_1872.jpg': 'laptop',\n",
            " 'IMG_1878.jpg': 'kangaroo',\n",
            " 'IMG_1882.jpg': 'computer-monitor',\n",
            " 'IMG_1883.jpg': 'lightning',\n",
            " 'IMG_1885.jpg': 'school-bus',\n",
            " 'IMG_1890.jpg': 'calculator',\n",
            " 'IMG_1892.jpg': 'sword',\n",
            " 'IMG_1899.jpg': 'mountain-bike',\n",
            " 'IMG_19.jpg': 'grand-piano',\n",
            " 'IMG_1901.jpg': 'laptop',\n",
            " 'IMG_1902.jpg': 'sword',\n",
            " 'IMG_1907.jpg': 'galaxy',\n",
            " 'IMG_1908.jpg': 'grand-piano',\n",
            " 'IMG_1909.jpg': 'kangaroo',\n",
            " 'IMG_1912.jpg': 'lightning',\n",
            " 'IMG_1915.jpg': 'calculator',\n",
            " 'IMG_1918.jpg': 'mountain-bike',\n",
            " 'IMG_1919.jpg': 'school-bus',\n",
            " 'IMG_1923.jpg': 'school-bus',\n",
            " 'IMG_1929.jpg': 'lightning',\n",
            " 'IMG_1935.jpg': 'sword',\n",
            " 'IMG_1936.jpg': 'calculator',\n",
            " 'IMG_1941.jpg': 'wine-bottle',\n",
            " 'IMG_1949.jpg': 'lightning',\n",
            " 'IMG_195.jpg': 'school-bus',\n",
            " 'IMG_1961.jpg': 'mountain-bike',\n",
            " 'IMG_1962.jpg': 'lightbulb',\n",
            " 'IMG_1966.jpg': 'lightning',\n",
            " 'IMG_1971.jpg': 'laptop',\n",
            " 'IMG_1975.jpg': 'school-bus',\n",
            " 'IMG_1977.jpg': 'owl',\n",
            " 'IMG_1978.jpg': 'laptop',\n",
            " 'IMG_1979.jpg': 'bear',\n",
            " 'IMG_1982.jpg': 'laptop',\n",
            " 'IMG_1989.jpg': 'galaxy',\n",
            " 'IMG_1991.jpg': 'kangaroo',\n",
            " 'IMG_2000.jpg': 'sword',\n",
            " 'IMG_2005.jpg': 't-shirt',\n",
            " 'IMG_2007.jpg': 't-shirt',\n",
            " 'IMG_2010.jpg': 'skyscraper',\n",
            " 'IMG_2017.jpg': 'sword',\n",
            " 'IMG_2018.jpg': 'skyscraper',\n",
            " 'IMG_2020.jpg': 'kangaroo',\n",
            " 'IMG_2021.jpg': 'fireworks',\n",
            " 'IMG_2023.jpg': 'grand-piano',\n",
            " 'IMG_2025.jpg': 'galaxy',\n",
            " 'IMG_2031.jpg': 'sword',\n",
            " 'IMG_2041.jpg': 'sword',\n",
            " 'IMG_2042.jpg': 'school-bus',\n",
            " 'IMG_2047.jpg': 'lightning',\n",
            " 'IMG_2052.jpg': 'fireworks',\n",
            " 'IMG_2053.jpg': 'wine-bottle',\n",
            " 'IMG_206.jpg': 'waterfall',\n",
            " 'IMG_214.jpg': 'grand-piano',\n",
            " 'IMG_217.jpg': 'calculator',\n",
            " 'IMG_220.jpg': 'airplanes',\n",
            " 'IMG_223.jpg': 'kangaroo',\n",
            " 'IMG_227.jpg': 'mountain-bike',\n",
            " 'IMG_228.jpg': 'bear',\n",
            " 'IMG_233.jpg': 'skyscraper',\n",
            " 'IMG_234.jpg': 'waterfall',\n",
            " 'IMG_237.jpg': 'grand-piano',\n",
            " 'IMG_24.jpg': 'wine-bottle',\n",
            " 'IMG_240.jpg': 't-shirt',\n",
            " 'IMG_245.jpg': 'kangaroo',\n",
            " 'IMG_249.jpg': 'fireworks',\n",
            " 'IMG_251.jpg': 'bear',\n",
            " 'IMG_252.jpg': 'sword',\n",
            " 'IMG_261.jpg': 'laptop',\n",
            " 'IMG_262.jpg': 'wine-bottle',\n",
            " 'IMG_263.jpg': 'school-bus',\n",
            " 'IMG_264.jpg': 'school-bus',\n",
            " 'IMG_267.jpg': 'bear',\n",
            " 'IMG_269.jpg': 'airplanes',\n",
            " 'IMG_270.jpg': 't-shirt',\n",
            " 'IMG_272.jpg': 'sheet-music',\n",
            " 'IMG_273.jpg': 'owl',\n",
            " 'IMG_278.jpg': 'sheet-music',\n",
            " 'IMG_279.jpg': 'galaxy',\n",
            " 'IMG_280.jpg': 't-shirt',\n",
            " 'IMG_285.jpg': 'owl',\n",
            " 'IMG_293.jpg': 'lightbulb',\n",
            " 'IMG_295.jpg': 'grand-piano',\n",
            " 'IMG_296.jpg': 'computer-monitor',\n",
            " 'IMG_298.jpg': 'owl',\n",
            " 'IMG_299.jpg': 'fireworks',\n",
            " 'IMG_30.jpg': 'computer-monitor',\n",
            " 'IMG_307.jpg': 'school-bus',\n",
            " 'IMG_308.jpg': 'bear',\n",
            " 'IMG_31.jpg': 'computer-monitor',\n",
            " 'IMG_312.jpg': 'sheet-music',\n",
            " 'IMG_32.jpg': 'laptop',\n",
            " 'IMG_321.jpg': 'owl',\n",
            " 'IMG_322.jpg': 'calculator',\n",
            " 'IMG_329.jpg': 'fireworks',\n",
            " 'IMG_338.jpg': 'grand-piano',\n",
            " 'IMG_34.jpg': 'calculator',\n",
            " 'IMG_35.jpg': 'airplanes',\n",
            " 'IMG_355.jpg': 'owl',\n",
            " 'IMG_367.jpg': 'bear',\n",
            " 'IMG_37.jpg': 'grand-piano',\n",
            " 'IMG_371.jpg': 'skyscraper',\n",
            " 'IMG_377.jpg': 'waterfall',\n",
            " 'IMG_379.jpg': 'school-bus',\n",
            " 'IMG_383.jpg': 'galaxy',\n",
            " 'IMG_384.jpg': 'fireworks',\n",
            " 'IMG_385.jpg': 'laptop',\n",
            " 'IMG_397.jpg': 'school-bus',\n",
            " 'IMG_400.jpg': 'sheet-music',\n",
            " 'IMG_404.jpg': 'fireworks',\n",
            " 'IMG_405.jpg': 'calculator',\n",
            " 'IMG_410.jpg': 'airplanes',\n",
            " 'IMG_414.jpg': 'grand-piano',\n",
            " 'IMG_420.jpg': 'bear',\n",
            " 'IMG_421.jpg': 'galaxy',\n",
            " 'IMG_423.jpg': 'grand-piano',\n",
            " 'IMG_451.jpg': 'waterfall',\n",
            " 'IMG_455.jpg': 'bear',\n",
            " 'IMG_461.jpg': 'laptop',\n",
            " 'IMG_467.jpg': 'grand-piano',\n",
            " 'IMG_473.jpg': 'laptop',\n",
            " 'IMG_478.jpg': 'wine-bottle',\n",
            " 'IMG_48.jpg': 'laptop',\n",
            " 'IMG_480.jpg': 'school-bus',\n",
            " 'IMG_485.jpg': 'calculator',\n",
            " 'IMG_487.jpg': 'calculator',\n",
            " 'IMG_497.jpg': 'laptop',\n",
            " 'IMG_499.jpg': 'calculator',\n",
            " 'IMG_501.jpg': 'owl',\n",
            " 'IMG_505.jpg': 'school-bus',\n",
            " 'IMG_507.jpg': 'fireworks',\n",
            " 'IMG_508.jpg': 'galaxy',\n",
            " 'IMG_51.jpg': 'laptop',\n",
            " 'IMG_512.jpg': 'airplanes',\n",
            " 'IMG_513.jpg': 'grand-piano',\n",
            " 'IMG_515.jpg': 'galaxy',\n",
            " 'IMG_517.jpg': 'computer-monitor',\n",
            " 'IMG_524.jpg': 'lightbulb',\n",
            " 'IMG_53.jpg': 'fireworks',\n",
            " 'IMG_535.jpg': 'calculator',\n",
            " 'IMG_539.jpg': 't-shirt',\n",
            " 'IMG_542.jpg': 'computer-monitor',\n",
            " 'IMG_543.jpg': 'skyscraper',\n",
            " 'IMG_546.jpg': 'sword',\n",
            " 'IMG_550.jpg': 'lightning',\n",
            " 'IMG_551.jpg': 'laptop',\n",
            " 'IMG_558.jpg': 'computer-monitor',\n",
            " 'IMG_561.jpg': 'airplanes',\n",
            " 'IMG_563.jpg': 'laptop',\n",
            " 'IMG_567.jpg': 'school-bus',\n",
            " 'IMG_57.jpg': 'waterfall',\n",
            " 'IMG_572.jpg': 'skyscraper',\n",
            " 'IMG_58.jpg': 'lightning',\n",
            " 'IMG_581.jpg': 'owl',\n",
            " 'IMG_582.jpg': 'fireworks',\n",
            " 'IMG_583.jpg': 't-shirt',\n",
            " 'IMG_588.jpg': 't-shirt',\n",
            " 'IMG_59.jpg': 'computer-monitor',\n",
            " 'IMG_592.jpg': 'sheet-music',\n",
            " 'IMG_597.jpg': 'sheet-music',\n",
            " 'IMG_598.jpg': 'wine-bottle',\n",
            " 'IMG_6.jpg': 'laptop',\n",
            " 'IMG_601.jpg': 'owl',\n",
            " 'IMG_602.jpg': 'skyscraper',\n",
            " 'IMG_603.jpg': 'lightning',\n",
            " 'IMG_606.jpg': 'school-bus',\n",
            " 'IMG_607.jpg': 'calculator',\n",
            " 'IMG_608.jpg': 'laptop',\n",
            " 'IMG_61.jpg': 'computer-monitor',\n",
            " 'IMG_616.jpg': 'lightbulb',\n",
            " 'IMG_621.jpg': 'skyscraper',\n",
            " 'IMG_635.jpg': 'skyscraper',\n",
            " 'IMG_638.jpg': 'wine-bottle',\n",
            " 'IMG_641.jpg': 'school-bus',\n",
            " 'IMG_645.jpg': 'skyscraper',\n",
            " 'IMG_647.jpg': 'fireworks',\n",
            " 'IMG_66.jpg': 'calculator',\n",
            " 'IMG_660.jpg': 'calculator',\n",
            " 'IMG_664.jpg': 'owl',\n",
            " 'IMG_667.jpg': 'laptop',\n",
            " 'IMG_67.jpg': 'lightbulb',\n",
            " 'IMG_671.jpg': 'mountain-bike',\n",
            " 'IMG_674.jpg': 'sheet-music',\n",
            " 'IMG_679.jpg': 'owl',\n",
            " 'IMG_68.jpg': 'galaxy',\n",
            " 'IMG_681.jpg': 'fireworks',\n",
            " 'IMG_682.jpg': 'computer-monitor',\n",
            " 'IMG_69.jpg': 'bear',\n",
            " 'IMG_691.jpg': 'sheet-music',\n",
            " 'IMG_695.jpg': 'computer-monitor',\n",
            " 'IMG_702.jpg': 'galaxy',\n",
            " 'IMG_703.jpg': 'airplanes',\n",
            " 'IMG_705.jpg': 'wine-bottle',\n",
            " 'IMG_706.jpg': 'sheet-music',\n",
            " 'IMG_708.jpg': 'computer-monitor',\n",
            " 'IMG_709.jpg': 'grand-piano',\n",
            " 'IMG_710.jpg': 't-shirt',\n",
            " 'IMG_711.jpg': 'fireworks',\n",
            " 'IMG_712.jpg': 'bear',\n",
            " 'IMG_717.jpg': 'owl',\n",
            " 'IMG_72.jpg': 'owl',\n",
            " 'IMG_722.jpg': 'laptop',\n",
            " 'IMG_727.jpg': 'mountain-bike',\n",
            " 'IMG_730.jpg': 'airplanes',\n",
            " 'IMG_739.jpg': 'waterfall',\n",
            " 'IMG_74.jpg': 'skyscraper',\n",
            " 'IMG_744.jpg': 'sheet-music',\n",
            " 'IMG_752.jpg': 't-shirt',\n",
            " 'IMG_755.jpg': 'mountain-bike',\n",
            " 'IMG_756.jpg': 'sheet-music',\n",
            " 'IMG_764.jpg': 'owl',\n",
            " 'IMG_775.jpg': 'sheet-music',\n",
            " 'IMG_785.jpg': 'galaxy',\n",
            " 'IMG_789.jpg': 'waterfall',\n",
            " 'IMG_791.jpg': 'lightning',\n",
            " 'IMG_794.jpg': 'airplanes',\n",
            " 'IMG_797.jpg': 't-shirt',\n",
            " 'IMG_802.jpg': 't-shirt',\n",
            " 'IMG_803.jpg': 'airplanes',\n",
            " 'IMG_805.jpg': 'airplanes',\n",
            " 'IMG_813.jpg': 'sword',\n",
            " 'IMG_815.jpg': 'mountain-bike',\n",
            " 'IMG_817.jpg': 'school-bus',\n",
            " 'IMG_823.jpg': 'sword',\n",
            " 'IMG_826.jpg': 'school-bus',\n",
            " 'IMG_828.jpg': 'galaxy',\n",
            " 'IMG_835.jpg': 'mountain-bike',\n",
            " 'IMG_837.jpg': 'sheet-music',\n",
            " 'IMG_844.jpg': 'grand-piano',\n",
            " 'IMG_845.jpg': 'sword',\n",
            " 'IMG_848.jpg': 'owl',\n",
            " 'IMG_852.jpg': 'lightbulb',\n",
            " 'IMG_862.jpg': 'wine-bottle',\n",
            " 'IMG_864.jpg': 'sheet-music',\n",
            " 'IMG_866.jpg': 'bear',\n",
            " 'IMG_867.jpg': 'airplanes',\n",
            " 'IMG_873.jpg': 'skyscraper',\n",
            " 'IMG_876.jpg': 'sheet-music',\n",
            " 'IMG_877.jpg': 'skyscraper',\n",
            " 'IMG_878.jpg': 'owl',\n",
            " 'IMG_880.jpg': 'bear',\n",
            " 'IMG_884.jpg': 'kangaroo',\n",
            " 'IMG_887.jpg': 'waterfall',\n",
            " 'IMG_89.jpg': 'waterfall',\n",
            " 'IMG_893.jpg': 'grand-piano',\n",
            " 'IMG_897.jpg': 'bear',\n",
            " 'IMG_904.jpg': 'fireworks',\n",
            " 'IMG_907.jpg': 'computer-monitor',\n",
            " 'IMG_912.jpg': 'lightning',\n",
            " 'IMG_913.jpg': 'galaxy',\n",
            " 'IMG_914.jpg': 'sheet-music',\n",
            " 'IMG_917.jpg': 't-shirt',\n",
            " 'IMG_919.jpg': 'sheet-music',\n",
            " 'IMG_92.jpg': 'mountain-bike',\n",
            " 'IMG_922.jpg': 'sheet-music',\n",
            " 'IMG_923.jpg': 'fireworks',\n",
            " 'IMG_932.jpg': 'airplanes',\n",
            " 'IMG_938.jpg': 'school-bus',\n",
            " 'IMG_94.jpg': 'wine-bottle',\n",
            " 'IMG_942.jpg': 'lightbulb',\n",
            " 'IMG_943.jpg': 'sword',\n",
            " 'IMG_944.jpg': 't-shirt',\n",
            " 'IMG_950.jpg': 't-shirt',\n",
            " 'IMG_952.jpg': 'fireworks',\n",
            " 'IMG_956.jpg': 't-shirt',\n",
            " 'IMG_959.jpg': 'kangaroo',\n",
            " 'IMG_96.jpg': 'airplanes',\n",
            " 'IMG_965.jpg': 'grand-piano',\n",
            " 'IMG_967.jpg': 'calculator',\n",
            " 'IMG_98.jpg': 'lightbulb',\n",
            " 'IMG_982.jpg': 'computer-monitor',\n",
            " 'IMG_986.jpg': 'wine-bottle',\n",
            " 'IMG_999.jpg': 'lightning'}\n",
            "Num. of labeled images 500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "txXZe0vv-g4J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b7f84a15-59df-4a9c-e40f-75c0a434c2b8"
      },
      "source": [
        "print(eval_out)"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[3.801963493973017, 0.5537459]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}