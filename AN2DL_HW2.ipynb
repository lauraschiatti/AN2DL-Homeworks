{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Setup\n### Imports"},{"metadata":{"trusted":true},"cell_type":"code","source":"from __future__ import absolute_import, division, print_function, unicode_literals\nimport sys\nimport os\nimport numpy as np\nfrom IPython.core.interactiveshell import InteractiveShell\nInteractiveShell.ast_node_interactivity = \"all\"\n\nIS_COLAB = 'google.colab' in sys.modules\nif IS_COLAB:\n    # %tensorflow_version only exists in Colab.\n    %tensorflow_version 2.x\n    \nimport tensorflow as tf\nfrom PIL import Image\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom datetime import datetime\nfrom pprint import pprint\nimport time\nimport matplotlib.pyplot as plt\n\n%matplotlib notebook","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Setup GPU"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Set GPU memory growth\n# Allows to only as much GPU memory as needed\ngpus = tf.config.experimental.list_physical_devices('GPU')\nif gpus:\n  try:\n    # Currently, memory growth needs to be the same across GPUs\n    for gpu in gpus:\n      tf.config.experimental.set_memory_growth(gpu, True)\n    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n  except RuntimeError as e:\n    # Memory growth must be set before GPUs have been initialized\n    print(e)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Constants"},{"metadata":{"trusted":true},"cell_type":"code","source":"SEED = 1234\ntf.random.set_seed(SEED)\n\nif IS_COLAB:\n    DATASET_PATH = '/content/drive/My Drive'\nelse:\n    DATASET_PATH = '/kaggle/input/ann-and-dl-image-segmentation'\n\nCWD = os.getcwd()\nDATASET_DIR_NAME = 'Segmentation_Dataset'\nEXPERIMENTS_PATH = os.path.join(CWD, 'segmentation_experiments')\n\nEPOCHS = 150\nLEARNING_RATE = 1e-3\nSHOW_PLOTS = False\nUSE_DATA_AUGMENTATION = True\nVALIDATION_SPLIT = 0.2\nBATCH_SIZE = 4\nIMAGE_WIDTH = 256\nIMAGE_HEIGHT = 256\nOUTPUT_CHANNELS = 1\nRGB_CHANNELS = 3\nNUMBER_OF_CLASSES = 1 # house / not-house\nEARLY_STOP = True\nSAVE_PREDICTIONS = True\n\nprint(\"cwd: %s\" % CWD)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data Generators"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"if USE_DATA_AUGMENTATION:\n    train_img_data_gen = ImageDataGenerator(rotation_range=10,\n                                            width_shift_range=10,\n                                            height_shift_range=10,\n                                            zoom_range=0.3,\n                                            horizontal_flip=True,\n                                            vertical_flip=True,\n                                            fill_mode='constant',\n                                            cval=0,\n                                            rescale=1. / 255,\n                                            validation_split=VALIDATION_SPLIT)\n\n    train_mask_data_gen = ImageDataGenerator(rotation_range=10,\n                                             width_shift_range=10,\n                                             height_shift_range=10,\n                                             zoom_range=0.3,\n                                             horizontal_flip=True,\n                                             vertical_flip=True,\n                                             fill_mode='constant',\n                                             cval=0,\n                                             rescale=1. / 255,\n                                             validation_split=VALIDATION_SPLIT)\nelse:\n    train_img_data_gen = ImageDataGenerator(rescale=1. / 255, validation_split=VALIDATION_SPLIT)\n    train_mask_data_gen = ImageDataGenerator(rescale=1. / 255, validation_split=VALIDATION_SPLIT)\n\ntest_img_data_gen = ImageDataGenerator(rescale=1./255)\n\n# Create generators to read images from dataset directory\n# -------------------------------------------------------\n\n# path to dataset\ndataset_dir = os.path.join(DATASET_PATH, DATASET_DIR_NAME)\n# path to train dataset\ntrain_dir = os.path.join(dataset_dir, 'training')\n# path to test dataset\ntest_dir = os.path.join(dataset_dir, 'test')\n\nprint('dataset %s \\ntrain dir %s \\ntest dir %s \\n' % (dataset_dir, train_dir, test_dir))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Dataset generation"},{"metadata":{"trusted":true},"cell_type":"code","source":"## Training images\ntrain_img_gen = train_img_data_gen.flow_from_directory(\n    os.path.join(train_dir, 'images'),\n    subset='training',  # subset of data\n    target_size=(IMAGE_HEIGHT, IMAGE_WIDTH),\n    batch_size=BATCH_SIZE,\n#     color_mode='grayscale',\n    class_mode=None,\n    shuffle=True,\n    interpolation='bilinear',\n    seed=SEED)\n## Training masks\ntrain_mask_gen = train_mask_data_gen.flow_from_directory(\n    os.path.join(train_dir, 'masks'),\n    subset='training',\n    target_size=(IMAGE_HEIGHT, IMAGE_WIDTH),\n    batch_size=BATCH_SIZE,\n    color_mode='grayscale',\n    class_mode=None,\n    shuffle=True,\n    interpolation='bilinear',\n    seed=SEED)\n\n## Validation images\nvalid_img_gen = train_img_data_gen.flow_from_directory(\n    os.path.join(train_dir, 'images'),\n    subset='validation',\n    target_size=(IMAGE_HEIGHT, IMAGE_WIDTH),\n    batch_size=BATCH_SIZE,\n#     color_mode='grayscale',\n    class_mode=None,\n    shuffle=False,\n    interpolation='bilinear',\n    seed=SEED)\n\n## Validation masks\nvalid_mask_gen = train_mask_data_gen.flow_from_directory(\n    os.path.join(train_dir, 'masks'),\n    subset='validation',\n    target_size=(IMAGE_HEIGHT, IMAGE_WIDTH),\n    batch_size=BATCH_SIZE,\n    color_mode='grayscale',\n    class_mode=None,\n    shuffle=False,\n    interpolation='bilinear',\n    seed=SEED)\n\n## Test images\ntest_img_gen = test_img_data_gen.flow_from_directory(os.path.join(test_dir, 'images'),\n                                                     target_size=(IMAGE_HEIGHT, IMAGE_WIDTH),\n                                                     batch_size=BATCH_SIZE, \n                                                     class_mode=None, # Because we have no class subfolders in this case\n                                                     shuffle=False,\n                                                     interpolation='bilinear',\n                                                     seed=SEED)\n\n## Validation generator\nvalid_gen = zip(valid_img_gen, valid_mask_gen)\n## Training generator\ntrain_gen = zip(train_img_gen, train_mask_gen)\n## Test generator ==> since we dont have masks..\ntest_gen = test_img_gen","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Create dataset objects"},{"metadata":{"trusted":true},"cell_type":"code","source":"def prepare_target(x_, y_):\n    y_ = tf.cast(tf.expand_dims(y_[..., 0], -1), tf.int32)\n    return x_, tf.where(y_ > 0, y_ - 1, y_ + 1)\n\ntrain_dataset = tf.data.Dataset.from_generator(lambda: train_gen,\n                                               output_types=(tf.float32, tf.float32),\n                                               output_shapes=([None, IMAGE_HEIGHT, IMAGE_WIDTH, RGB_CHANNELS], [None, IMAGE_HEIGHT, IMAGE_WIDTH, OUTPUT_CHANNELS]))\ntrain_dataset = train_dataset.map(prepare_target)\n# Repeat\ntrain_dataset = train_dataset.repeat()\n\n# Validation\n# ----------\nvalid_dataset = tf.data.Dataset.from_generator(lambda: valid_gen, \n                                               output_types=(tf.float32, tf.float32),\n                                               output_shapes=([None, IMAGE_HEIGHT, IMAGE_WIDTH, RGB_CHANNELS], [None, IMAGE_HEIGHT, IMAGE_WIDTH, OUTPUT_CHANNELS]))\nvalid_dataset = valid_dataset.map(prepare_target)\n# Repeat\nvalid_dataset = valid_dataset.repeat()\n\n# Test\n# ----------\ntest_dataset = tf.data.Dataset.from_generator(lambda: test_gen, \n                                               output_types=(tf.float32, tf.float32),\n                                               output_shapes=([None, IMAGE_HEIGHT, IMAGE_WIDTH, RGB_CHANNELS], [None, IMAGE_HEIGHT, IMAGE_WIDTH, OUTPUT_CHANNELS]))\ntest_dataset = test_dataset.map(prepare_target)\n# Repeat\ntest_dataset = test_dataset.repeat()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Test data generator"},{"metadata":{"trusted":true},"cell_type":"code","source":"if SHOW_PLOTS:\n    fig, ax = plt.subplots(1, 2)\n    fig.show()\n\n    # Assign a color to each class\n    colors_dict = {}\n    colors_dict[0] = [255, 255, 255]  # foreground\n    colors_dict[1] = [0, 0, 0]  # background\n    colors_dict[2] = [3, 82, 252] # contours\n\n    iterator = iter(train_dataset)\n\n    for _ in range(2):\n        augmented_img, target = next(iterator)\n        augmented_img = augmented_img[0]   # First element\n        augmented_img = augmented_img * 255  # denormalize\n\n        target = np.array(target[0, ..., 0])   # First element (squeezing channel dimension)\n\n        # Assign colors (just for visualization)\n        target_img = np.zeros([target.shape[0], target.shape[1], 3])\n\n        target_img[np.where(target == 0)] = colors_dict[0]\n        target_img[np.where(target == 1)] = colors_dict[1]\n        target_img[np.where(target == 2)] = colors_dict[2]\n\n        ax[0].imshow(np.uint8(augmented_img))\n        ax[1].imshow(np.uint8(target_img))\n\n        fig.canvas.draw()\n        time.sleep(1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Convolutional Neural Network\n### Functions"},{"metadata":{"trusted":true},"cell_type":"code","source":"# IoU metric function\ndef iou_metric(y_true, y_pred):\n    # from pobability to predicted class {0, 1}\n    y_pred = tf.cast(y_pred > 0.5, tf.float32) # when using sigmoid. Use argmax for softmax\n    # A and B\n    intersection = tf.reduce_sum(y_true * y_pred)\n    # A or B\n    union = tf.reduce_sum(y_true) + tf.reduce_sum(y_pred) - intersection\n    # IoU\n    return intersection / union\n\n# Create a model \ndef create_model(depth, start_f, num_classes, dynamic_input_shape):\n    model = tf.keras.Sequential()\n\n    # Encoder\n    # -------\n    for i in range(depth):\n        if i == 0:\n            if dynamic_input_shape:\n                input_shape = [None, None, RGB_CHANNELS]\n            else:\n                input_shape = [IMAGE_HEIGHT, IMAGE_WIDTH, RGB_CHANNELS]\n        else:\n            input_shape = [None]\n\n        model.add(\n            tf.keras.layers.Conv2D(filters=start_f,\n                                   kernel_size=(3, 3),\n                                   strides=(1, 1),\n                                   padding='same',\n                                   input_shape=input_shape))\n        model.add(tf.keras.layers.ReLU())\n        model.add(tf.keras.layers.MaxPool2D(pool_size=(2, 2)))\n\n        start_f *= 2\n\n    # Decoder\n    # -------\n    for i in range(depth):\n        model.add(tf.keras.layers.UpSampling2D(2, interpolation='bilinear'))\n        model.add(tf.keras.layers.Conv2D(filters=start_f // 2,\n                                   kernel_size=(3, 3),\n                                   strides=(1, 1),\n                                   padding='same'))\n\n        model.add(tf.keras.layers.ReLU())\n\n        start_f = start_f // 2\n\n    # Prediction Layer\n    # ----------------\n    model.add(\n        tf.keras.layers.Conv2D(filters=num_classes,\n                               kernel_size=(1, 1),\n                               strides=(1, 1),\n                               padding='same',\n                               activation='sigmoid'))\n\n    return model","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Create the model"},{"metadata":{"trusted":true},"cell_type":"code","source":"model = create_model(depth=4,\n                     start_f=4,\n                     num_classes=NUMBER_OF_CLASSES,\n                     dynamic_input_shape=False)\n\n# Visualize created model as a table\nmodel.summary()\n\n# Visualize initialized weights\n# print(model.weights)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Compile the model\n#### Functions"},{"metadata":{"trusted":true},"cell_type":"code","source":"def dice_coeficcient(y_true, y_pred, smooth=1):\n    from keras import backend as K\n    intersection = K.sum(K.abs(y_true * y_pred), axis=-1)\n    return (2. * intersection + smooth) / (K.sum(K.square(y_true),-1) + K.sum(K.square(y_pred),-1) + smooth)\n\ndef dice_loss(y_true, y_pred):\n    return 1-dice_coeficcient(y_true, y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Loss\n# Sparse Categorical Crossentropy to use integers (mask) instead of one-hot encoded labels\n# loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False)\nloss = 'binary_crossentropy'\n\n# optimizer\noptimizer = tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE)\n\n# Validation metrics\nmetrics = [iou_metric, 'accuracy']\n\n# Compile Model\nmodel.compile(optimizer=optimizer, loss=loss, metrics=metrics)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Training"},{"metadata":{"trusted":true},"cell_type":"code","source":"callbacks = []\n\nif not os.path.exists(EXPERIMENTS_PATH):\n    os.makedirs(EXPERIMENTS_PATH)\n\nnow = datetime.now().strftime('%b%d_%H-%M-%S')\n\nmodel_name = 'CNN'\n\nexp_dir = os.path.join(EXPERIMENTS_PATH, model_name + '_' + str(now))\nif not os.path.exists(exp_dir):\n    os.makedirs(exp_dir)\n\n# Model checkpoint\n# ----------------\nckpt_dir = os.path.join(exp_dir, 'ckpts')\nif not os.path.exists(ckpt_dir):\n    os.makedirs(ckpt_dir)\n\nckpt_callback = tf.keras.callbacks.ModelCheckpoint(filepath=os.path.join(ckpt_dir, 'cp_{epoch:02d}.ckpt'), \n                                                   save_weights_only=False)  # False to save the model directly\ncallbacks.append(ckpt_callback)\n\n# Visualize Learning on Tensorboard\n# ---------------------------------\n# tb_dir = os.path.join(exp_dir, 'tb_logs')\n# if not os.path.exists(tb_dir):\n#     os.makedirs(tb_dir)\n    \n# # By default shows losses and metrics for both training and validation\n# tb_callback = tf.keras.callbacks.TensorBoard(log_dir=tb_dir,\n#                                              profile_batch=0,\n#                                              histogram_freq=0)  # if 1 shows weights histograms\n# callbacks.append(tb_callback)\n\n# Early Stopping\n# --------------\nif EARLY_STOP:\n    es_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n    callbacks.append(es_callback)\n\n\nmodel.fit(x=train_dataset, epochs=EPOCHS, \n                          steps_per_epoch = (len(train_img_gen)//BATCH_SIZE),\n                          validation_data=valid_gen, \n                          validation_steps=(len(valid_img_gen)//BATCH_SIZE), \n                          callbacks=callbacks)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Evaluation"},{"metadata":{"trusted":true},"cell_type":"code","source":"evaluation_output = model.evaluate(x=valid_dataset, steps=len(valid_img_gen), verbose=0)\n\nprint('Loss: %s \\nIoU Metric: %s \\nAccuracy: %s' % (evaluation_output[0], evaluation_output[1], evaluation_output[2]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Final result\n### Functions"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Compute predictions\ndef generate_predictions(model):\n    # Cycle over test images\n    test_img_dir = os.path.join(test_dir, 'images', 'img')\n\n    # s[:10] predict until 10th image\n    image_filenames = next(os.walk(test_img_dir))[2]\n\n    results = {}\n\n    for filename in image_filenames:\n        # test images are in RGB, hence no need to transform them.\n        img = Image.open(os.path.join(test_img_dir, filename))\n        img = img.resize((IMAGE_HEIGHT, IMAGE_WIDTH))  # target size\n\n        # data_normalization\n        img_array = np.array(img)  #\n        # img_array = img_array * 1. / 255  # normalization\n        img_array = np.expand_dims(img_array, axis=0) # to fix dims of input in the model\n\n        print(\"prediction for {}...\".format(filename))\n        predictions = model.predict(img_array)\n\n        # Get predicted class as the index corresponding to the maximum value in the vector probability\n        predicted_mask = tf.argmax(predictions, axis=-1)\n        predicted_mask = predicted_mask[0]\n        target = np.array(predicted_mask)\n        target = rle_encode(target)\n        \n        # print(target.shape)\n        results[filename[:-4]] = target\n\n    # create_csv(results)\n    print('Num. of labeled images', results.__len__())\n    return results\n    \n## Create CSV file\ndef create_csv(results, results_dir='./'):\n    csv_fname = 'results_'\n    csv_fname += datetime.now().strftime('%b%d_%H-%M-%S') + '.csv'\n    csv_fname = os.path.join(results_dir, csv_fname)\n    with open(csv_fname, 'w') as f:\n        f.write('ImageId,EncodedPixels,Width,Height\\n')\n        for key, value in results.items():\n            f.write(key + ',' + str(value) + ',' + '256' + ',' + '256' + '\\n')\n        \ndef rle_encode(img):\n    # Flatten column-wise\n    pixels = img.T.flatten()\n    pixels = np.concatenate([[0], pixels, [0]])\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n    runs[1::2] -= runs[::2]\n    return ' '.join(str(x) for x in runs)\n        ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Generate predictions"},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = generate_predictions(model)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Save predictions"},{"metadata":{"trusted":true},"cell_type":"code","source":"if SAVE_PREDICTIONS:\n    predictions_dir = os.path.join(CWD, 'predictions')\n    if not os.path.exists(predictions_dir):\n        os.makedirs(predictions_dir)\n    create_csv(predictions, predictions_dir)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}